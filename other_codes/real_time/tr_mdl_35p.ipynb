{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tr_mdl_35p.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks_AbdKIb-xZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump as jdump\n",
        "import time\n",
        "import random\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5XUNQBvcGf6"
      },
      "source": [
        "PATH2PROJECT = \"/content/drive/MyDrive/Projects/EyeTracker/\"\n",
        "raw_models_dir = PATH2PROJECT + \"models/eye_tracking/raw/\"\n",
        "trained_models_dir = PATH2PROJECT + \"models/eye_tracking/trained/\"\n",
        "scaler_dir = PATH2PROJECT + \"models/eye_tracking/trained/scalers.bin\"\n",
        "MODEL_FOL = \"model1\"\n",
        "R_TRAIN = 0.9\n",
        "CHOSEN_INPUTS = [0, 1, 2, 6, 7, 8, 9]\n",
        "N_EPOCHS = 200\n",
        "PATIENCE = 25\n",
        "MIN_BRIGHTNESS_RATIO = 0.7\n",
        "MAX_BRIGHTNESS_RATIO = 1.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W471W2kGcGct",
        "outputId": "efbc0dae-1b41-4c3d-9a28-1ab68a46d87a"
      },
      "source": [
        "x1_load = []\n",
        "x2_load = []\n",
        "y_load = []\n",
        "dataset_dir = PATH2PROJECT + \"dataset/\"\n",
        "datasets_folders = os.listdir(dataset_dir)\n",
        "\n",
        "for data_fol in datasets_folders:\n",
        "    with open(dataset_dir + data_fol +\n",
        "              \"/eye_tracking_calibration_modified/x1.pickle\", \"rb\") as f:\n",
        "        x1_load0 = pickle.load(f)\n",
        "    with open(dataset_dir + data_fol +\n",
        "              \"/eye_tracking_calibration_modified/x2.pickle\", \"rb\") as f:\n",
        "        x2_load0 = pickle.load(f)\n",
        "    with open(dataset_dir + data_fol +\n",
        "              \"/eye_tracking_calibration_modified/y.pickle\", \"rb\") as f:\n",
        "        y_load0 = pickle.load(f)\n",
        "    for (x10, x20, y10) in zip(x1_load0, x2_load0, y_load0):\n",
        "        x1_load.append(x10)\n",
        "        x2_load.append(x20)\n",
        "        y_load.append(y10)\n",
        "\n",
        "x1_load = np.array(x1_load)\n",
        "x2_load = np.array(x2_load)\n",
        "y_load = np.array(y_load)\n",
        "\n",
        "n_samples, frame_height, frame_width = x1_load.shape[:-1]\n",
        "print(n_samples, frame_height, frame_width)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24500 48 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGCJnYPQcGZW"
      },
      "source": [
        "x1_chg_bri = x1_load.copy()\n",
        "for (i, _) in enumerate(x1_chg_bri):\n",
        "    r = random.uniform(MIN_BRIGHTNESS_RATIO, MAX_BRIGHTNESS_RATIO)\n",
        "    x1_chg_bri[i] = (x1_chg_bri[i] * r).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiA8EMH-cGV5"
      },
      "source": [
        "x2_chs_inp = x2_load[:, CHOSEN_INPUTS]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "cQCtiUVrcGTE",
        "outputId": "cf673c86-4d57-4381-e848-610ac31224f4"
      },
      "source": [
        "SAMPLE_NUMBER = 2\n",
        "print(x2_chs_inp[SAMPLE_NUMBER])\n",
        "print(y_load[SAMPLE_NUMBER])\n",
        "plt.imshow(x1_chg_bri[SAMPLE_NUMBER].reshape((frame_height, frame_width)),\n",
        "           cmap=\"gray\", vmin=0, vmax=255)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.92097984  0.01450496 -0.1692337   0.51821423  0.47875661  0.51987594\n",
            "  0.49142322]\n",
            "[2995.  948.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh_Zk28FcGQM",
        "outputId": "46f72028-9f35-4a63-d431-ca1095fc23a6"
      },
      "source": [
        "x1_scaler = 255\n",
        "x1 = x1_chg_bri / x1_scaler\n",
        "\n",
        "x2_scaler = StandardScaler()\n",
        "x2 = x2_scaler.fit_transform(x2_chs_inp)\n",
        "\n",
        "y_scalers = y_load.max(0)\n",
        "y = y_load / y_scalers\n",
        "\n",
        "scalers = [x1_scaler, x2_scaler, y_scalers]\n",
        "jdump(scalers, scaler_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Projects/EyeTracker/models/eye_tracking/trained/scalers.bin']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIZGqD-WcGNY"
      },
      "source": [
        "y1, y2 = y[:, 0], y[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbNgiHNOcGKq",
        "outputId": "ec4926d5-4033-4404-f630-012ea6cc9495"
      },
      "source": [
        "x1_shf, x2_shf, y1_shf, y2_shf = shuffle(x1, x2, y1, y2)\n",
        "\n",
        "n_train = int(R_TRAIN * n_samples)\n",
        "n_test = n_samples - n_train\n",
        "x1_train, x2_train = x1_shf[:n_train], x2_shf[:n_train]\n",
        "x1_test, x2_test = x1_shf[n_train:], x2_shf[n_train:]\n",
        "y1_train, y2_train = y1_shf[:n_train], y2_shf[:n_train]\n",
        "y1_test, y2_test = y1_shf[n_train:], y2_shf[n_train:]\n",
        "\n",
        "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape,\n",
        "      x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22050, 48, 44, 1) (2450, 48, 44, 1) (22050,) (2450,) (22050, 7) (2450, 7) (22050,) (2450,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry-G5x1jcGID"
      },
      "source": [
        "x_train_list = [x1_train, x2_train]\n",
        "x_test_list = [x1_test, x2_test]\n",
        "y_train_list = [y1_train, y2_train]\n",
        "y_test_list = [y1_test, y2_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hasap1QZcpoy"
      },
      "source": [
        "cb = EarlyStopping(patience=PATIENCE, verbose=1, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrUF35MNcpl6",
        "outputId": "527350e0-f72b-4b9e-89da-3f7aae450fd7"
      },
      "source": [
        "model = load_model(raw_models_dir + MODEL_FOL)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 48, 44, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 48, 44, 16)   416         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 24, 22, 16)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 24, 22, 32)   12832       max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 12, 11, 32)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 10, 9, 64)    18496       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 5, 4, 64)     0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 1280)         0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 256)          327936      flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 263)          0           dense_44[0][0]                   \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 128)          33792       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 128)          33792       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 64)           8256        dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 64)           8256        dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 16)           1040        dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 16)           1040        dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 8)            136         dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 8)            136         dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 1)            9           dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 1)            9           dense_52[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 446,146\n",
            "Trainable params: 446,146\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRSpklK-emfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9738c510-2126-4122-8d69-f31492db2d03"
      },
      "source": [
        "model.fit(x_train_list,\n",
        "          y_train_list,\n",
        "          validation_data=(x_test_list, y_test_list),\n",
        "          epochs=N_EPOCHS,\n",
        "          callbacks=cb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "690/690 [==============================] - 39s 12ms/step - loss: 0.2981 - dense_53_loss: 0.1147 - dense_54_loss: 0.1834 - val_loss: 0.2116 - val_dense_53_loss: 0.0783 - val_dense_54_loss: 0.1334\n",
            "Epoch 2/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1953 - dense_53_loss: 0.0741 - dense_54_loss: 0.1212 - val_loss: 0.1794 - val_dense_53_loss: 0.0636 - val_dense_54_loss: 0.1158\n",
            "Epoch 3/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1708 - dense_53_loss: 0.0657 - dense_54_loss: 0.1051 - val_loss: 0.1639 - val_dense_53_loss: 0.0632 - val_dense_54_loss: 0.1007\n",
            "Epoch 4/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1566 - dense_53_loss: 0.0612 - dense_54_loss: 0.0954 - val_loss: 0.1478 - val_dense_53_loss: 0.0567 - val_dense_54_loss: 0.0911\n",
            "Epoch 5/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.1455 - dense_53_loss: 0.0577 - dense_54_loss: 0.0878 - val_loss: 0.1465 - val_dense_53_loss: 0.0592 - val_dense_54_loss: 0.0873\n",
            "Epoch 6/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.1380 - dense_53_loss: 0.0545 - dense_54_loss: 0.0835 - val_loss: 0.1410 - val_dense_53_loss: 0.0575 - val_dense_54_loss: 0.0835\n",
            "Epoch 7/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1277 - dense_53_loss: 0.0518 - dense_54_loss: 0.0760 - val_loss: 0.1322 - val_dense_53_loss: 0.0583 - val_dense_54_loss: 0.0739\n",
            "Epoch 8/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1242 - dense_53_loss: 0.0495 - dense_54_loss: 0.0747 - val_loss: 0.1273 - val_dense_53_loss: 0.0489 - val_dense_54_loss: 0.0784\n",
            "Epoch 9/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.1194 - dense_53_loss: 0.0489 - dense_54_loss: 0.0704 - val_loss: 0.1365 - val_dense_53_loss: 0.0504 - val_dense_54_loss: 0.0862\n",
            "Epoch 10/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1119 - dense_53_loss: 0.0457 - dense_54_loss: 0.0663 - val_loss: 0.1357 - val_dense_53_loss: 0.0533 - val_dense_54_loss: 0.0824\n",
            "Epoch 11/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.1112 - dense_53_loss: 0.0459 - dense_54_loss: 0.0653 - val_loss: 0.1209 - val_dense_53_loss: 0.0519 - val_dense_54_loss: 0.0690\n",
            "Epoch 12/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.1061 - dense_53_loss: 0.0441 - dense_54_loss: 0.0620 - val_loss: 0.1242 - val_dense_53_loss: 0.0474 - val_dense_54_loss: 0.0768\n",
            "Epoch 13/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.1033 - dense_53_loss: 0.0431 - dense_54_loss: 0.0602 - val_loss: 0.1171 - val_dense_53_loss: 0.0452 - val_dense_54_loss: 0.0718\n",
            "Epoch 14/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0988 - dense_53_loss: 0.0414 - dense_54_loss: 0.0574 - val_loss: 0.1136 - val_dense_53_loss: 0.0459 - val_dense_54_loss: 0.0678\n",
            "Epoch 15/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0966 - dense_53_loss: 0.0402 - dense_54_loss: 0.0563 - val_loss: 0.1208 - val_dense_53_loss: 0.0456 - val_dense_54_loss: 0.0752\n",
            "Epoch 16/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0944 - dense_53_loss: 0.0397 - dense_54_loss: 0.0547 - val_loss: 0.1068 - val_dense_53_loss: 0.0424 - val_dense_54_loss: 0.0644\n",
            "Epoch 17/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0894 - dense_53_loss: 0.0381 - dense_54_loss: 0.0513 - val_loss: 0.1001 - val_dense_53_loss: 0.0405 - val_dense_54_loss: 0.0596\n",
            "Epoch 18/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0890 - dense_53_loss: 0.0381 - dense_54_loss: 0.0509 - val_loss: 0.1075 - val_dense_53_loss: 0.0434 - val_dense_54_loss: 0.0641\n",
            "Epoch 19/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0890 - dense_53_loss: 0.0377 - dense_54_loss: 0.0513 - val_loss: 0.1009 - val_dense_53_loss: 0.0438 - val_dense_54_loss: 0.0572\n",
            "Epoch 20/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0859 - dense_53_loss: 0.0366 - dense_54_loss: 0.0493 - val_loss: 0.1068 - val_dense_53_loss: 0.0450 - val_dense_54_loss: 0.0618\n",
            "Epoch 21/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0846 - dense_53_loss: 0.0358 - dense_54_loss: 0.0488 - val_loss: 0.1045 - val_dense_53_loss: 0.0431 - val_dense_54_loss: 0.0615\n",
            "Epoch 22/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0818 - dense_53_loss: 0.0354 - dense_54_loss: 0.0464 - val_loss: 0.1153 - val_dense_53_loss: 0.0483 - val_dense_54_loss: 0.0670\n",
            "Epoch 23/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0801 - dense_53_loss: 0.0347 - dense_54_loss: 0.0454 - val_loss: 0.0986 - val_dense_53_loss: 0.0415 - val_dense_54_loss: 0.0571\n",
            "Epoch 24/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0817 - dense_53_loss: 0.0350 - dense_54_loss: 0.0468 - val_loss: 0.0972 - val_dense_53_loss: 0.0398 - val_dense_54_loss: 0.0575\n",
            "Epoch 25/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0785 - dense_53_loss: 0.0340 - dense_54_loss: 0.0445 - val_loss: 0.0990 - val_dense_53_loss: 0.0420 - val_dense_54_loss: 0.0570\n",
            "Epoch 26/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0771 - dense_53_loss: 0.0334 - dense_54_loss: 0.0437 - val_loss: 0.0880 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0529\n",
            "Epoch 27/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0740 - dense_53_loss: 0.0323 - dense_54_loss: 0.0417 - val_loss: 0.0926 - val_dense_53_loss: 0.0382 - val_dense_54_loss: 0.0544\n",
            "Epoch 28/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0739 - dense_53_loss: 0.0326 - dense_54_loss: 0.0413 - val_loss: 0.0926 - val_dense_53_loss: 0.0376 - val_dense_54_loss: 0.0550\n",
            "Epoch 29/200\n",
            "690/690 [==============================] - 7s 10ms/step - loss: 0.0728 - dense_53_loss: 0.0323 - dense_54_loss: 0.0404 - val_loss: 0.1000 - val_dense_53_loss: 0.0444 - val_dense_54_loss: 0.0556\n",
            "Epoch 30/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0770 - dense_53_loss: 0.0340 - dense_54_loss: 0.0430 - val_loss: 0.0900 - val_dense_53_loss: 0.0389 - val_dense_54_loss: 0.0511\n",
            "Epoch 31/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0697 - dense_53_loss: 0.0315 - dense_54_loss: 0.0382 - val_loss: 0.0846 - val_dense_53_loss: 0.0367 - val_dense_54_loss: 0.0479\n",
            "Epoch 32/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0682 - dense_53_loss: 0.0306 - dense_54_loss: 0.0377 - val_loss: 0.0858 - val_dense_53_loss: 0.0360 - val_dense_54_loss: 0.0498\n",
            "Epoch 33/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0727 - dense_53_loss: 0.0323 - dense_54_loss: 0.0404 - val_loss: 0.0859 - val_dense_53_loss: 0.0375 - val_dense_54_loss: 0.0484\n",
            "Epoch 34/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0713 - dense_53_loss: 0.0315 - dense_54_loss: 0.0398 - val_loss: 0.1024 - val_dense_53_loss: 0.0442 - val_dense_54_loss: 0.0581\n",
            "Epoch 35/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0682 - dense_53_loss: 0.0310 - dense_54_loss: 0.0372 - val_loss: 0.0846 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0500\n",
            "Epoch 36/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0655 - dense_53_loss: 0.0302 - dense_54_loss: 0.0354 - val_loss: 0.0864 - val_dense_53_loss: 0.0360 - val_dense_54_loss: 0.0504\n",
            "Epoch 37/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0660 - dense_53_loss: 0.0302 - dense_54_loss: 0.0358 - val_loss: 0.0926 - val_dense_53_loss: 0.0382 - val_dense_54_loss: 0.0544\n",
            "Epoch 38/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0635 - dense_53_loss: 0.0300 - dense_54_loss: 0.0335 - val_loss: 0.0810 - val_dense_53_loss: 0.0362 - val_dense_54_loss: 0.0448\n",
            "Epoch 39/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0607 - dense_53_loss: 0.0289 - dense_54_loss: 0.0318 - val_loss: 0.0825 - val_dense_53_loss: 0.0387 - val_dense_54_loss: 0.0438\n",
            "Epoch 40/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0606 - dense_53_loss: 0.0286 - dense_54_loss: 0.0320 - val_loss: 0.0936 - val_dense_53_loss: 0.0371 - val_dense_54_loss: 0.0566\n",
            "Epoch 41/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0666 - dense_53_loss: 0.0299 - dense_54_loss: 0.0367 - val_loss: 0.0826 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0474\n",
            "Epoch 42/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0617 - dense_53_loss: 0.0294 - dense_54_loss: 0.0323 - val_loss: 0.0860 - val_dense_53_loss: 0.0382 - val_dense_54_loss: 0.0479\n",
            "Epoch 43/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0570 - dense_53_loss: 0.0284 - dense_54_loss: 0.0286 - val_loss: 0.0811 - val_dense_53_loss: 0.0370 - val_dense_54_loss: 0.0441\n",
            "Epoch 44/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0595 - dense_53_loss: 0.0289 - dense_54_loss: 0.0306 - val_loss: 0.0783 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0423\n",
            "Epoch 45/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0592 - dense_53_loss: 0.0289 - dense_54_loss: 0.0303 - val_loss: 0.0806 - val_dense_53_loss: 0.0383 - val_dense_54_loss: 0.0423\n",
            "Epoch 46/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0625 - dense_53_loss: 0.0295 - dense_54_loss: 0.0330 - val_loss: 0.0803 - val_dense_53_loss: 0.0380 - val_dense_54_loss: 0.0422\n",
            "Epoch 47/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0551 - dense_53_loss: 0.0279 - dense_54_loss: 0.0272 - val_loss: 0.0765 - val_dense_53_loss: 0.0372 - val_dense_54_loss: 0.0393\n",
            "Epoch 48/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0580 - dense_53_loss: 0.0285 - dense_54_loss: 0.0295 - val_loss: 0.0840 - val_dense_53_loss: 0.0368 - val_dense_54_loss: 0.0472\n",
            "Epoch 49/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0677 - dense_53_loss: 0.0307 - dense_54_loss: 0.0370 - val_loss: 0.0760 - val_dense_53_loss: 0.0335 - val_dense_54_loss: 0.0424\n",
            "Epoch 50/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0540 - dense_53_loss: 0.0277 - dense_54_loss: 0.0263 - val_loss: 0.0774 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0428\n",
            "Epoch 51/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0627 - dense_53_loss: 0.0295 - dense_54_loss: 0.0331 - val_loss: 0.0774 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0417\n",
            "Epoch 52/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0535 - dense_53_loss: 0.0275 - dense_54_loss: 0.0260 - val_loss: 0.0742 - val_dense_53_loss: 0.0342 - val_dense_54_loss: 0.0399\n",
            "Epoch 53/200\n",
            "690/690 [==============================] - 7s 11ms/step - loss: 0.0522 - dense_53_loss: 0.0269 - dense_54_loss: 0.0253 - val_loss: 0.0725 - val_dense_53_loss: 0.0323 - val_dense_54_loss: 0.0402\n",
            "Epoch 54/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0533 - dense_53_loss: 0.0270 - dense_54_loss: 0.0263 - val_loss: 0.0849 - val_dense_53_loss: 0.0372 - val_dense_54_loss: 0.0477\n",
            "Epoch 55/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0557 - dense_53_loss: 0.0275 - dense_54_loss: 0.0281 - val_loss: 0.0824 - val_dense_53_loss: 0.0389 - val_dense_54_loss: 0.0435\n",
            "Epoch 56/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0562 - dense_53_loss: 0.0282 - dense_54_loss: 0.0280 - val_loss: 0.0779 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0428\n",
            "Epoch 57/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0599 - dense_53_loss: 0.0289 - dense_54_loss: 0.0309 - val_loss: 0.0782 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0431\n",
            "Epoch 58/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0608 - dense_53_loss: 0.0288 - dense_54_loss: 0.0320 - val_loss: 0.0860 - val_dense_53_loss: 0.0370 - val_dense_54_loss: 0.0491\n",
            "Epoch 59/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0535 - dense_53_loss: 0.0269 - dense_54_loss: 0.0266 - val_loss: 0.0777 - val_dense_53_loss: 0.0363 - val_dense_54_loss: 0.0414\n",
            "Epoch 60/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0620 - dense_53_loss: 0.0288 - dense_54_loss: 0.0332 - val_loss: 0.0776 - val_dense_53_loss: 0.0354 - val_dense_54_loss: 0.0422\n",
            "Epoch 61/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0549 - dense_53_loss: 0.0274 - dense_54_loss: 0.0275 - val_loss: 0.0765 - val_dense_53_loss: 0.0360 - val_dense_54_loss: 0.0405\n",
            "Epoch 62/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0514 - dense_53_loss: 0.0263 - dense_54_loss: 0.0251 - val_loss: 0.0779 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0434\n",
            "Epoch 63/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0541 - dense_53_loss: 0.0276 - dense_54_loss: 0.0265 - val_loss: 0.0751 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0392\n",
            "Epoch 64/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0544 - dense_53_loss: 0.0267 - dense_54_loss: 0.0277 - val_loss: 0.0808 - val_dense_53_loss: 0.0361 - val_dense_54_loss: 0.0446\n",
            "Epoch 65/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0614 - dense_53_loss: 0.0290 - dense_54_loss: 0.0324 - val_loss: 0.0745 - val_dense_53_loss: 0.0353 - val_dense_54_loss: 0.0392\n",
            "Epoch 66/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0547 - dense_53_loss: 0.0267 - dense_54_loss: 0.0280 - val_loss: 0.0829 - val_dense_53_loss: 0.0343 - val_dense_54_loss: 0.0487\n",
            "Epoch 67/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0530 - dense_53_loss: 0.0264 - dense_54_loss: 0.0266 - val_loss: 0.0801 - val_dense_53_loss: 0.0354 - val_dense_54_loss: 0.0447\n",
            "Epoch 68/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0567 - dense_53_loss: 0.0274 - dense_54_loss: 0.0293 - val_loss: 0.0785 - val_dense_53_loss: 0.0356 - val_dense_54_loss: 0.0429\n",
            "Epoch 69/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0549 - dense_53_loss: 0.0264 - dense_54_loss: 0.0285 - val_loss: 0.0785 - val_dense_53_loss: 0.0343 - val_dense_54_loss: 0.0442\n",
            "Epoch 70/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0579 - dense_53_loss: 0.0277 - dense_54_loss: 0.0302 - val_loss: 0.0763 - val_dense_53_loss: 0.0362 - val_dense_54_loss: 0.0401\n",
            "Epoch 71/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0517 - dense_53_loss: 0.0257 - dense_54_loss: 0.0260 - val_loss: 0.0710 - val_dense_53_loss: 0.0332 - val_dense_54_loss: 0.0379\n",
            "Epoch 72/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0502 - dense_53_loss: 0.0255 - dense_54_loss: 0.0247 - val_loss: 0.0714 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0357\n",
            "Epoch 73/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0502 - dense_53_loss: 0.0250 - dense_54_loss: 0.0252 - val_loss: 0.0764 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0404\n",
            "Epoch 74/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0497 - dense_53_loss: 0.0259 - dense_54_loss: 0.0238 - val_loss: 0.0751 - val_dense_53_loss: 0.0361 - val_dense_54_loss: 0.0390\n",
            "Epoch 75/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0515 - dense_53_loss: 0.0265 - dense_54_loss: 0.0251 - val_loss: 0.0753 - val_dense_53_loss: 0.0368 - val_dense_54_loss: 0.0385\n",
            "Epoch 76/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0524 - dense_53_loss: 0.0261 - dense_54_loss: 0.0263 - val_loss: 0.0840 - val_dense_53_loss: 0.0362 - val_dense_54_loss: 0.0478\n",
            "Epoch 77/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0543 - dense_53_loss: 0.0261 - dense_54_loss: 0.0282 - val_loss: 0.0832 - val_dense_53_loss: 0.0372 - val_dense_54_loss: 0.0460\n",
            "Epoch 78/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0525 - dense_53_loss: 0.0258 - dense_54_loss: 0.0267 - val_loss: 0.0901 - val_dense_53_loss: 0.0415 - val_dense_54_loss: 0.0486\n",
            "Epoch 79/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0544 - dense_53_loss: 0.0272 - dense_54_loss: 0.0271 - val_loss: 0.0755 - val_dense_53_loss: 0.0345 - val_dense_54_loss: 0.0410\n",
            "Epoch 80/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0490 - dense_53_loss: 0.0251 - dense_54_loss: 0.0239 - val_loss: 0.0755 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0404\n",
            "Epoch 81/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0505 - dense_53_loss: 0.0253 - dense_54_loss: 0.0252 - val_loss: 0.0763 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0417\n",
            "Epoch 82/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0486 - dense_53_loss: 0.0250 - dense_54_loss: 0.0236 - val_loss: 0.0768 - val_dense_53_loss: 0.0345 - val_dense_54_loss: 0.0423\n",
            "Epoch 83/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0497 - dense_53_loss: 0.0251 - dense_54_loss: 0.0247 - val_loss: 0.0784 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0432\n",
            "Epoch 84/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0544 - dense_53_loss: 0.0262 - dense_54_loss: 0.0281 - val_loss: 0.0941 - val_dense_53_loss: 0.0349 - val_dense_54_loss: 0.0592\n",
            "Epoch 85/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0485 - dense_53_loss: 0.0240 - dense_54_loss: 0.0244 - val_loss: 0.0823 - val_dense_53_loss: 0.0372 - val_dense_54_loss: 0.0452\n",
            "Epoch 86/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0613 - dense_53_loss: 0.0291 - dense_54_loss: 0.0323 - val_loss: 0.0865 - val_dense_53_loss: 0.0361 - val_dense_54_loss: 0.0504\n",
            "Epoch 87/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0530 - dense_53_loss: 0.0255 - dense_54_loss: 0.0275 - val_loss: 0.0757 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0398\n",
            "Epoch 88/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0476 - dense_53_loss: 0.0245 - dense_54_loss: 0.0231 - val_loss: 0.0738 - val_dense_53_loss: 0.0339 - val_dense_54_loss: 0.0399\n",
            "Epoch 89/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0526 - dense_53_loss: 0.0253 - dense_54_loss: 0.0274 - val_loss: 0.0760 - val_dense_53_loss: 0.0360 - val_dense_54_loss: 0.0400\n",
            "Epoch 90/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0516 - dense_53_loss: 0.0254 - dense_54_loss: 0.0262 - val_loss: 0.0800 - val_dense_53_loss: 0.0349 - val_dense_54_loss: 0.0450\n",
            "Epoch 91/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0528 - dense_53_loss: 0.0251 - dense_54_loss: 0.0277 - val_loss: 0.0844 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0485\n",
            "Epoch 92/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0475 - dense_53_loss: 0.0237 - dense_54_loss: 0.0238 - val_loss: 0.0732 - val_dense_53_loss: 0.0317 - val_dense_54_loss: 0.0415\n",
            "Epoch 93/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0497 - dense_53_loss: 0.0248 - dense_54_loss: 0.0249 - val_loss: 0.0716 - val_dense_53_loss: 0.0333 - val_dense_54_loss: 0.0383\n",
            "Epoch 94/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0537 - dense_53_loss: 0.0256 - dense_54_loss: 0.0281 - val_loss: 0.0784 - val_dense_53_loss: 0.0350 - val_dense_54_loss: 0.0435\n",
            "Epoch 95/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0487 - dense_53_loss: 0.0252 - dense_54_loss: 0.0235 - val_loss: 0.0703 - val_dense_53_loss: 0.0326 - val_dense_54_loss: 0.0377\n",
            "Epoch 96/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0472 - dense_53_loss: 0.0237 - dense_54_loss: 0.0235 - val_loss: 0.0755 - val_dense_53_loss: 0.0325 - val_dense_54_loss: 0.0430\n",
            "Epoch 97/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0471 - dense_53_loss: 0.0234 - dense_54_loss: 0.0237 - val_loss: 0.0809 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0452\n",
            "Epoch 98/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0484 - dense_53_loss: 0.0240 - dense_54_loss: 0.0244 - val_loss: 0.0809 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0452\n",
            "Epoch 99/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0451 - dense_53_loss: 0.0238 - dense_54_loss: 0.0213 - val_loss: 0.0688 - val_dense_53_loss: 0.0314 - val_dense_54_loss: 0.0373\n",
            "Epoch 100/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0481 - dense_53_loss: 0.0239 - dense_54_loss: 0.0243 - val_loss: 0.0751 - val_dense_53_loss: 0.0339 - val_dense_54_loss: 0.0412\n",
            "Epoch 101/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0487 - dense_53_loss: 0.0241 - dense_54_loss: 0.0246 - val_loss: 0.0748 - val_dense_53_loss: 0.0324 - val_dense_54_loss: 0.0424\n",
            "Epoch 102/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0503 - dense_53_loss: 0.0249 - dense_54_loss: 0.0254 - val_loss: 0.0811 - val_dense_53_loss: 0.0353 - val_dense_54_loss: 0.0458\n",
            "Epoch 103/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0533 - dense_53_loss: 0.0255 - dense_54_loss: 0.0278 - val_loss: 0.0843 - val_dense_53_loss: 0.0358 - val_dense_54_loss: 0.0485\n",
            "Epoch 104/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0618 - dense_53_loss: 0.0270 - dense_54_loss: 0.0348 - val_loss: 0.0776 - val_dense_53_loss: 0.0330 - val_dense_54_loss: 0.0447\n",
            "Epoch 105/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0537 - dense_53_loss: 0.0252 - dense_54_loss: 0.0285 - val_loss: 0.0754 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0407\n",
            "Epoch 106/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0442 - dense_53_loss: 0.0232 - dense_54_loss: 0.0210 - val_loss: 0.0686 - val_dense_53_loss: 0.0312 - val_dense_54_loss: 0.0373\n",
            "Epoch 107/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0459 - dense_53_loss: 0.0234 - dense_54_loss: 0.0225 - val_loss: 0.0777 - val_dense_53_loss: 0.0347 - val_dense_54_loss: 0.0430\n",
            "Epoch 108/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0488 - dense_53_loss: 0.0240 - dense_54_loss: 0.0248 - val_loss: 0.0744 - val_dense_53_loss: 0.0323 - val_dense_54_loss: 0.0421\n",
            "Epoch 109/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0482 - dense_53_loss: 0.0235 - dense_54_loss: 0.0247 - val_loss: 0.0747 - val_dense_53_loss: 0.0341 - val_dense_54_loss: 0.0406\n",
            "Epoch 110/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0475 - dense_53_loss: 0.0238 - dense_54_loss: 0.0238 - val_loss: 0.0737 - val_dense_53_loss: 0.0331 - val_dense_54_loss: 0.0406\n",
            "Epoch 111/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0480 - dense_53_loss: 0.0236 - dense_54_loss: 0.0245 - val_loss: 0.0780 - val_dense_53_loss: 0.0359 - val_dense_54_loss: 0.0421\n",
            "Epoch 112/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0498 - dense_53_loss: 0.0243 - dense_54_loss: 0.0254 - val_loss: 0.0798 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0441\n",
            "Epoch 113/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0469 - dense_53_loss: 0.0236 - dense_54_loss: 0.0234 - val_loss: 0.0781 - val_dense_53_loss: 0.0325 - val_dense_54_loss: 0.0456\n",
            "Epoch 114/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0463 - dense_53_loss: 0.0235 - dense_54_loss: 0.0227 - val_loss: 0.0711 - val_dense_53_loss: 0.0327 - val_dense_54_loss: 0.0385\n",
            "Epoch 115/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0468 - dense_53_loss: 0.0231 - dense_54_loss: 0.0237 - val_loss: 0.0787 - val_dense_53_loss: 0.0328 - val_dense_54_loss: 0.0460\n",
            "Epoch 116/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0487 - dense_53_loss: 0.0232 - dense_54_loss: 0.0255 - val_loss: 0.0814 - val_dense_53_loss: 0.0357 - val_dense_54_loss: 0.0457\n",
            "Epoch 117/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0716 - dense_53_loss: 0.0315 - dense_54_loss: 0.0401 - val_loss: 0.0764 - val_dense_53_loss: 0.0342 - val_dense_54_loss: 0.0422\n",
            "Epoch 118/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0460 - dense_53_loss: 0.0235 - dense_54_loss: 0.0225 - val_loss: 0.0777 - val_dense_53_loss: 0.0342 - val_dense_54_loss: 0.0436\n",
            "Epoch 119/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0474 - dense_53_loss: 0.0233 - dense_54_loss: 0.0241 - val_loss: 0.0826 - val_dense_53_loss: 0.0334 - val_dense_54_loss: 0.0492\n",
            "Epoch 120/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0468 - dense_53_loss: 0.0234 - dense_54_loss: 0.0234 - val_loss: 0.0710 - val_dense_53_loss: 0.0312 - val_dense_54_loss: 0.0398\n",
            "Epoch 121/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0502 - dense_53_loss: 0.0238 - dense_54_loss: 0.0264 - val_loss: 0.0762 - val_dense_53_loss: 0.0318 - val_dense_54_loss: 0.0444\n",
            "Epoch 122/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0470 - dense_53_loss: 0.0228 - dense_54_loss: 0.0241 - val_loss: 0.0732 - val_dense_53_loss: 0.0314 - val_dense_54_loss: 0.0418\n",
            "Epoch 123/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0459 - dense_53_loss: 0.0227 - dense_54_loss: 0.0232 - val_loss: 0.0826 - val_dense_53_loss: 0.0315 - val_dense_54_loss: 0.0511\n",
            "Epoch 124/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0484 - dense_53_loss: 0.0237 - dense_54_loss: 0.0247 - val_loss: 0.0891 - val_dense_53_loss: 0.0331 - val_dense_54_loss: 0.0559\n",
            "Epoch 125/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0497 - dense_53_loss: 0.0236 - dense_54_loss: 0.0261 - val_loss: 0.0739 - val_dense_53_loss: 0.0321 - val_dense_54_loss: 0.0418\n",
            "Epoch 126/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0461 - dense_53_loss: 0.0230 - dense_54_loss: 0.0231 - val_loss: 0.0777 - val_dense_53_loss: 0.0316 - val_dense_54_loss: 0.0462\n",
            "Epoch 127/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0460 - dense_53_loss: 0.0227 - dense_54_loss: 0.0233 - val_loss: 0.0824 - val_dense_53_loss: 0.0366 - val_dense_54_loss: 0.0458\n",
            "Epoch 128/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0496 - dense_53_loss: 0.0236 - dense_54_loss: 0.0260 - val_loss: 0.0754 - val_dense_53_loss: 0.0316 - val_dense_54_loss: 0.0438\n",
            "Epoch 129/200\n",
            "690/690 [==============================] - 8s 12ms/step - loss: 0.0499 - dense_53_loss: 0.0238 - dense_54_loss: 0.0261 - val_loss: 0.0850 - val_dense_53_loss: 0.0347 - val_dense_54_loss: 0.0503\n",
            "Epoch 130/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0473 - dense_53_loss: 0.0236 - dense_54_loss: 0.0237 - val_loss: 0.0747 - val_dense_53_loss: 0.0326 - val_dense_54_loss: 0.0421\n",
            "Epoch 131/200\n",
            "690/690 [==============================] - 8s 11ms/step - loss: 0.0462 - dense_53_loss: 0.0228 - dense_54_loss: 0.0234 - val_loss: 0.0792 - val_dense_53_loss: 0.0331 - val_dense_54_loss: 0.0461\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00131: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81fb7a3fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx7vI5sieta_"
      },
      "source": [
        "yhat_train_list = model.predict(x_train_list)\n",
        "yhat_test_list = model.predict(x_test_list)\n",
        "\n",
        "y_train = np.concatenate((np.expand_dims(y_train_list[0], 1),\n",
        "                          np.expand_dims(y_train_list[1], 1)), 1)\n",
        "yhat_train = np.concatenate((yhat_train_list[0], yhat_train_list[1]), 1)\n",
        "y_test = np.concatenate((np.expand_dims(y_test_list[0], 1),\n",
        "                          np.expand_dims(y_test_list[1], 1)), 1)\n",
        "yhat_test = np.concatenate((yhat_test_list[0], yhat_test_list[1]), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR4p1QPpjndQ"
      },
      "source": [
        "train_loss = np.abs(y_train - yhat_train).sum(0) / n_train\n",
        "test_loss = np.abs(y_test - yhat_test).sum(0) / n_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W8EZ8WKj6tY",
        "outputId": "f09f1734-6b68-4072-a523-b826e5d718e6"
      },
      "source": [
        "model.save(trained_models_dir + MODEL_FOL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Projects/EyeTracker/models/eye_tracking/trained/model4/assets\n"
          ]
        }
      ]
    }
  ]
}