{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e28fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 00:03:25.233713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-10 00:03:25.233741: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump as jdump\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeee9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH2PROJECT = \"\"\n",
    "SUBJECT_NUM = 1\n",
    "CHOSEN_INPUTS = [0, 1, 2, 6, 7, 8, 9]\n",
    "R_TRAIN = 0.9\n",
    "N_EPOCHS = 200\n",
    "PATIENCE = 16\n",
    "N_SUBJECTS = 5\n",
    "MIN_BRIGHTNESS_RATIO = 0.7\n",
    "MAX_BRIGHTNESS_RATIO = 1.4\n",
    "N_MODELS = 6\n",
    "TRAINABLE_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68dcf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24500 48 44\n"
     ]
    }
   ],
   "source": [
    "x1_load = []\n",
    "x2_load = []\n",
    "y_load = []\n",
    "dataset_dir = PATH2PROJECT + \"Dataset/\n",
    "datasets_folders = os.listdir(dataset_dir)\n",
    "\n",
    "for data_fol in datasets_folders:\n",
    "    with open(dataset_dir + f\"{data_fol}/x1.pickle\", \"rb\") as f:\n",
    "        x1_load0 = pickle.load(f)\n",
    "    with open(dataset_dir + f\"{data_fol}/x2.pickle\", \"rb\") as f:\n",
    "        x2_load0 = pickle.load(f)\n",
    "    with open(dataset_dir + f\"{data_fol}/y.pickle\", \"rb\") as f:\n",
    "        y_load0 = pickle.load(f)\n",
    "    for (x10, x20, y10) in zip(x1_load0, x2_load0, y_load0):\n",
    "        x1_load.append(x10)\n",
    "        x2_load.append(x20)\n",
    "        y_load.append(y10)\n",
    "\n",
    "x1_load = np.array(x1_load)\n",
    "x2_load = np.array(x2_load)\n",
    "y_load = np.array(y_load)\n",
    "\n",
    "n_samples, frame_height, frame_width = x1_load.shape[:-1]\n",
    "print(n_samples, frame_height, frame_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d511a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_chg_bri = x1_load.copy()\n",
    "for (i, _) in enumerate(x1_chg_bri):\n",
    "    r = random.uniform(MIN_BRIGHTNESS_RATIO, MAX_BRIGHTNESS_RATIO)\n",
    "    x1_chg_bri[i] = (x1_chg_bri[i] * r).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5355a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_chs_inp = x2_load[:, CHOSEN_INPUTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba9c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.92097984  0.01450496 -0.1692337   0.51821423  0.47875661  0.51987594\n",
      "  0.49142322]\n",
      "[2995.  948.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_NUMBER = 2\n",
    "print(x2_chs_inp[SAMPLE_NUMBER])\n",
    "print(y_load[SAMPLE_NUMBER])\n",
    "plt.imshow(x1_chg_bri[SAMPLE_NUMBER].reshape((frame_height, frame_width)),\n",
    "           cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b923cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model/test/scalers.bin']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_scaler = 255\n",
    "x1 = x1_chg_bri / x1_scaler\n",
    "\n",
    "x2_scaler = StandardScaler()\n",
    "x2 = x2_scaler.fit_transform(x2_chs_inp)\n",
    "\n",
    "y_scalers = y_load.max(0)\n",
    "y = y_load / y_scalers\n",
    "\n",
    "scalers = [x1_scaler, x2_scaler, y_scalers]\n",
    "jdump(scalers, PATH2PROJECT + \"Model/Models/trained/scalers.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b518fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2 = y[:, 0], y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2a7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22050, 48, 44, 1) (2450, 48, 44, 1) (22050,) (2450,) (22050, 7) (2450, 7) (22050,) (2450,)\n"
     ]
    }
   ],
   "source": [
    "x1_shf, x2_shf, y1_shf, y2_shf = shuffle(x1, x2, y1, y2)\n",
    "\n",
    "n_train = int(R_TRAIN * n_samples)\n",
    "n_test = n_samples - n_train\n",
    "x1_train, x2_train = x1_shf[:n_train], x2_shf[:n_train]\n",
    "x1_test, x2_test = x1_shf[n_train:], x2_shf[n_train:]\n",
    "y1_train, y2_train = y1_shf[:n_train], y2_shf[:n_train]\n",
    "y1_test, y2_test = y1_shf[n_train:], y2_shf[n_train:]\n",
    "\n",
    "print(x1_train.shape, x1_test.shape, y1_train.shape, y1_test.shape,\n",
    "      x2_train.shape, x2_test.shape, y2_train.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93bafcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = [x1_train, x2_train]\n",
    "x_test_list = [x1_test, x2_test]\n",
    "y_train_list = [y1_train, y2_train]\n",
    "y_test_list = [y1_test, y2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5483878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n"
     ]
    }
   ],
   "source": [
    "subjects_dir = PATH2PROJECT + \"Subjects/\"\n",
    "\n",
    "with open(subjects_dir + f\"{SUBJECT_NUM}/x1.pickle\", \"rb\") as f:\n",
    "    x1_sbj_load = pickle.load(f)\n",
    "with open(subjects_dir + f\"{SUBJECT_NUM}/x2.pickle\", \"rb\") as f:\n",
    "    x2_sbj_load = pickle.load(f)\n",
    "with open(subjects_dir + f\"{SUBJECT_NUM}/y.pickle\", \"rb\") as f:\n",
    "    y_sbj_load = pickle.load(f)\n",
    "\n",
    "n_smp_sbj = x1_sbj_load.shape[0]\n",
    "print(n_smp_sbj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b48c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sbj_chs_inp = x2_sbj_load[:, CHOSEN_INPUTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3914718",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_sbj = x1_sbj_load / x1_scaler\n",
    "x2_sbj = x2_scaler.transform(x2_sbj_chs_inp)\n",
    "y_sbj = y_sbj_load / y_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4960a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "10400\n"
     ]
    }
   ],
   "source": [
    "points3x3 = np.array([1, 3, 5, 10, 17, 18, 20, 26, 31])\n",
    "n_smp_slc = 100\n",
    "n_smp_pnt = 400\n",
    "\n",
    "n_point = n_smp_sbj // n_smp_pnt\n",
    "x1_seen = []\n",
    "x2_seen = []\n",
    "y_seen = []\n",
    "x1_unseen = []\n",
    "x2_unseen = []\n",
    "y_unseen = []\n",
    "\n",
    "for i in range(n_point):\n",
    "    if np.sum(i == points3x3) == 1:\n",
    "        for j in range(n_smp_slc):\n",
    "            x1_seen.append(x1_sbj[i * n_smp_pnt + j])\n",
    "            x2_seen.append(x2_sbj[i * n_smp_pnt + j])\n",
    "            y_seen.append(y_sbj[i * n_smp_pnt + j])\n",
    "    else:\n",
    "        for j in range(n_smp_pnt):\n",
    "            x1_unseen.append(x1_sbj[i * n_smp_pnt + j])\n",
    "            x2_unseen.append(x2_sbj[i * n_smp_pnt + j])\n",
    "            y_unseen.append(y_sbj[i * n_smp_pnt + j])\n",
    "\n",
    "x1_seen = np.array(x1_seen)\n",
    "x2_seen = np.array(x2_seen)\n",
    "y_seen = np.array(y_seen)\n",
    "x1_unseen = np.array(x1_unseen)\n",
    "x2_unseen = np.array(x2_unseen)\n",
    "y_unseen = np.array(y_unseen)\n",
    "\n",
    "n_seen = x1_seen.shape[0]\n",
    "n_unseen = x1_unseen.shape[0]\n",
    "print(n_seen)\n",
    "print(n_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d99733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55829163  0.35274728 -0.18863474 -0.71921379 -0.63960778  0.4223304\n",
      "  0.19969227]\n",
      "[0.5 0. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLE_NUMBER = 120\n",
    "print(x2_seen[SAMPLE_NUMBER])\n",
    "print(y_seen[SAMPLE_NUMBER])\n",
    "plt.imshow(x1_seen[SAMPLE_NUMBER].\n",
    "           reshape((frame_height, frame_width)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78bbf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_seen, y2_seen = y_seen[:, 0], y_seen[:, 1]\n",
    "y1_unseen, y2_unseen = y_unseen[:, 0], y_unseen[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2e0e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 48, 44, 1) (90, 48, 44, 1) (810,) (90,) (810, 7) (90, 7) (810,) (90,) (10400, 48, 44, 1) (10400, 7) (10400,) (10400,)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "  x1_seen_shf,\n",
    "  x2_seen_shf,\n",
    "  y1_seen_shf,\n",
    "  y2_seen_shf\n",
    ") = shuffle(\n",
    "    x1_seen,\n",
    "    x2_seen,\n",
    "    y1_seen,\n",
    "    y2_seen\n",
    "    )\n",
    "\n",
    "n_train_seen = int(R_TRAIN * n_seen)\n",
    "n_test_seen = n_seen - n_train_seen\n",
    "x1_train_seen = x1_seen_shf[:n_train_seen]\n",
    "x2_train_seen = x2_seen_shf[:n_train_seen]\n",
    "x1_test_seen = x1_seen_shf[n_train_seen:]\n",
    "x2_test_seen = x2_seen_shf[n_train_seen:]\n",
    "y1_train_seen = y1_seen_shf[:n_train_seen]\n",
    "y2_train_seen = y2_seen_shf[:n_train_seen]\n",
    "y1_test_seen = y1_seen_shf[n_train_seen:]\n",
    "y2_test_seen = y2_seen_shf[n_train_seen:]\n",
    "\n",
    "(\n",
    "    x1_unseen_shf,\n",
    "    x2_unseen_shf,\n",
    "    y1_unseen_shf,\n",
    "    y2_unseen_shf\n",
    ") = shuffle(\n",
    "    x1_unseen,\n",
    "    x2_unseen,\n",
    "    y1_unseen,\n",
    "    y2_unseen\n",
    ")\n",
    "\n",
    "print(x1_train_seen.shape, x1_test_seen.shape,\n",
    "      y1_train_seen.shape, y1_test_seen.shape,\n",
    "      x2_train_seen.shape, x2_test_seen.shape,\n",
    "      y2_train_seen.shape, y2_test_seen.shape,\n",
    "      x1_unseen_shf.shape, x2_unseen_shf.shape,\n",
    "      y1_unseen_shf.shape, y2_unseen_shf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb47797",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seen_list = [x1_train_seen, x2_train_seen]\n",
    "x_test_seen_list = [x1_test_seen, x2_test_seen]\n",
    "y_train_seen_list = [y1_train_seen, y2_train_seen]\n",
    "y_test_seen_list = [y1_test_seen, y2_test_seen]\n",
    "\n",
    "x_unseen_list = [x1_unseen_shf, x2_unseen_shf]\n",
    "y_unseen_list = [y1_unseen_shf, y2_unseen_shf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce75dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = EarlyStopping(patience=PATIENCE, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02709de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Model 1 ************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 00:03:32.697921: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 186278400 exceeds 10% of free system memory.\n",
      "2021-10-10 00:03:32.827945: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "690/690 [==============================] - 17s 23ms/step - loss: 0.4387 - dense_20_loss: 0.1958 - dense_21_loss: 0.2429 - val_loss: 0.3271 - val_dense_20_loss: 0.1314 - val_dense_21_loss: 0.1957\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.3123 - dense_20_loss: 0.1324 - dense_21_loss: 0.1799 - val_loss: 0.2858 - val_dense_20_loss: 0.1146 - val_dense_21_loss: 0.1711\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2716 - dense_20_loss: 0.1148 - dense_21_loss: 0.1567 - val_loss: 0.2717 - val_dense_20_loss: 0.1077 - val_dense_21_loss: 0.1640\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2494 - dense_20_loss: 0.1054 - dense_21_loss: 0.1440 - val_loss: 0.2444 - val_dense_20_loss: 0.1030 - val_dense_21_loss: 0.1415\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2368 - dense_20_loss: 0.1002 - dense_21_loss: 0.1365 - val_loss: 0.2989 - val_dense_20_loss: 0.1029 - val_dense_21_loss: 0.1960\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2258 - dense_20_loss: 0.0957 - dense_21_loss: 0.1300 - val_loss: 0.2538 - val_dense_20_loss: 0.0928 - val_dense_21_loss: 0.1610\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2199 - dense_20_loss: 0.0943 - dense_21_loss: 0.1256 - val_loss: 0.2700 - val_dense_20_loss: 0.0947 - val_dense_21_loss: 0.1753\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2134 - dense_20_loss: 0.0913 - dense_21_loss: 0.1222 - val_loss: 0.2586 - val_dense_20_loss: 0.0962 - val_dense_21_loss: 0.1623\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2086 - dense_20_loss: 0.0891 - dense_21_loss: 0.1195 - val_loss: 0.2610 - val_dense_20_loss: 0.0921 - val_dense_21_loss: 0.1690\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2042 - dense_20_loss: 0.0877 - dense_21_loss: 0.1165 - val_loss: 0.2408 - val_dense_20_loss: 0.0845 - val_dense_21_loss: 0.1563\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.2018 - dense_20_loss: 0.0865 - dense_21_loss: 0.1153 - val_loss: 0.2220 - val_dense_20_loss: 0.0935 - val_dense_21_loss: 0.1285\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1974 - dense_20_loss: 0.0853 - dense_21_loss: 0.1121 - val_loss: 0.2285 - val_dense_20_loss: 0.0815 - val_dense_21_loss: 0.1470\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1943 - dense_20_loss: 0.0847 - dense_21_loss: 0.1096 - val_loss: 0.2398 - val_dense_20_loss: 0.0857 - val_dense_21_loss: 0.1541\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1953 - dense_20_loss: 0.0839 - dense_21_loss: 0.1114 - val_loss: 0.2191 - val_dense_20_loss: 0.0899 - val_dense_21_loss: 0.1292\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1913 - dense_20_loss: 0.0824 - dense_21_loss: 0.1089 - val_loss: 0.2127 - val_dense_20_loss: 0.0884 - val_dense_21_loss: 0.1242\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1901 - dense_20_loss: 0.0823 - dense_21_loss: 0.1078 - val_loss: 0.2485 - val_dense_20_loss: 0.0832 - val_dense_21_loss: 0.1653\n",
      "Epoch 17/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1880 - dense_20_loss: 0.0813 - dense_21_loss: 0.1067 - val_loss: 0.2176 - val_dense_20_loss: 0.0898 - val_dense_21_loss: 0.1278\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1856 - dense_20_loss: 0.0800 - dense_21_loss: 0.1056 - val_loss: 0.2160 - val_dense_20_loss: 0.0819 - val_dense_21_loss: 0.1341\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1850 - dense_20_loss: 0.0807 - dense_21_loss: 0.1043 - val_loss: 0.2095 - val_dense_20_loss: 0.0880 - val_dense_21_loss: 0.1215\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1836 - dense_20_loss: 0.0795 - dense_21_loss: 0.1041 - val_loss: 0.2297 - val_dense_20_loss: 0.0927 - val_dense_21_loss: 0.1371\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1834 - dense_20_loss: 0.0799 - dense_21_loss: 0.1035 - val_loss: 0.2344 - val_dense_20_loss: 0.0974 - val_dense_21_loss: 0.1370\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1837 - dense_20_loss: 0.0795 - dense_21_loss: 0.1043 - val_loss: 0.2122 - val_dense_20_loss: 0.0860 - val_dense_21_loss: 0.1262\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1814 - dense_20_loss: 0.0787 - dense_21_loss: 0.1026 - val_loss: 0.2029 - val_dense_20_loss: 0.0864 - val_dense_21_loss: 0.1165\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1812 - dense_20_loss: 0.0782 - dense_21_loss: 0.1030 - val_loss: 0.2053 - val_dense_20_loss: 0.0846 - val_dense_21_loss: 0.1207\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1805 - dense_20_loss: 0.0782 - dense_21_loss: 0.1023 - val_loss: 0.2089 - val_dense_20_loss: 0.0873 - val_dense_21_loss: 0.1216\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 18s 26ms/step - loss: 0.1791 - dense_20_loss: 0.0780 - dense_21_loss: 0.1011 - val_loss: 0.2243 - val_dense_20_loss: 0.0932 - val_dense_21_loss: 0.1311\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1800 - dense_20_loss: 0.0786 - dense_21_loss: 0.1015 - val_loss: 0.2562 - val_dense_20_loss: 0.0831 - val_dense_21_loss: 0.1731\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1825 - dense_20_loss: 0.0782 - dense_21_loss: 0.1044 - val_loss: 0.2188 - val_dense_20_loss: 0.0846 - val_dense_21_loss: 0.1341\n",
      "Epoch 29/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1840 - dense_20_loss: 0.0797 - dense_21_loss: 0.1044 - val_loss: 0.2107 - val_dense_20_loss: 0.0837 - val_dense_21_loss: 0.1270\n",
      "Epoch 30/200\n",
      "690/690 [==============================] - 18s 26ms/step - loss: 0.1802 - dense_20_loss: 0.0784 - dense_21_loss: 0.1017 - val_loss: 0.2202 - val_dense_20_loss: 0.0885 - val_dense_21_loss: 0.1317\n",
      "Epoch 31/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1802 - dense_20_loss: 0.0777 - dense_21_loss: 0.1025 - val_loss: 0.2248 - val_dense_20_loss: 0.0807 - val_dense_21_loss: 0.1442\n",
      "Epoch 32/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1766 - dense_20_loss: 0.0770 - dense_21_loss: 0.0995 - val_loss: 0.2067 - val_dense_20_loss: 0.0795 - val_dense_21_loss: 0.1272\n",
      "Epoch 33/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1774 - dense_20_loss: 0.0779 - dense_21_loss: 0.0995 - val_loss: 0.2114 - val_dense_20_loss: 0.0901 - val_dense_21_loss: 0.1213\n",
      "Epoch 34/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1784 - dense_20_loss: 0.0774 - dense_21_loss: 0.1010 - val_loss: 0.2142 - val_dense_20_loss: 0.0839 - val_dense_21_loss: 0.1303\n",
      "Epoch 35/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1786 - dense_20_loss: 0.0755 - dense_21_loss: 0.1031 - val_loss: 0.1992 - val_dense_20_loss: 0.0825 - val_dense_21_loss: 0.1167\n",
      "Epoch 36/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1771 - dense_20_loss: 0.0759 - dense_21_loss: 0.1013 - val_loss: 0.2009 - val_dense_20_loss: 0.0777 - val_dense_21_loss: 0.1233\n",
      "Epoch 37/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1758 - dense_20_loss: 0.0767 - dense_21_loss: 0.0991 - val_loss: 0.2394 - val_dense_20_loss: 0.0866 - val_dense_21_loss: 0.1528\n",
      "Epoch 38/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1780 - dense_20_loss: 0.0766 - dense_21_loss: 0.1014 - val_loss: 0.2064 - val_dense_20_loss: 0.0832 - val_dense_21_loss: 0.1232\n",
      "Epoch 39/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1760 - dense_20_loss: 0.0764 - dense_21_loss: 0.0997 - val_loss: 0.2391 - val_dense_20_loss: 0.0829 - val_dense_21_loss: 0.1562\n",
      "Epoch 40/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1774 - dense_20_loss: 0.0760 - dense_21_loss: 0.1014 - val_loss: 0.1906 - val_dense_20_loss: 0.0817 - val_dense_21_loss: 0.1089\n",
      "Epoch 41/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1765 - dense_20_loss: 0.0763 - dense_21_loss: 0.1002 - val_loss: 0.1971 - val_dense_20_loss: 0.0875 - val_dense_21_loss: 0.1096\n",
      "Epoch 42/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1835 - dense_20_loss: 0.0781 - dense_21_loss: 0.1054 - val_loss: 0.2078 - val_dense_20_loss: 0.0875 - val_dense_21_loss: 0.1203\n",
      "Epoch 43/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1759 - dense_20_loss: 0.0758 - dense_21_loss: 0.1002 - val_loss: 0.1936 - val_dense_20_loss: 0.0794 - val_dense_21_loss: 0.1142\n",
      "Epoch 44/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1729 - dense_20_loss: 0.0754 - dense_21_loss: 0.0974 - val_loss: 0.1896 - val_dense_20_loss: 0.0713 - val_dense_21_loss: 0.1183\n",
      "Epoch 45/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1732 - dense_20_loss: 0.0762 - dense_21_loss: 0.0970 - val_loss: 0.2342 - val_dense_20_loss: 0.0821 - val_dense_21_loss: 0.1520\n",
      "Epoch 46/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1699 - dense_20_loss: 0.0754 - dense_21_loss: 0.0945 - val_loss: 0.1952 - val_dense_20_loss: 0.0816 - val_dense_21_loss: 0.1136\n",
      "Epoch 47/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1722 - dense_20_loss: 0.0751 - dense_21_loss: 0.0971 - val_loss: 0.1992 - val_dense_20_loss: 0.0786 - val_dense_21_loss: 0.1206\n",
      "Epoch 48/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1730 - dense_20_loss: 0.0756 - dense_21_loss: 0.0974 - val_loss: 0.2004 - val_dense_20_loss: 0.0798 - val_dense_21_loss: 0.1206\n",
      "Epoch 49/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1700 - dense_20_loss: 0.0749 - dense_21_loss: 0.0951 - val_loss: 0.1929 - val_dense_20_loss: 0.0791 - val_dense_21_loss: 0.1137\n",
      "Epoch 50/200\n",
      "690/690 [==============================] - 16s 22ms/step - loss: 0.1843 - dense_20_loss: 0.0781 - dense_21_loss: 0.1062 - val_loss: 0.2190 - val_dense_20_loss: 0.0879 - val_dense_21_loss: 0.1311\n",
      "Epoch 51/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1745 - dense_20_loss: 0.0750 - dense_21_loss: 0.0995 - val_loss: 0.1957 - val_dense_20_loss: 0.0836 - val_dense_21_loss: 0.1121\n",
      "Epoch 52/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1712 - dense_20_loss: 0.0747 - dense_21_loss: 0.0965 - val_loss: 0.2069 - val_dense_20_loss: 0.0830 - val_dense_21_loss: 0.1239\n",
      "Epoch 53/200\n",
      "690/690 [==============================] - 16s 24ms/step - loss: 0.1748 - dense_20_loss: 0.0751 - dense_21_loss: 0.0996 - val_loss: 0.2115 - val_dense_20_loss: 0.0799 - val_dense_21_loss: 0.1316\n",
      "Epoch 54/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1735 - dense_20_loss: 0.0764 - dense_21_loss: 0.0972 - val_loss: 0.2075 - val_dense_20_loss: 0.0785 - val_dense_21_loss: 0.1291\n",
      "Epoch 55/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1720 - dense_20_loss: 0.0755 - dense_21_loss: 0.0965 - val_loss: 0.2149 - val_dense_20_loss: 0.0811 - val_dense_21_loss: 0.1338\n",
      "Epoch 56/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1735 - dense_20_loss: 0.0756 - dense_21_loss: 0.0979 - val_loss: 0.2291 - val_dense_20_loss: 0.0839 - val_dense_21_loss: 0.1452\n",
      "Epoch 57/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1796 - dense_20_loss: 0.0762 - dense_21_loss: 0.1034 - val_loss: 0.2045 - val_dense_20_loss: 0.0794 - val_dense_21_loss: 0.1251\n",
      "Epoch 58/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1748 - dense_20_loss: 0.0752 - dense_21_loss: 0.0995 - val_loss: 0.1853 - val_dense_20_loss: 0.0743 - val_dense_21_loss: 0.1110\n",
      "Epoch 59/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1770 - dense_20_loss: 0.0757 - dense_21_loss: 0.1013 - val_loss: 0.2119 - val_dense_20_loss: 0.0816 - val_dense_21_loss: 0.1304\n",
      "Epoch 60/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1756 - dense_20_loss: 0.0751 - dense_21_loss: 0.1005 - val_loss: 0.2316 - val_dense_20_loss: 0.0992 - val_dense_21_loss: 0.1324\n",
      "Epoch 61/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1794 - dense_20_loss: 0.0777 - dense_21_loss: 0.1017 - val_loss: 0.2047 - val_dense_20_loss: 0.0851 - val_dense_21_loss: 0.1196\n",
      "Epoch 62/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1767 - dense_20_loss: 0.0760 - dense_21_loss: 0.1008 - val_loss: 0.2027 - val_dense_20_loss: 0.0792 - val_dense_21_loss: 0.1235\n",
      "Epoch 63/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1724 - dense_20_loss: 0.0746 - dense_21_loss: 0.0978 - val_loss: 0.1941 - val_dense_20_loss: 0.0754 - val_dense_21_loss: 0.1187\n",
      "Epoch 64/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1679 - dense_20_loss: 0.0730 - dense_21_loss: 0.0949 - val_loss: 0.2038 - val_dense_20_loss: 0.0772 - val_dense_21_loss: 0.1266\n",
      "Epoch 65/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1750 - dense_20_loss: 0.0744 - dense_21_loss: 0.1006 - val_loss: 0.2081 - val_dense_20_loss: 0.0833 - val_dense_21_loss: 0.1247\n",
      "Epoch 66/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1692 - dense_20_loss: 0.0744 - dense_21_loss: 0.0948 - val_loss: 0.2076 - val_dense_20_loss: 0.0843 - val_dense_21_loss: 0.1233\n",
      "Epoch 67/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1755 - dense_20_loss: 0.0759 - dense_21_loss: 0.0996 - val_loss: 0.2151 - val_dense_20_loss: 0.0770 - val_dense_21_loss: 0.1382\n",
      "Epoch 68/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1792 - dense_20_loss: 0.0765 - dense_21_loss: 0.1028 - val_loss: 0.2140 - val_dense_20_loss: 0.0820 - val_dense_21_loss: 0.1320\n",
      "Epoch 69/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1778 - dense_20_loss: 0.0753 - dense_21_loss: 0.1025 - val_loss: 0.2066 - val_dense_20_loss: 0.0803 - val_dense_21_loss: 0.1263\n",
      "Epoch 70/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1794 - dense_20_loss: 0.0769 - dense_21_loss: 0.1025 - val_loss: 0.2025 - val_dense_20_loss: 0.0792 - val_dense_21_loss: 0.1233\n",
      "Epoch 71/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1723 - dense_20_loss: 0.0745 - dense_21_loss: 0.0978 - val_loss: 0.1842 - val_dense_20_loss: 0.0773 - val_dense_21_loss: 0.1068\n",
      "Epoch 72/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1727 - dense_20_loss: 0.0760 - dense_21_loss: 0.0967 - val_loss: 0.2084 - val_dense_20_loss: 0.0799 - val_dense_21_loss: 0.1285\n",
      "Epoch 73/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1749 - dense_20_loss: 0.0751 - dense_21_loss: 0.0999 - val_loss: 0.2107 - val_dense_20_loss: 0.0782 - val_dense_21_loss: 0.1324\n",
      "Epoch 74/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1762 - dense_20_loss: 0.0758 - dense_21_loss: 0.1004 - val_loss: 0.1920 - val_dense_20_loss: 0.0795 - val_dense_21_loss: 0.1125\n",
      "Epoch 75/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1763 - dense_20_loss: 0.0753 - dense_21_loss: 0.1010 - val_loss: 0.2068 - val_dense_20_loss: 0.0827 - val_dense_21_loss: 0.1241\n",
      "Epoch 76/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1826 - dense_20_loss: 0.0766 - dense_21_loss: 0.1061 - val_loss: 0.1944 - val_dense_20_loss: 0.0798 - val_dense_21_loss: 0.1146\n",
      "Epoch 77/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1722 - dense_20_loss: 0.0739 - dense_21_loss: 0.0984 - val_loss: 0.1900 - val_dense_20_loss: 0.0805 - val_dense_21_loss: 0.1095\n",
      "Epoch 78/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1719 - dense_20_loss: 0.0738 - dense_21_loss: 0.0981 - val_loss: 0.2040 - val_dense_20_loss: 0.0813 - val_dense_21_loss: 0.1227\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1724 - dense_20_loss: 0.0744 - dense_21_loss: 0.0980 - val_loss: 0.2070 - val_dense_20_loss: 0.0861 - val_dense_21_loss: 0.1209\n",
      "Epoch 80/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1711 - dense_20_loss: 0.0731 - dense_21_loss: 0.0980 - val_loss: 0.2162 - val_dense_20_loss: 0.0838 - val_dense_21_loss: 0.1324\n",
      "Epoch 81/200\n",
      "690/690 [==============================] - 17s 25ms/step - loss: 0.1752 - dense_20_loss: 0.0742 - dense_21_loss: 0.1009 - val_loss: 0.2183 - val_dense_20_loss: 0.0867 - val_dense_21_loss: 0.1316\n",
      "Epoch 82/200\n",
      "690/690 [==============================] - 17s 24ms/step - loss: 0.1740 - dense_20_loss: 0.0740 - dense_21_loss: 0.1000 - val_loss: 0.1966 - val_dense_20_loss: 0.0773 - val_dense_21_loss: 0.1193\n",
      "Epoch 83/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1668 - dense_20_loss: 0.0717 - dense_21_loss: 0.0952 - val_loss: 0.1874 - val_dense_20_loss: 0.0819 - val_dense_21_loss: 0.1054\n",
      "Epoch 84/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1730 - dense_20_loss: 0.0731 - dense_21_loss: 0.0999 - val_loss: 0.2324 - val_dense_20_loss: 0.0807 - val_dense_21_loss: 0.1518\n",
      "Epoch 85/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1771 - dense_20_loss: 0.0750 - dense_21_loss: 0.1021 - val_loss: 0.2150 - val_dense_20_loss: 0.0774 - val_dense_21_loss: 0.1377\n",
      "Epoch 86/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1761 - dense_20_loss: 0.0747 - dense_21_loss: 0.1014 - val_loss: 0.2096 - val_dense_20_loss: 0.0801 - val_dense_21_loss: 0.1296\n",
      "Epoch 87/200\n",
      "690/690 [==============================] - 16s 23ms/step - loss: 0.1664 - dense_20_loss: 0.0729 - dense_21_loss: 0.0935 - val_loss: 0.2069 - val_dense_20_loss: 0.0793 - val_dense_21_loss: 0.1275\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 00:27:43.644104: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 186278400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fef36552eb0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef367ad640> False\n",
      "<keras.layers.core.Dropout object at 0x7fef367adbe0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef366c10d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef366c13d0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef366c1c10> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef366c14f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef366d6130> False\n",
      "<keras.layers.core.Dropout object at 0x7fef366d6970> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef366d6250> False\n",
      "<keras.layers.core.Flatten object at 0x7fef366d6c40> False\n",
      "<keras.layers.core.Dense object at 0x7fef3665c100> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3665c7c0> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fef3665c7f0> False\n",
      "<keras.layers.merge.Concatenate object at 0x7fef3665cdc0> False\n",
      "<keras.layers.core.Dense object at 0x7fef36667040> False\n",
      "<keras.layers.core.Dense object at 0x7fef36667100> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36667ca0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36667cd0> False\n",
      "<keras.layers.core.Dense object at 0x7fef36667ee0> False\n",
      "<keras.layers.core.Dense object at 0x7fef36673310> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36673ca0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36673cd0> False\n",
      "<keras.layers.core.Dense object at 0x7fef3667c070> False\n",
      "<keras.layers.core.Dense object at 0x7fef3667c130> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3667cd60> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3667cd90> False\n",
      "<keras.layers.core.Dense object at 0x7fef36686070> False\n",
      "<keras.layers.core.Dense object at 0x7fef366861f0> False\n",
      "<keras.layers.core.Dense object at 0x7fef36686700> True\n",
      "<keras.layers.core.Dense object at 0x7fef3668e220> True\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.2929 - dense_20_loss: 0.1229 - dense_21_loss: 0.1700 - val_loss: 0.3368 - val_dense_20_loss: 0.1123 - val_dense_21_loss: 0.2245\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.2623 - dense_20_loss: 0.1025 - dense_21_loss: 0.1598 - val_loss: 0.2983 - val_dense_20_loss: 0.1031 - val_dense_21_loss: 0.1952\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.2542 - dense_20_loss: 0.0970 - dense_21_loss: 0.1572 - val_loss: 0.2907 - val_dense_20_loss: 0.0966 - val_dense_21_loss: 0.1941\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.2263 - dense_20_loss: 0.0919 - dense_21_loss: 0.1344 - val_loss: 0.2955 - val_dense_20_loss: 0.0807 - val_dense_21_loss: 0.2149\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.2118 - dense_20_loss: 0.0795 - dense_21_loss: 0.1322 - val_loss: 0.2511 - val_dense_20_loss: 0.0763 - val_dense_21_loss: 0.1748\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1940 - dense_20_loss: 0.0726 - dense_21_loss: 0.1214 - val_loss: 0.2261 - val_dense_20_loss: 0.0768 - val_dense_21_loss: 0.1493\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1910 - dense_20_loss: 0.0731 - dense_21_loss: 0.1178 - val_loss: 0.2407 - val_dense_20_loss: 0.0661 - val_dense_21_loss: 0.1746\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1723 - dense_20_loss: 0.0618 - dense_21_loss: 0.1106 - val_loss: 0.2068 - val_dense_20_loss: 0.0675 - val_dense_21_loss: 0.1393\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1740 - dense_20_loss: 0.0611 - dense_21_loss: 0.1129 - val_loss: 0.2215 - val_dense_20_loss: 0.0604 - val_dense_21_loss: 0.1612\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1659 - dense_20_loss: 0.0577 - dense_21_loss: 0.1082 - val_loss: 0.2157 - val_dense_20_loss: 0.0687 - val_dense_21_loss: 0.1470\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1604 - dense_20_loss: 0.0579 - dense_21_loss: 0.1025 - val_loss: 0.2042 - val_dense_20_loss: 0.0668 - val_dense_21_loss: 0.1374\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1581 - dense_20_loss: 0.0525 - dense_21_loss: 0.1055 - val_loss: 0.1870 - val_dense_20_loss: 0.0592 - val_dense_21_loss: 0.1277\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1468 - dense_20_loss: 0.0527 - dense_21_loss: 0.0941 - val_loss: 0.1834 - val_dense_20_loss: 0.0596 - val_dense_21_loss: 0.1238\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1322 - dense_20_loss: 0.0509 - dense_21_loss: 0.0813 - val_loss: 0.1877 - val_dense_20_loss: 0.0540 - val_dense_21_loss: 0.1337\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1355 - dense_20_loss: 0.0507 - dense_21_loss: 0.0847 - val_loss: 0.1827 - val_dense_20_loss: 0.0564 - val_dense_21_loss: 0.1263\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1282 - dense_20_loss: 0.0492 - dense_21_loss: 0.0790 - val_loss: 0.1562 - val_dense_20_loss: 0.0570 - val_dense_21_loss: 0.0992\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1361 - dense_20_loss: 0.0511 - dense_21_loss: 0.0850 - val_loss: 0.1892 - val_dense_20_loss: 0.0502 - val_dense_21_loss: 0.1390\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1309 - dense_20_loss: 0.0497 - dense_21_loss: 0.0812 - val_loss: 0.1761 - val_dense_20_loss: 0.0535 - val_dense_21_loss: 0.1226\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1230 - dense_20_loss: 0.0510 - dense_21_loss: 0.0720 - val_loss: 0.1601 - val_dense_20_loss: 0.0546 - val_dense_21_loss: 0.1055\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1093 - dense_20_loss: 0.0456 - dense_21_loss: 0.0637 - val_loss: 0.1859 - val_dense_20_loss: 0.0560 - val_dense_21_loss: 0.1299\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1102 - dense_20_loss: 0.0465 - dense_21_loss: 0.0637 - val_loss: 0.1374 - val_dense_20_loss: 0.0441 - val_dense_21_loss: 0.0933\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1118 - dense_20_loss: 0.0448 - dense_21_loss: 0.0669 - val_loss: 0.1727 - val_dense_20_loss: 0.0533 - val_dense_21_loss: 0.1193\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1030 - dense_20_loss: 0.0418 - dense_21_loss: 0.0612 - val_loss: 0.1253 - val_dense_20_loss: 0.0402 - val_dense_21_loss: 0.0852\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1120 - dense_20_loss: 0.0430 - dense_21_loss: 0.0690 - val_loss: 0.1296 - val_dense_20_loss: 0.0456 - val_dense_21_loss: 0.0840\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1235 - dense_20_loss: 0.0439 - dense_21_loss: 0.0796 - val_loss: 0.2520 - val_dense_20_loss: 0.0584 - val_dense_21_loss: 0.1936\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1364 - dense_20_loss: 0.0477 - dense_21_loss: 0.0887 - val_loss: 0.1426 - val_dense_20_loss: 0.0450 - val_dense_21_loss: 0.0975\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1126 - dense_20_loss: 0.0479 - dense_21_loss: 0.0647 - val_loss: 0.1428 - val_dense_20_loss: 0.0390 - val_dense_21_loss: 0.1038\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1091 - dense_20_loss: 0.0420 - dense_21_loss: 0.0671 - val_loss: 0.1267 - val_dense_20_loss: 0.0436 - val_dense_21_loss: 0.0831\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.1182 - dense_20_loss: 0.0410 - dense_21_loss: 0.0772 - val_loss: 0.1298 - val_dense_20_loss: 0.0394 - val_dense_21_loss: 0.0904\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1058 - dense_20_loss: 0.0394 - dense_21_loss: 0.0664 - val_loss: 0.1451 - val_dense_20_loss: 0.0372 - val_dense_21_loss: 0.1080\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0902 - dense_20_loss: 0.0360 - dense_21_loss: 0.0542 - val_loss: 0.1355 - val_dense_20_loss: 0.0361 - val_dense_21_loss: 0.0993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0906 - dense_20_loss: 0.0346 - dense_21_loss: 0.0560 - val_loss: 0.1423 - val_dense_20_loss: 0.0355 - val_dense_21_loss: 0.1068\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0932 - dense_20_loss: 0.0352 - dense_21_loss: 0.0580 - val_loss: 0.1396 - val_dense_20_loss: 0.0335 - val_dense_21_loss: 0.1061\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0946 - dense_20_loss: 0.0375 - dense_21_loss: 0.0571 - val_loss: 0.1293 - val_dense_20_loss: 0.0404 - val_dense_21_loss: 0.0889\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0928 - dense_20_loss: 0.0335 - dense_21_loss: 0.0593 - val_loss: 0.1190 - val_dense_20_loss: 0.0294 - val_dense_21_loss: 0.0896\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0925 - dense_20_loss: 0.0330 - dense_21_loss: 0.0595 - val_loss: 0.1195 - val_dense_20_loss: 0.0351 - val_dense_21_loss: 0.0844\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0822 - dense_20_loss: 0.0341 - dense_21_loss: 0.0481 - val_loss: 0.1235 - val_dense_20_loss: 0.0347 - val_dense_21_loss: 0.0888\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0829 - dense_20_loss: 0.0282 - dense_21_loss: 0.0547 - val_loss: 0.1140 - val_dense_20_loss: 0.0261 - val_dense_21_loss: 0.0879\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0790 - dense_20_loss: 0.0306 - dense_21_loss: 0.0484 - val_loss: 0.1160 - val_dense_20_loss: 0.0303 - val_dense_21_loss: 0.0857\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0736 - dense_20_loss: 0.0324 - dense_21_loss: 0.0412 - val_loss: 0.1123 - val_dense_20_loss: 0.0271 - val_dense_21_loss: 0.0852\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0921 - dense_20_loss: 0.0340 - dense_21_loss: 0.0581 - val_loss: 0.1274 - val_dense_20_loss: 0.0318 - val_dense_21_loss: 0.0956\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0894 - dense_20_loss: 0.0317 - dense_21_loss: 0.0577 - val_loss: 0.1044 - val_dense_20_loss: 0.0293 - val_dense_21_loss: 0.0751\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0847 - dense_20_loss: 0.0335 - dense_21_loss: 0.0512 - val_loss: 0.1126 - val_dense_20_loss: 0.0246 - val_dense_21_loss: 0.0880\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0851 - dense_20_loss: 0.0306 - dense_21_loss: 0.0545 - val_loss: 0.1022 - val_dense_20_loss: 0.0253 - val_dense_21_loss: 0.0769\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0722 - dense_20_loss: 0.0282 - dense_21_loss: 0.0440 - val_loss: 0.1206 - val_dense_20_loss: 0.0267 - val_dense_21_loss: 0.0939\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0766 - dense_20_loss: 0.0326 - dense_21_loss: 0.0439 - val_loss: 0.1258 - val_dense_20_loss: 0.0291 - val_dense_21_loss: 0.0968\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0713 - dense_20_loss: 0.0278 - dense_21_loss: 0.0434 - val_loss: 0.1195 - val_dense_20_loss: 0.0271 - val_dense_21_loss: 0.0924\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0803 - dense_20_loss: 0.0284 - dense_21_loss: 0.0519 - val_loss: 0.1179 - val_dense_20_loss: 0.0239 - val_dense_21_loss: 0.0940\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0729 - dense_20_loss: 0.0275 - dense_21_loss: 0.0454 - val_loss: 0.1414 - val_dense_20_loss: 0.0290 - val_dense_21_loss: 0.1124\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0752 - dense_20_loss: 0.0320 - dense_21_loss: 0.0432 - val_loss: 0.1402 - val_dense_20_loss: 0.0271 - val_dense_21_loss: 0.1131\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0776 - dense_20_loss: 0.0291 - dense_21_loss: 0.0485 - val_loss: 0.1231 - val_dense_20_loss: 0.0301 - val_dense_21_loss: 0.0930\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0747 - dense_20_loss: 0.0296 - dense_21_loss: 0.0451 - val_loss: 0.1229 - val_dense_20_loss: 0.0257 - val_dense_21_loss: 0.0972\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0735 - dense_20_loss: 0.0282 - dense_21_loss: 0.0453 - val_loss: 0.1147 - val_dense_20_loss: 0.0303 - val_dense_21_loss: 0.0844\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0819 - dense_20_loss: 0.0296 - dense_21_loss: 0.0523 - val_loss: 0.1372 - val_dense_20_loss: 0.0289 - val_dense_21_loss: 0.1083\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0765 - dense_20_loss: 0.0300 - dense_21_loss: 0.0464 - val_loss: 0.1146 - val_dense_20_loss: 0.0322 - val_dense_21_loss: 0.0824\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0808 - dense_20_loss: 0.0290 - dense_21_loss: 0.0518 - val_loss: 0.1200 - val_dense_20_loss: 0.0263 - val_dense_21_loss: 0.0936\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0696 - dense_20_loss: 0.0303 - dense_21_loss: 0.0394 - val_loss: 0.1113 - val_dense_20_loss: 0.0237 - val_dense_21_loss: 0.0876\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0675 - dense_20_loss: 0.0278 - dense_21_loss: 0.0397 - val_loss: 0.1128 - val_dense_20_loss: 0.0275 - val_dense_21_loss: 0.0853\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0701 - dense_20_loss: 0.0282 - dense_21_loss: 0.0419 - val_loss: 0.1154 - val_dense_20_loss: 0.0259 - val_dense_21_loss: 0.0895\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0675 - dense_20_loss: 0.0256 - dense_21_loss: 0.0419 - val_loss: 0.0993 - val_dense_20_loss: 0.0230 - val_dense_21_loss: 0.0763\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0733 - dense_20_loss: 0.0263 - dense_21_loss: 0.0471 - val_loss: 0.2009 - val_dense_20_loss: 0.0391 - val_dense_21_loss: 0.1618\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0674 - dense_20_loss: 0.0274 - dense_21_loss: 0.0400 - val_loss: 0.0983 - val_dense_20_loss: 0.0271 - val_dense_21_loss: 0.0712\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0666 - dense_20_loss: 0.0287 - dense_21_loss: 0.0379 - val_loss: 0.1236 - val_dense_20_loss: 0.0324 - val_dense_21_loss: 0.0912\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0746 - dense_20_loss: 0.0271 - dense_21_loss: 0.0475 - val_loss: 0.1095 - val_dense_20_loss: 0.0306 - val_dense_21_loss: 0.0790\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0646 - dense_20_loss: 0.0267 - dense_21_loss: 0.0379 - val_loss: 0.1183 - val_dense_20_loss: 0.0301 - val_dense_21_loss: 0.0882\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0676 - dense_20_loss: 0.0294 - dense_21_loss: 0.0383 - val_loss: 0.1096 - val_dense_20_loss: 0.0289 - val_dense_21_loss: 0.0807\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0715 - dense_20_loss: 0.0296 - dense_21_loss: 0.0419 - val_loss: 0.1163 - val_dense_20_loss: 0.0384 - val_dense_21_loss: 0.0779\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0743 - dense_20_loss: 0.0280 - dense_21_loss: 0.0463 - val_loss: 0.1176 - val_dense_20_loss: 0.0317 - val_dense_21_loss: 0.0859\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0759 - dense_20_loss: 0.0271 - dense_21_loss: 0.0488 - val_loss: 0.1144 - val_dense_20_loss: 0.0276 - val_dense_21_loss: 0.0868\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0667 - dense_20_loss: 0.0289 - dense_21_loss: 0.0379 - val_loss: 0.1093 - val_dense_20_loss: 0.0275 - val_dense_21_loss: 0.0818\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0674 - dense_20_loss: 0.0293 - dense_21_loss: 0.0381 - val_loss: 0.1155 - val_dense_20_loss: 0.0345 - val_dense_21_loss: 0.0811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0632 - dense_20_loss: 0.0292 - dense_21_loss: 0.0340 - val_loss: 0.1089 - val_dense_20_loss: 0.0293 - val_dense_21_loss: 0.0796\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0555 - dense_20_loss: 0.0237 - dense_21_loss: 0.0318 - val_loss: 0.1029 - val_dense_20_loss: 0.0299 - val_dense_21_loss: 0.0729\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0573 - dense_20_loss: 0.0226 - dense_21_loss: 0.0347 - val_loss: 0.1218 - val_dense_20_loss: 0.0291 - val_dense_21_loss: 0.0927\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0608 - dense_20_loss: 0.0240 - dense_21_loss: 0.0368 - val_loss: 0.1188 - val_dense_20_loss: 0.0303 - val_dense_21_loss: 0.0885\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0689 - dense_20_loss: 0.0261 - dense_21_loss: 0.0428 - val_loss: 0.1186 - val_dense_20_loss: 0.0273 - val_dense_21_loss: 0.0913\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0576 - dense_20_loss: 0.0240 - dense_21_loss: 0.0336 - val_loss: 0.1166 - val_dense_20_loss: 0.0273 - val_dense_21_loss: 0.0892\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0592 - dense_20_loss: 0.0242 - dense_21_loss: 0.0350 - val_loss: 0.1230 - val_dense_20_loss: 0.0229 - val_dense_21_loss: 0.1002\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 00:28:38.548353: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model/trained/model1.model/assets\n",
      "*********** Model 2 ************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 00:28:39.985536: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 186278400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 28s 39ms/step - loss: 0.3981 - dense_31_loss: 0.1691 - dense_32_loss: 0.2290 - val_loss: 0.3210 - val_dense_31_loss: 0.1275 - val_dense_32_loss: 0.1934\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.2699 - dense_31_loss: 0.1094 - dense_32_loss: 0.1605 - val_loss: 0.3084 - val_dense_31_loss: 0.1224 - val_dense_32_loss: 0.1860\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.2364 - dense_31_loss: 0.0964 - dense_32_loss: 0.1400 - val_loss: 0.3446 - val_dense_31_loss: 0.1099 - val_dense_32_loss: 0.2347\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.2212 - dense_31_loss: 0.0898 - dense_32_loss: 0.1314 - val_loss: 0.3206 - val_dense_31_loss: 0.1248 - val_dense_32_loss: 0.1957\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.2097 - dense_31_loss: 0.0864 - dense_32_loss: 0.1233 - val_loss: 0.2609 - val_dense_31_loss: 0.1045 - val_dense_32_loss: 0.1563\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1994 - dense_31_loss: 0.0831 - dense_32_loss: 0.1163 - val_loss: 0.2325 - val_dense_31_loss: 0.0876 - val_dense_32_loss: 0.1449\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1950 - dense_31_loss: 0.0808 - dense_32_loss: 0.1142 - val_loss: 0.2484 - val_dense_31_loss: 0.1103 - val_dense_32_loss: 0.1381\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.1893 - dense_31_loss: 0.0799 - dense_32_loss: 0.1094 - val_loss: 0.2524 - val_dense_31_loss: 0.1020 - val_dense_32_loss: 0.1504\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1836 - dense_31_loss: 0.0775 - dense_32_loss: 0.1061 - val_loss: 0.2604 - val_dense_31_loss: 0.1128 - val_dense_32_loss: 0.1476\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1790 - dense_31_loss: 0.0764 - dense_32_loss: 0.1026 - val_loss: 0.2671 - val_dense_31_loss: 0.1002 - val_dense_32_loss: 0.1669\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1759 - dense_31_loss: 0.0746 - dense_32_loss: 0.1013 - val_loss: 0.2258 - val_dense_31_loss: 0.0955 - val_dense_32_loss: 0.1303\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1769 - dense_31_loss: 0.0748 - dense_32_loss: 0.1021 - val_loss: 0.2391 - val_dense_31_loss: 0.0964 - val_dense_32_loss: 0.1426\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1721 - dense_31_loss: 0.0740 - dense_32_loss: 0.0981 - val_loss: 0.2684 - val_dense_31_loss: 0.0926 - val_dense_32_loss: 0.1757\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1669 - dense_31_loss: 0.0720 - dense_32_loss: 0.0949 - val_loss: 0.2609 - val_dense_31_loss: 0.1143 - val_dense_32_loss: 0.1465\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1694 - dense_31_loss: 0.0725 - dense_32_loss: 0.0969 - val_loss: 0.2319 - val_dense_31_loss: 0.0953 - val_dense_32_loss: 0.1366\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1660 - dense_31_loss: 0.0714 - dense_32_loss: 0.0946 - val_loss: 0.2202 - val_dense_31_loss: 0.0891 - val_dense_32_loss: 0.1312\n",
      "Epoch 17/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1643 - dense_31_loss: 0.0701 - dense_32_loss: 0.0941 - val_loss: 0.2413 - val_dense_31_loss: 0.1034 - val_dense_32_loss: 0.1379\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1620 - dense_31_loss: 0.0706 - dense_32_loss: 0.0915 - val_loss: 0.2123 - val_dense_31_loss: 0.0961 - val_dense_32_loss: 0.1162\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1636 - dense_31_loss: 0.0705 - dense_32_loss: 0.0932 - val_loss: 0.1985 - val_dense_31_loss: 0.0904 - val_dense_32_loss: 0.1081\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 29s 41ms/step - loss: 0.1596 - dense_31_loss: 0.0702 - dense_32_loss: 0.0894 - val_loss: 0.2593 - val_dense_31_loss: 0.0912 - val_dense_32_loss: 0.1681\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1590 - dense_31_loss: 0.0687 - dense_32_loss: 0.0903 - val_loss: 0.1968 - val_dense_31_loss: 0.0845 - val_dense_32_loss: 0.1122\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1614 - dense_31_loss: 0.0700 - dense_32_loss: 0.0913 - val_loss: 0.2243 - val_dense_31_loss: 0.0945 - val_dense_32_loss: 0.1298\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1569 - dense_31_loss: 0.0682 - dense_32_loss: 0.0886 - val_loss: 0.1947 - val_dense_31_loss: 0.0897 - val_dense_32_loss: 0.1050\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1568 - dense_31_loss: 0.0677 - dense_32_loss: 0.0891 - val_loss: 0.1984 - val_dense_31_loss: 0.0876 - val_dense_32_loss: 0.1108\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1500 - dense_31_loss: 0.0658 - dense_32_loss: 0.0842 - val_loss: 0.1959 - val_dense_31_loss: 0.0799 - val_dense_32_loss: 0.1161\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1555 - dense_31_loss: 0.0677 - dense_32_loss: 0.0878 - val_loss: 0.2047 - val_dense_31_loss: 0.0920 - val_dense_32_loss: 0.1127\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1523 - dense_31_loss: 0.0660 - dense_32_loss: 0.0862 - val_loss: 0.1913 - val_dense_31_loss: 0.0888 - val_dense_32_loss: 0.1025\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1503 - dense_31_loss: 0.0654 - dense_32_loss: 0.0849 - val_loss: 0.1979 - val_dense_31_loss: 0.0899 - val_dense_32_loss: 0.1080\n",
      "Epoch 29/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1510 - dense_31_loss: 0.0655 - dense_32_loss: 0.0854 - val_loss: 0.2219 - val_dense_31_loss: 0.0942 - val_dense_32_loss: 0.1277\n",
      "Epoch 30/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1531 - dense_31_loss: 0.0660 - dense_32_loss: 0.0871 - val_loss: 0.1945 - val_dense_31_loss: 0.0802 - val_dense_32_loss: 0.1143\n",
      "Epoch 31/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1503 - dense_31_loss: 0.0647 - dense_32_loss: 0.0856 - val_loss: 0.1821 - val_dense_31_loss: 0.0836 - val_dense_32_loss: 0.0985\n",
      "Epoch 32/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1473 - dense_31_loss: 0.0642 - dense_32_loss: 0.0831 - val_loss: 0.2008 - val_dense_31_loss: 0.0855 - val_dense_32_loss: 0.1153\n",
      "Epoch 33/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1471 - dense_31_loss: 0.0644 - dense_32_loss: 0.0827 - val_loss: 0.1862 - val_dense_31_loss: 0.0843 - val_dense_32_loss: 0.1019\n",
      "Epoch 34/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1468 - dense_31_loss: 0.0645 - dense_32_loss: 0.0823 - val_loss: 0.1823 - val_dense_31_loss: 0.0780 - val_dense_32_loss: 0.1043\n",
      "Epoch 35/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1510 - dense_31_loss: 0.0647 - dense_32_loss: 0.0863 - val_loss: 0.1958 - val_dense_31_loss: 0.0838 - val_dense_32_loss: 0.1120\n",
      "Epoch 36/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1476 - dense_31_loss: 0.0631 - dense_32_loss: 0.0845 - val_loss: 0.1902 - val_dense_31_loss: 0.0828 - val_dense_32_loss: 0.1074\n",
      "Epoch 37/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1511 - dense_31_loss: 0.0647 - dense_32_loss: 0.0864 - val_loss: 0.1905 - val_dense_31_loss: 0.0847 - val_dense_32_loss: 0.1058\n",
      "Epoch 38/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1513 - dense_31_loss: 0.0640 - dense_32_loss: 0.0873 - val_loss: 0.1885 - val_dense_31_loss: 0.0830 - val_dense_32_loss: 0.1055\n",
      "Epoch 39/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1466 - dense_31_loss: 0.0635 - dense_32_loss: 0.0831 - val_loss: 0.1899 - val_dense_31_loss: 0.0843 - val_dense_32_loss: 0.1055\n",
      "Epoch 40/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1529 - dense_31_loss: 0.0651 - dense_32_loss: 0.0879 - val_loss: 0.2038 - val_dense_31_loss: 0.0832 - val_dense_32_loss: 0.1206\n",
      "Epoch 41/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1490 - dense_31_loss: 0.0641 - dense_32_loss: 0.0848 - val_loss: 0.2041 - val_dense_31_loss: 0.0827 - val_dense_32_loss: 0.1214\n",
      "Epoch 42/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1433 - dense_31_loss: 0.0626 - dense_32_loss: 0.0806 - val_loss: 0.1812 - val_dense_31_loss: 0.0741 - val_dense_32_loss: 0.1071\n",
      "Epoch 43/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1409 - dense_31_loss: 0.0616 - dense_32_loss: 0.0793 - val_loss: 0.1769 - val_dense_31_loss: 0.0794 - val_dense_32_loss: 0.0976\n",
      "Epoch 44/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1444 - dense_31_loss: 0.0631 - dense_32_loss: 0.0813 - val_loss: 0.1970 - val_dense_31_loss: 0.0839 - val_dense_32_loss: 0.1131\n",
      "Epoch 45/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1447 - dense_31_loss: 0.0632 - dense_32_loss: 0.0814 - val_loss: 0.1835 - val_dense_31_loss: 0.0799 - val_dense_32_loss: 0.1036\n",
      "Epoch 46/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1461 - dense_31_loss: 0.0630 - dense_32_loss: 0.0831 - val_loss: 0.2138 - val_dense_31_loss: 0.0872 - val_dense_32_loss: 0.1266\n",
      "Epoch 47/200\n",
      "690/690 [==============================] - 30s 43ms/step - loss: 0.1461 - dense_31_loss: 0.0639 - dense_32_loss: 0.0822 - val_loss: 0.1932 - val_dense_31_loss: 0.0837 - val_dense_32_loss: 0.1095\n",
      "Epoch 48/200\n",
      "690/690 [==============================] - 29s 43ms/step - loss: 0.1430 - dense_31_loss: 0.0623 - dense_32_loss: 0.0807 - val_loss: 0.2104 - val_dense_31_loss: 0.0887 - val_dense_32_loss: 0.1217\n",
      "Epoch 49/200\n",
      "690/690 [==============================] - 30s 43ms/step - loss: 0.1432 - dense_31_loss: 0.0616 - dense_32_loss: 0.0816 - val_loss: 0.1784 - val_dense_31_loss: 0.0788 - val_dense_32_loss: 0.0995\n",
      "Epoch 50/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1434 - dense_31_loss: 0.0623 - dense_32_loss: 0.0811 - val_loss: 0.1913 - val_dense_31_loss: 0.0877 - val_dense_32_loss: 0.1035\n",
      "Epoch 51/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1448 - dense_31_loss: 0.0630 - dense_32_loss: 0.0818 - val_loss: 0.1794 - val_dense_31_loss: 0.0688 - val_dense_32_loss: 0.1106\n",
      "Epoch 52/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1403 - dense_31_loss: 0.0608 - dense_32_loss: 0.0795 - val_loss: 0.1735 - val_dense_31_loss: 0.0758 - val_dense_32_loss: 0.0977\n",
      "Epoch 53/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1502 - dense_31_loss: 0.0643 - dense_32_loss: 0.0859 - val_loss: 0.2080 - val_dense_31_loss: 0.0885 - val_dense_32_loss: 0.1195\n",
      "Epoch 54/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1414 - dense_31_loss: 0.0608 - dense_32_loss: 0.0806 - val_loss: 0.1706 - val_dense_31_loss: 0.0794 - val_dense_32_loss: 0.0912\n",
      "Epoch 55/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1386 - dense_31_loss: 0.0604 - dense_32_loss: 0.0782 - val_loss: 0.1787 - val_dense_31_loss: 0.0827 - val_dense_32_loss: 0.0959\n",
      "Epoch 56/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1387 - dense_31_loss: 0.0612 - dense_32_loss: 0.0775 - val_loss: 0.1604 - val_dense_31_loss: 0.0671 - val_dense_32_loss: 0.0933\n",
      "Epoch 57/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1459 - dense_31_loss: 0.0631 - dense_32_loss: 0.0828 - val_loss: 0.1655 - val_dense_31_loss: 0.0720 - val_dense_32_loss: 0.0935\n",
      "Epoch 58/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1430 - dense_31_loss: 0.0618 - dense_32_loss: 0.0812 - val_loss: 0.1751 - val_dense_31_loss: 0.0740 - val_dense_32_loss: 0.1011\n",
      "Epoch 59/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.1426 - dense_31_loss: 0.0614 - dense_32_loss: 0.0812 - val_loss: 0.1859 - val_dense_31_loss: 0.0769 - val_dense_32_loss: 0.1091\n",
      "Epoch 60/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.1403 - dense_31_loss: 0.0608 - dense_32_loss: 0.0795 - val_loss: 0.1714 - val_dense_31_loss: 0.0763 - val_dense_32_loss: 0.0950\n",
      "Epoch 61/200\n",
      "690/690 [==============================] - 28s 40ms/step - loss: 0.1397 - dense_31_loss: 0.0612 - dense_32_loss: 0.0784 - val_loss: 0.1833 - val_dense_31_loss: 0.0798 - val_dense_32_loss: 0.1035\n",
      "Epoch 62/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1437 - dense_31_loss: 0.0619 - dense_32_loss: 0.0818 - val_loss: 0.1831 - val_dense_31_loss: 0.0830 - val_dense_32_loss: 0.1000\n",
      "Epoch 63/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1443 - dense_31_loss: 0.0619 - dense_32_loss: 0.0824 - val_loss: 0.1708 - val_dense_31_loss: 0.0806 - val_dense_32_loss: 0.0902\n",
      "Epoch 64/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1392 - dense_31_loss: 0.0610 - dense_32_loss: 0.0782 - val_loss: 0.1627 - val_dense_31_loss: 0.0746 - val_dense_32_loss: 0.0881\n",
      "Epoch 65/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1421 - dense_31_loss: 0.0616 - dense_32_loss: 0.0805 - val_loss: 0.1660 - val_dense_31_loss: 0.0762 - val_dense_32_loss: 0.0898\n",
      "Epoch 66/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1451 - dense_31_loss: 0.0628 - dense_32_loss: 0.0822 - val_loss: 0.1763 - val_dense_31_loss: 0.0862 - val_dense_32_loss: 0.0901\n",
      "Epoch 67/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1396 - dense_31_loss: 0.0617 - dense_32_loss: 0.0779 - val_loss: 0.1672 - val_dense_31_loss: 0.0742 - val_dense_32_loss: 0.0930\n",
      "Epoch 68/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1369 - dense_31_loss: 0.0605 - dense_32_loss: 0.0764 - val_loss: 0.1852 - val_dense_31_loss: 0.0750 - val_dense_32_loss: 0.1103\n",
      "Epoch 69/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.1446 - dense_31_loss: 0.0618 - dense_32_loss: 0.0829 - val_loss: 0.1881 - val_dense_31_loss: 0.0774 - val_dense_32_loss: 0.1107\n",
      "Epoch 70/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1412 - dense_31_loss: 0.0610 - dense_32_loss: 0.0802 - val_loss: 0.1619 - val_dense_31_loss: 0.0722 - val_dense_32_loss: 0.0896\n",
      "Epoch 71/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1418 - dense_31_loss: 0.0610 - dense_32_loss: 0.0808 - val_loss: 0.2003 - val_dense_31_loss: 0.0833 - val_dense_32_loss: 0.1170\n",
      "Epoch 72/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.1408 - dense_31_loss: 0.0598 - dense_32_loss: 0.0809 - val_loss: 0.1642 - val_dense_31_loss: 0.0705 - val_dense_32_loss: 0.0937\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 01:01:53.673802: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 186278400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fef3651b0a0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef360b2f10> False\n",
      "<keras.layers.core.Dropout object at 0x7fef360b8580> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef360b85e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef360b8610> False\n",
      "<keras.layers.core.Dropout object at 0x7fef360b8fa0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef360800d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef360803d0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36080c10> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef360804f0> False\n",
      "<keras.layers.core.Flatten object at 0x7fef36087160> False\n",
      "<keras.layers.core.Dense object at 0x7fef36087370> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36087a60> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fef36087a90> False\n",
      "<keras.layers.merge.Concatenate object at 0x7fef3608f070> False\n",
      "<keras.layers.core.Dense object at 0x7fef3608f100> False\n",
      "<keras.layers.core.Dense object at 0x7fef3608f370> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3608ff10> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3608ff40> False\n",
      "<keras.layers.core.Dense object at 0x7fef3601a190> False\n",
      "<keras.layers.core.Dense object at 0x7fef3601a310> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3601aeb0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef3601aee0> False\n",
      "<keras.layers.core.Dense object at 0x7fef36026130> False\n",
      "<keras.layers.core.Dense object at 0x7fef360262b0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36026e50> False\n",
      "<keras.layers.core.Dropout object at 0x7fef36026e80> False\n",
      "<keras.layers.core.Dense object at 0x7fef3602e0d0> False\n",
      "<keras.layers.core.Dense object at 0x7fef3602e250> False\n",
      "<keras.layers.core.Dense object at 0x7fef3602e730> True\n",
      "<keras.layers.core.Dense object at 0x7fef360371f0> True\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.2834 - dense_31_loss: 0.1142 - dense_32_loss: 0.1693 - val_loss: 0.3323 - val_dense_31_loss: 0.1432 - val_dense_32_loss: 0.1891\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.2422 - dense_31_loss: 0.0951 - dense_32_loss: 0.1471 - val_loss: 0.3179 - val_dense_31_loss: 0.1279 - val_dense_32_loss: 0.1899\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1958 - dense_31_loss: 0.0784 - dense_32_loss: 0.1174 - val_loss: 0.2809 - val_dense_31_loss: 0.1171 - val_dense_32_loss: 0.1638\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1757 - dense_31_loss: 0.0749 - dense_32_loss: 0.1008 - val_loss: 0.2628 - val_dense_31_loss: 0.1150 - val_dense_32_loss: 0.1478\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1740 - dense_31_loss: 0.0662 - dense_32_loss: 0.1077 - val_loss: 0.2532 - val_dense_31_loss: 0.1145 - val_dense_32_loss: 0.1386\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1673 - dense_31_loss: 0.0657 - dense_32_loss: 0.1017 - val_loss: 0.2825 - val_dense_31_loss: 0.1184 - val_dense_32_loss: 0.1641\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1556 - dense_31_loss: 0.0627 - dense_32_loss: 0.0930 - val_loss: 0.2616 - val_dense_31_loss: 0.1290 - val_dense_32_loss: 0.1326\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1418 - dense_31_loss: 0.0578 - dense_32_loss: 0.0840 - val_loss: 0.2451 - val_dense_31_loss: 0.1194 - val_dense_32_loss: 0.1257\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1368 - dense_31_loss: 0.0568 - dense_32_loss: 0.0800 - val_loss: 0.2643 - val_dense_31_loss: 0.1246 - val_dense_32_loss: 0.1397\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1343 - dense_31_loss: 0.0526 - dense_32_loss: 0.0817 - val_loss: 0.2337 - val_dense_31_loss: 0.1081 - val_dense_32_loss: 0.1255\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1324 - dense_31_loss: 0.0553 - dense_32_loss: 0.0771 - val_loss: 0.2427 - val_dense_31_loss: 0.1129 - val_dense_32_loss: 0.1299\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1287 - dense_31_loss: 0.0511 - dense_32_loss: 0.0776 - val_loss: 0.2002 - val_dense_31_loss: 0.0951 - val_dense_32_loss: 0.1050\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1223 - dense_31_loss: 0.0505 - dense_32_loss: 0.0718 - val_loss: 0.2183 - val_dense_31_loss: 0.0965 - val_dense_32_loss: 0.1218\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.1277 - dense_31_loss: 0.0546 - dense_32_loss: 0.0730 - val_loss: 0.2156 - val_dense_31_loss: 0.0970 - val_dense_32_loss: 0.1186\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1356 - dense_31_loss: 0.0544 - dense_32_loss: 0.0812 - val_loss: 0.2297 - val_dense_31_loss: 0.0884 - val_dense_32_loss: 0.1414\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1273 - dense_31_loss: 0.0522 - dense_32_loss: 0.0751 - val_loss: 0.2280 - val_dense_31_loss: 0.0845 - val_dense_32_loss: 0.1435\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1236 - dense_31_loss: 0.0481 - dense_32_loss: 0.0755 - val_loss: 0.2291 - val_dense_31_loss: 0.0925 - val_dense_32_loss: 0.1367\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1129 - dense_31_loss: 0.0453 - dense_32_loss: 0.0676 - val_loss: 0.2269 - val_dense_31_loss: 0.1004 - val_dense_32_loss: 0.1265\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1109 - dense_31_loss: 0.0463 - dense_32_loss: 0.0647 - val_loss: 0.2102 - val_dense_31_loss: 0.0950 - val_dense_32_loss: 0.1152\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1067 - dense_31_loss: 0.0459 - dense_32_loss: 0.0608 - val_loss: 0.2056 - val_dense_31_loss: 0.0930 - val_dense_32_loss: 0.1126\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1115 - dense_31_loss: 0.0482 - dense_32_loss: 0.0633 - val_loss: 0.2159 - val_dense_31_loss: 0.0993 - val_dense_32_loss: 0.1165\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1030 - dense_31_loss: 0.0447 - dense_32_loss: 0.0584 - val_loss: 0.1884 - val_dense_31_loss: 0.0888 - val_dense_32_loss: 0.0996\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1150 - dense_31_loss: 0.0461 - dense_32_loss: 0.0688 - val_loss: 0.2083 - val_dense_31_loss: 0.1021 - val_dense_32_loss: 0.1062\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1080 - dense_31_loss: 0.0458 - dense_32_loss: 0.0623 - val_loss: 0.1961 - val_dense_31_loss: 0.0897 - val_dense_32_loss: 0.1065\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0983 - dense_31_loss: 0.0418 - dense_32_loss: 0.0565 - val_loss: 0.1928 - val_dense_31_loss: 0.0826 - val_dense_32_loss: 0.1102\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1247 - dense_31_loss: 0.0523 - dense_32_loss: 0.0724 - val_loss: 0.2229 - val_dense_31_loss: 0.0992 - val_dense_32_loss: 0.1237\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1112 - dense_31_loss: 0.0437 - dense_32_loss: 0.0675 - val_loss: 0.2075 - val_dense_31_loss: 0.0959 - val_dense_32_loss: 0.1116\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1064 - dense_31_loss: 0.0424 - dense_32_loss: 0.0640 - val_loss: 0.2241 - val_dense_31_loss: 0.0963 - val_dense_32_loss: 0.1278\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1085 - dense_31_loss: 0.0466 - dense_32_loss: 0.0619 - val_loss: 0.2040 - val_dense_31_loss: 0.0885 - val_dense_32_loss: 0.1156\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1066 - dense_31_loss: 0.0484 - dense_32_loss: 0.0582 - val_loss: 0.2008 - val_dense_31_loss: 0.0817 - val_dense_32_loss: 0.1191\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0943 - dense_31_loss: 0.0445 - dense_32_loss: 0.0499 - val_loss: 0.1851 - val_dense_31_loss: 0.0857 - val_dense_32_loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0961 - dense_31_loss: 0.0439 - dense_32_loss: 0.0522 - val_loss: 0.1837 - val_dense_31_loss: 0.0765 - val_dense_32_loss: 0.1072\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0833 - dense_31_loss: 0.0407 - dense_32_loss: 0.0426 - val_loss: 0.1820 - val_dense_31_loss: 0.0789 - val_dense_32_loss: 0.1031\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0823 - dense_31_loss: 0.0415 - dense_32_loss: 0.0408 - val_loss: 0.2005 - val_dense_31_loss: 0.0850 - val_dense_32_loss: 0.1155\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0793 - dense_31_loss: 0.0417 - dense_32_loss: 0.0376 - val_loss: 0.1731 - val_dense_31_loss: 0.0777 - val_dense_32_loss: 0.0954\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0897 - dense_31_loss: 0.0421 - dense_32_loss: 0.0477 - val_loss: 0.1573 - val_dense_31_loss: 0.0761 - val_dense_32_loss: 0.0812\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0849 - dense_31_loss: 0.0435 - dense_32_loss: 0.0414 - val_loss: 0.1732 - val_dense_31_loss: 0.0822 - val_dense_32_loss: 0.0910\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0810 - dense_31_loss: 0.0392 - dense_32_loss: 0.0418 - val_loss: 0.1743 - val_dense_31_loss: 0.0798 - val_dense_32_loss: 0.0945\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0769 - dense_31_loss: 0.0395 - dense_32_loss: 0.0374 - val_loss: 0.1863 - val_dense_31_loss: 0.0903 - val_dense_32_loss: 0.0959\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0740 - dense_31_loss: 0.0377 - dense_32_loss: 0.0363 - val_loss: 0.1504 - val_dense_31_loss: 0.0767 - val_dense_32_loss: 0.0737\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0778 - dense_31_loss: 0.0380 - dense_32_loss: 0.0397 - val_loss: 0.1472 - val_dense_31_loss: 0.0791 - val_dense_32_loss: 0.0680\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0718 - dense_31_loss: 0.0380 - dense_32_loss: 0.0339 - val_loss: 0.1521 - val_dense_31_loss: 0.0819 - val_dense_32_loss: 0.0702\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0754 - dense_31_loss: 0.0408 - dense_32_loss: 0.0346 - val_loss: 0.1599 - val_dense_31_loss: 0.0803 - val_dense_32_loss: 0.0796\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0803 - dense_31_loss: 0.0429 - dense_32_loss: 0.0374 - val_loss: 0.1741 - val_dense_31_loss: 0.0874 - val_dense_32_loss: 0.0867\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0864 - dense_31_loss: 0.0445 - dense_32_loss: 0.0419 - val_loss: 0.1824 - val_dense_31_loss: 0.0831 - val_dense_32_loss: 0.0993\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0759 - dense_31_loss: 0.0405 - dense_32_loss: 0.0354 - val_loss: 0.1671 - val_dense_31_loss: 0.0876 - val_dense_32_loss: 0.0795\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0819 - dense_31_loss: 0.0435 - dense_32_loss: 0.0384 - val_loss: 0.2075 - val_dense_31_loss: 0.0741 - val_dense_32_loss: 0.1335\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0897 - dense_31_loss: 0.0407 - dense_32_loss: 0.0490 - val_loss: 0.1543 - val_dense_31_loss: 0.0753 - val_dense_32_loss: 0.0790\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0728 - dense_31_loss: 0.0371 - dense_32_loss: 0.0357 - val_loss: 0.1494 - val_dense_31_loss: 0.0735 - val_dense_32_loss: 0.0759\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0751 - dense_31_loss: 0.0415 - dense_32_loss: 0.0335 - val_loss: 0.1501 - val_dense_31_loss: 0.0794 - val_dense_32_loss: 0.0706\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0697 - dense_31_loss: 0.0373 - dense_32_loss: 0.0325 - val_loss: 0.1479 - val_dense_31_loss: 0.0737 - val_dense_32_loss: 0.0742\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0680 - dense_31_loss: 0.0388 - dense_32_loss: 0.0293 - val_loss: 0.1644 - val_dense_31_loss: 0.0855 - val_dense_32_loss: 0.0789\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0723 - dense_31_loss: 0.0381 - dense_32_loss: 0.0342 - val_loss: 0.1620 - val_dense_31_loss: 0.0824 - val_dense_32_loss: 0.0796\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0694 - dense_31_loss: 0.0406 - dense_32_loss: 0.0288 - val_loss: 0.1644 - val_dense_31_loss: 0.0826 - val_dense_32_loss: 0.0818\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0688 - dense_31_loss: 0.0372 - dense_32_loss: 0.0316 - val_loss: 0.1666 - val_dense_31_loss: 0.0814 - val_dense_32_loss: 0.0852\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0670 - dense_31_loss: 0.0367 - dense_32_loss: 0.0303 - val_loss: 0.1558 - val_dense_31_loss: 0.0774 - val_dense_32_loss: 0.0784\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0670 - dense_31_loss: 0.0343 - dense_32_loss: 0.0327 - val_loss: 0.1393 - val_dense_31_loss: 0.0660 - val_dense_32_loss: 0.0733\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0864 - dense_31_loss: 0.0402 - dense_32_loss: 0.0462 - val_loss: 0.1578 - val_dense_31_loss: 0.0813 - val_dense_32_loss: 0.0765\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0828 - dense_31_loss: 0.0421 - dense_32_loss: 0.0406 - val_loss: 0.1617 - val_dense_31_loss: 0.0729 - val_dense_32_loss: 0.0888\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0839 - dense_31_loss: 0.0388 - dense_32_loss: 0.0450 - val_loss: 0.1500 - val_dense_31_loss: 0.0667 - val_dense_32_loss: 0.0833\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0774 - dense_31_loss: 0.0390 - dense_32_loss: 0.0385 - val_loss: 0.1417 - val_dense_31_loss: 0.0778 - val_dense_32_loss: 0.0639\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0743 - dense_31_loss: 0.0378 - dense_32_loss: 0.0365 - val_loss: 0.1381 - val_dense_31_loss: 0.0722 - val_dense_32_loss: 0.0659\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0677 - dense_31_loss: 0.0368 - dense_32_loss: 0.0309 - val_loss: 0.1480 - val_dense_31_loss: 0.0714 - val_dense_32_loss: 0.0765\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.0759 - dense_31_loss: 0.0358 - dense_32_loss: 0.0400 - val_loss: 0.1628 - val_dense_31_loss: 0.0749 - val_dense_32_loss: 0.0878\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0709 - dense_31_loss: 0.0378 - dense_32_loss: 0.0332 - val_loss: 0.1503 - val_dense_31_loss: 0.0713 - val_dense_32_loss: 0.0790\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0636 - dense_31_loss: 0.0368 - dense_32_loss: 0.0268 - val_loss: 0.1414 - val_dense_31_loss: 0.0613 - val_dense_32_loss: 0.0801\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0705 - dense_31_loss: 0.0377 - dense_32_loss: 0.0328 - val_loss: 0.1617 - val_dense_31_loss: 0.0630 - val_dense_32_loss: 0.0987\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0726 - dense_31_loss: 0.0363 - dense_32_loss: 0.0363 - val_loss: 0.1563 - val_dense_31_loss: 0.0783 - val_dense_32_loss: 0.0780\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0765 - dense_31_loss: 0.0360 - dense_32_loss: 0.0404 - val_loss: 0.1542 - val_dense_31_loss: 0.0753 - val_dense_32_loss: 0.0788\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0720 - dense_31_loss: 0.0337 - dense_32_loss: 0.0383 - val_loss: 0.1472 - val_dense_31_loss: 0.0689 - val_dense_32_loss: 0.0783\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0668 - dense_31_loss: 0.0339 - dense_32_loss: 0.0329 - val_loss: 0.1219 - val_dense_31_loss: 0.0581 - val_dense_32_loss: 0.0638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0787 - dense_31_loss: 0.0337 - dense_32_loss: 0.0450 - val_loss: 0.1381 - val_dense_31_loss: 0.0671 - val_dense_32_loss: 0.0710\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0696 - dense_31_loss: 0.0357 - dense_32_loss: 0.0339 - val_loss: 0.1422 - val_dense_31_loss: 0.0658 - val_dense_32_loss: 0.0764\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0596 - dense_31_loss: 0.0327 - dense_32_loss: 0.0268 - val_loss: 0.1418 - val_dense_31_loss: 0.0735 - val_dense_32_loss: 0.0683\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0588 - dense_31_loss: 0.0327 - dense_32_loss: 0.0262 - val_loss: 0.1381 - val_dense_31_loss: 0.0649 - val_dense_32_loss: 0.0731\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0625 - dense_31_loss: 0.0342 - dense_32_loss: 0.0284 - val_loss: 0.1380 - val_dense_31_loss: 0.0716 - val_dense_32_loss: 0.0664\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0715 - dense_31_loss: 0.0363 - dense_32_loss: 0.0352 - val_loss: 0.1821 - val_dense_31_loss: 0.0694 - val_dense_32_loss: 0.1127\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0717 - dense_31_loss: 0.0361 - dense_32_loss: 0.0356 - val_loss: 0.1581 - val_dense_31_loss: 0.0727 - val_dense_32_loss: 0.0854\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0701 - dense_31_loss: 0.0352 - dense_32_loss: 0.0349 - val_loss: 0.1673 - val_dense_31_loss: 0.0652 - val_dense_32_loss: 0.1021\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0660 - dense_31_loss: 0.0354 - dense_32_loss: 0.0307 - val_loss: 0.1517 - val_dense_31_loss: 0.0745 - val_dense_32_loss: 0.0773\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0755 - dense_31_loss: 0.0344 - dense_32_loss: 0.0411 - val_loss: 0.1525 - val_dense_31_loss: 0.0689 - val_dense_32_loss: 0.0836\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0654 - dense_31_loss: 0.0323 - dense_32_loss: 0.0331 - val_loss: 0.1377 - val_dense_31_loss: 0.0637 - val_dense_32_loss: 0.0740\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0635 - dense_31_loss: 0.0346 - dense_32_loss: 0.0289 - val_loss: 0.1551 - val_dense_31_loss: 0.0662 - val_dense_32_loss: 0.0889\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0695 - dense_31_loss: 0.0371 - dense_32_loss: 0.0324 - val_loss: 0.1609 - val_dense_31_loss: 0.0759 - val_dense_32_loss: 0.0850\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0619 - dense_31_loss: 0.0344 - dense_32_loss: 0.0274 - val_loss: 0.1576 - val_dense_31_loss: 0.0745 - val_dense_32_loss: 0.0831\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0603 - dense_31_loss: 0.0339 - dense_32_loss: 0.0264 - val_loss: 0.1531 - val_dense_31_loss: 0.0779 - val_dense_32_loss: 0.0752\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0587 - dense_31_loss: 0.0333 - dense_32_loss: 0.0254 - val_loss: 0.1690 - val_dense_31_loss: 0.0732 - val_dense_32_loss: 0.0958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n",
      "INFO:tensorflow:Assets written to: Model/trained/model2.model/assets\n",
      "*********** Model 3 ************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 01:03:33.329436: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 186278400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "690/690 [==============================] - 28s 39ms/step - loss: 0.5395 - dense_42_loss: 0.2354 - dense_43_loss: 0.3041 - val_loss: 0.4179 - val_dense_42_loss: 0.1564 - val_dense_43_loss: 0.2616\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.4277 - dense_42_loss: 0.1806 - dense_43_loss: 0.2471 - val_loss: 0.3812 - val_dense_42_loss: 0.1598 - val_dense_43_loss: 0.2215\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3932 - dense_42_loss: 0.1661 - dense_43_loss: 0.2271 - val_loss: 0.3298 - val_dense_42_loss: 0.1330 - val_dense_43_loss: 0.1968\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3732 - dense_42_loss: 0.1614 - dense_43_loss: 0.2119 - val_loss: 0.3615 - val_dense_42_loss: 0.1434 - val_dense_43_loss: 0.2181\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3640 - dense_42_loss: 0.1582 - dense_43_loss: 0.2058 - val_loss: 0.3819 - val_dense_42_loss: 0.1287 - val_dense_43_loss: 0.2532\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3573 - dense_42_loss: 0.1557 - dense_43_loss: 0.2017 - val_loss: 0.3210 - val_dense_42_loss: 0.1330 - val_dense_43_loss: 0.1880\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3504 - dense_42_loss: 0.1532 - dense_43_loss: 0.1972 - val_loss: 0.3489 - val_dense_42_loss: 0.1406 - val_dense_43_loss: 0.2082\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3490 - dense_42_loss: 0.1518 - dense_43_loss: 0.1972 - val_loss: 0.3213 - val_dense_42_loss: 0.1366 - val_dense_43_loss: 0.1848\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3431 - dense_42_loss: 0.1493 - dense_43_loss: 0.1938 - val_loss: 0.3177 - val_dense_42_loss: 0.1222 - val_dense_43_loss: 0.1955\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3387 - dense_42_loss: 0.1493 - dense_43_loss: 0.1894 - val_loss: 0.3335 - val_dense_42_loss: 0.1358 - val_dense_43_loss: 0.1977\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3381 - dense_42_loss: 0.1476 - dense_43_loss: 0.1905 - val_loss: 0.3266 - val_dense_42_loss: 0.1232 - val_dense_43_loss: 0.2034\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3403 - dense_42_loss: 0.1493 - dense_43_loss: 0.1910 - val_loss: 0.3076 - val_dense_42_loss: 0.1351 - val_dense_43_loss: 0.1724\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3350 - dense_42_loss: 0.1476 - dense_43_loss: 0.1874 - val_loss: 0.3117 - val_dense_42_loss: 0.1270 - val_dense_43_loss: 0.1847\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3330 - dense_42_loss: 0.1473 - dense_43_loss: 0.1857 - val_loss: 0.3128 - val_dense_42_loss: 0.1191 - val_dense_43_loss: 0.1937\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3328 - dense_42_loss: 0.1463 - dense_43_loss: 0.1865 - val_loss: 0.3179 - val_dense_42_loss: 0.1222 - val_dense_43_loss: 0.1957\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 29s 43ms/step - loss: 0.3307 - dense_42_loss: 0.1456 - dense_43_loss: 0.1851 - val_loss: 0.3226 - val_dense_42_loss: 0.1207 - val_dense_43_loss: 0.2019\n",
      "Epoch 17/200\n",
      "690/690 [==============================] - 29s 41ms/step - loss: 0.3286 - dense_42_loss: 0.1451 - dense_43_loss: 0.1835 - val_loss: 0.2961 - val_dense_42_loss: 0.1268 - val_dense_43_loss: 0.1692\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3245 - dense_42_loss: 0.1429 - dense_43_loss: 0.1816 - val_loss: 0.2856 - val_dense_42_loss: 0.1294 - val_dense_43_loss: 0.1562\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3280 - dense_42_loss: 0.1445 - dense_43_loss: 0.1834 - val_loss: 0.3029 - val_dense_42_loss: 0.1299 - val_dense_43_loss: 0.1730\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3271 - dense_42_loss: 0.1447 - dense_43_loss: 0.1824 - val_loss: 0.3269 - val_dense_42_loss: 0.1411 - val_dense_43_loss: 0.1858\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3246 - dense_42_loss: 0.1432 - dense_43_loss: 0.1815 - val_loss: 0.2862 - val_dense_42_loss: 0.1082 - val_dense_43_loss: 0.1780\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.3229 - dense_42_loss: 0.1431 - dense_43_loss: 0.1798 - val_loss: 0.2818 - val_dense_42_loss: 0.1313 - val_dense_43_loss: 0.1505\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 27s 40ms/step - loss: 0.3243 - dense_42_loss: 0.1443 - dense_43_loss: 0.1800 - val_loss: 0.2895 - val_dense_42_loss: 0.1176 - val_dense_43_loss: 0.1720\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3205 - dense_42_loss: 0.1414 - dense_43_loss: 0.1792 - val_loss: 0.2823 - val_dense_42_loss: 0.1138 - val_dense_43_loss: 0.1685\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3203 - dense_42_loss: 0.1409 - dense_43_loss: 0.1794 - val_loss: 0.2959 - val_dense_42_loss: 0.1160 - val_dense_43_loss: 0.1799\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3206 - dense_42_loss: 0.1423 - dense_43_loss: 0.1783 - val_loss: 0.2794 - val_dense_42_loss: 0.1201 - val_dense_43_loss: 0.1593\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 29s 41ms/step - loss: 0.3214 - dense_42_loss: 0.1429 - dense_43_loss: 0.1785 - val_loss: 0.2828 - val_dense_42_loss: 0.1123 - val_dense_43_loss: 0.1705\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 29s 41ms/step - loss: 0.3200 - dense_42_loss: 0.1433 - dense_43_loss: 0.1767 - val_loss: 0.2836 - val_dense_42_loss: 0.1201 - val_dense_43_loss: 0.1636\n",
      "Epoch 29/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3174 - dense_42_loss: 0.1415 - dense_43_loss: 0.1759 - val_loss: 0.2730 - val_dense_42_loss: 0.1208 - val_dense_43_loss: 0.1522\n",
      "Epoch 30/200\n",
      "690/690 [==============================] - 29s 41ms/step - loss: 0.3188 - dense_42_loss: 0.1418 - dense_43_loss: 0.1770 - val_loss: 0.2981 - val_dense_42_loss: 0.1290 - val_dense_43_loss: 0.1691\n",
      "Epoch 31/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3261 - dense_42_loss: 0.1431 - dense_43_loss: 0.1829 - val_loss: 0.2772 - val_dense_42_loss: 0.1145 - val_dense_43_loss: 0.1627\n",
      "Epoch 32/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3181 - dense_42_loss: 0.1408 - dense_43_loss: 0.1773 - val_loss: 0.2865 - val_dense_42_loss: 0.1254 - val_dense_43_loss: 0.1612\n",
      "Epoch 33/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3163 - dense_42_loss: 0.1412 - dense_43_loss: 0.1750 - val_loss: 0.3017 - val_dense_42_loss: 0.1313 - val_dense_43_loss: 0.1704\n",
      "Epoch 34/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3159 - dense_42_loss: 0.1415 - dense_43_loss: 0.1744 - val_loss: 0.2891 - val_dense_42_loss: 0.1243 - val_dense_43_loss: 0.1649\n",
      "Epoch 35/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3155 - dense_42_loss: 0.1395 - dense_43_loss: 0.1759 - val_loss: 0.2959 - val_dense_42_loss: 0.1196 - val_dense_43_loss: 0.1763\n",
      "Epoch 36/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3167 - dense_42_loss: 0.1413 - dense_43_loss: 0.1755 - val_loss: 0.2755 - val_dense_42_loss: 0.1126 - val_dense_43_loss: 0.1629\n",
      "Epoch 37/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3151 - dense_42_loss: 0.1400 - dense_43_loss: 0.1751 - val_loss: 0.2838 - val_dense_42_loss: 0.1189 - val_dense_43_loss: 0.1649\n",
      "Epoch 38/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3127 - dense_42_loss: 0.1397 - dense_43_loss: 0.1730 - val_loss: 0.2879 - val_dense_42_loss: 0.1244 - val_dense_43_loss: 0.1634\n",
      "Epoch 39/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3146 - dense_42_loss: 0.1398 - dense_43_loss: 0.1748 - val_loss: 0.2879 - val_dense_42_loss: 0.1150 - val_dense_43_loss: 0.1729\n",
      "Epoch 40/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3116 - dense_42_loss: 0.1403 - dense_43_loss: 0.1713 - val_loss: 0.2890 - val_dense_42_loss: 0.1215 - val_dense_43_loss: 0.1675\n",
      "Epoch 41/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3138 - dense_42_loss: 0.1399 - dense_43_loss: 0.1739 - val_loss: 0.2819 - val_dense_42_loss: 0.1183 - val_dense_43_loss: 0.1636\n",
      "Epoch 42/200\n",
      "690/690 [==============================] - 29s 42ms/step - loss: 0.3128 - dense_42_loss: 0.1391 - dense_43_loss: 0.1737 - val_loss: 0.2753 - val_dense_42_loss: 0.1170 - val_dense_43_loss: 0.1583\n",
      "Epoch 43/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.3126 - dense_42_loss: 0.1402 - dense_43_loss: 0.1724 - val_loss: 0.2686 - val_dense_42_loss: 0.1157 - val_dense_43_loss: 0.1530\n",
      "Epoch 44/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3109 - dense_42_loss: 0.1383 - dense_43_loss: 0.1726 - val_loss: 0.2777 - val_dense_42_loss: 0.1198 - val_dense_43_loss: 0.1579\n",
      "Epoch 45/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3120 - dense_42_loss: 0.1389 - dense_43_loss: 0.1731 - val_loss: 0.2656 - val_dense_42_loss: 0.1171 - val_dense_43_loss: 0.1485\n",
      "Epoch 46/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3138 - dense_42_loss: 0.1402 - dense_43_loss: 0.1735 - val_loss: 0.2893 - val_dense_42_loss: 0.1150 - val_dense_43_loss: 0.1743\n",
      "Epoch 47/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3121 - dense_42_loss: 0.1378 - dense_43_loss: 0.1742 - val_loss: 0.2747 - val_dense_42_loss: 0.1198 - val_dense_43_loss: 0.1549\n",
      "Epoch 48/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3104 - dense_42_loss: 0.1392 - dense_43_loss: 0.1712 - val_loss: 0.2585 - val_dense_42_loss: 0.1184 - val_dense_43_loss: 0.1401\n",
      "Epoch 49/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3101 - dense_42_loss: 0.1387 - dense_43_loss: 0.1714 - val_loss: 0.2890 - val_dense_42_loss: 0.1244 - val_dense_43_loss: 0.1646\n",
      "Epoch 50/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3100 - dense_42_loss: 0.1387 - dense_43_loss: 0.1713 - val_loss: 0.2777 - val_dense_42_loss: 0.1145 - val_dense_43_loss: 0.1632\n",
      "Epoch 51/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3093 - dense_42_loss: 0.1387 - dense_43_loss: 0.1707 - val_loss: 0.2769 - val_dense_42_loss: 0.1101 - val_dense_43_loss: 0.1668\n",
      "Epoch 52/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3126 - dense_42_loss: 0.1392 - dense_43_loss: 0.1735 - val_loss: 0.2842 - val_dense_42_loss: 0.1215 - val_dense_43_loss: 0.1627\n",
      "Epoch 53/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3100 - dense_42_loss: 0.1385 - dense_43_loss: 0.1715 - val_loss: 0.2666 - val_dense_42_loss: 0.1163 - val_dense_43_loss: 0.1504\n",
      "Epoch 54/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3111 - dense_42_loss: 0.1387 - dense_43_loss: 0.1723 - val_loss: 0.2583 - val_dense_42_loss: 0.1116 - val_dense_43_loss: 0.1467\n",
      "Epoch 55/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3094 - dense_42_loss: 0.1384 - dense_43_loss: 0.1710 - val_loss: 0.2796 - val_dense_42_loss: 0.1244 - val_dense_43_loss: 0.1552\n",
      "Epoch 56/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3082 - dense_42_loss: 0.1386 - dense_43_loss: 0.1696 - val_loss: 0.2617 - val_dense_42_loss: 0.1122 - val_dense_43_loss: 0.1495\n",
      "Epoch 57/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3061 - dense_42_loss: 0.1372 - dense_43_loss: 0.1689 - val_loss: 0.2652 - val_dense_42_loss: 0.1058 - val_dense_43_loss: 0.1594\n",
      "Epoch 58/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3108 - dense_42_loss: 0.1392 - dense_43_loss: 0.1715 - val_loss: 0.2842 - val_dense_42_loss: 0.1168 - val_dense_43_loss: 0.1675\n",
      "Epoch 59/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3103 - dense_42_loss: 0.1384 - dense_43_loss: 0.1719 - val_loss: 0.2815 - val_dense_42_loss: 0.1112 - val_dense_43_loss: 0.1703\n",
      "Epoch 60/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3071 - dense_42_loss: 0.1383 - dense_43_loss: 0.1688 - val_loss: 0.2462 - val_dense_42_loss: 0.1113 - val_dense_43_loss: 0.1349\n",
      "Epoch 61/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3065 - dense_42_loss: 0.1385 - dense_43_loss: 0.1680 - val_loss: 0.2591 - val_dense_42_loss: 0.1142 - val_dense_43_loss: 0.1448\n",
      "Epoch 62/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3074 - dense_42_loss: 0.1380 - dense_43_loss: 0.1694 - val_loss: 0.2594 - val_dense_42_loss: 0.1185 - val_dense_43_loss: 0.1408\n",
      "Epoch 63/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3065 - dense_42_loss: 0.1373 - dense_43_loss: 0.1692 - val_loss: 0.2620 - val_dense_42_loss: 0.1114 - val_dense_43_loss: 0.1505\n",
      "Epoch 64/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3060 - dense_42_loss: 0.1363 - dense_43_loss: 0.1697 - val_loss: 0.2803 - val_dense_42_loss: 0.1196 - val_dense_43_loss: 0.1607\n",
      "Epoch 65/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3057 - dense_42_loss: 0.1364 - dense_43_loss: 0.1693 - val_loss: 0.2881 - val_dense_42_loss: 0.1214 - val_dense_43_loss: 0.1667\n",
      "Epoch 66/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3075 - dense_42_loss: 0.1388 - dense_43_loss: 0.1687 - val_loss: 0.2831 - val_dense_42_loss: 0.1315 - val_dense_43_loss: 0.1516\n",
      "Epoch 67/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3061 - dense_42_loss: 0.1367 - dense_43_loss: 0.1694 - val_loss: 0.2919 - val_dense_42_loss: 0.1280 - val_dense_43_loss: 0.1639\n",
      "Epoch 68/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3043 - dense_42_loss: 0.1365 - dense_43_loss: 0.1678 - val_loss: 0.2732 - val_dense_42_loss: 0.1120 - val_dense_43_loss: 0.1613\n",
      "Epoch 69/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3060 - dense_42_loss: 0.1372 - dense_43_loss: 0.1688 - val_loss: 0.2943 - val_dense_42_loss: 0.1204 - val_dense_43_loss: 0.1739\n",
      "Epoch 70/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3053 - dense_42_loss: 0.1369 - dense_43_loss: 0.1684 - val_loss: 0.2803 - val_dense_42_loss: 0.1154 - val_dense_43_loss: 0.1648\n",
      "Epoch 71/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3059 - dense_42_loss: 0.1378 - dense_43_loss: 0.1681 - val_loss: 0.2858 - val_dense_42_loss: 0.1228 - val_dense_43_loss: 0.1631\n",
      "Epoch 72/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.3051 - dense_42_loss: 0.1374 - dense_43_loss: 0.1678 - val_loss: 0.2619 - val_dense_42_loss: 0.1154 - val_dense_43_loss: 0.1465\n",
      "Epoch 73/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3048 - dense_42_loss: 0.1359 - dense_43_loss: 0.1689 - val_loss: 0.2711 - val_dense_42_loss: 0.1154 - val_dense_43_loss: 0.1557\n",
      "Epoch 74/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3024 - dense_42_loss: 0.1348 - dense_43_loss: 0.1676 - val_loss: 0.2591 - val_dense_42_loss: 0.1011 - val_dense_43_loss: 0.1580\n",
      "Epoch 75/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.3015 - dense_42_loss: 0.1344 - dense_43_loss: 0.1671 - val_loss: 0.2796 - val_dense_42_loss: 0.1224 - val_dense_43_loss: 0.1572\n",
      "Epoch 76/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.3031 - dense_42_loss: 0.1340 - dense_43_loss: 0.1691 - val_loss: 0.2617 - val_dense_42_loss: 0.1173 - val_dense_43_loss: 0.1443\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00076: early stopping\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fef35a50b80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef35a4d700> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35ac3d90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef35ac3b20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef35a53730> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a53d30> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef35a53b80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fef35a70250> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a70a90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fef35a70370> False\n",
      "<keras.layers.core.Flatten object at 0x7fef35a70d60> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a761f0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a768e0> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fef35a76910> False\n",
      "<keras.layers.merge.Concatenate object at 0x7fef35a76eb0> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a7e040> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a7e1f0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a7ed90> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a7edc0> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a88100> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a88190> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a88d30> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a88d60> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a12070> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a12130> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a12cd0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a12d00> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a12f10> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a1b0d0> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a1bc70> False\n",
      "<keras.layers.core.Dropout object at 0x7fef35a1bca0> False\n",
      "<keras.layers.core.Dense object at 0x7fef35a1beb0> True\n",
      "<keras.layers.core.Dense object at 0x7fef35a252e0> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 39ms/step - loss: 0.4572 - dense_42_loss: 0.1888 - dense_43_loss: 0.2684 - val_loss: 0.4127 - val_dense_42_loss: 0.1565 - val_dense_43_loss: 0.2563\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.4231 - dense_42_loss: 0.1825 - dense_43_loss: 0.2405 - val_loss: 0.4121 - val_dense_42_loss: 0.1488 - val_dense_43_loss: 0.2633\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4122 - dense_42_loss: 0.1834 - dense_43_loss: 0.2288 - val_loss: 0.3650 - val_dense_42_loss: 0.1544 - val_dense_43_loss: 0.2106\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.4031 - dense_42_loss: 0.1744 - dense_43_loss: 0.2288 - val_loss: 0.3622 - val_dense_42_loss: 0.1438 - val_dense_43_loss: 0.2183\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3878 - dense_42_loss: 0.1638 - dense_43_loss: 0.2240 - val_loss: 0.3684 - val_dense_42_loss: 0.1389 - val_dense_43_loss: 0.2294\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3861 - dense_42_loss: 0.1651 - dense_43_loss: 0.2210 - val_loss: 0.3580 - val_dense_42_loss: 0.1473 - val_dense_43_loss: 0.2107\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3692 - dense_42_loss: 0.1638 - dense_43_loss: 0.2053 - val_loss: 0.3359 - val_dense_42_loss: 0.1389 - val_dense_43_loss: 0.1970\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3625 - dense_42_loss: 0.1573 - dense_43_loss: 0.2052 - val_loss: 0.3146 - val_dense_42_loss: 0.1115 - val_dense_43_loss: 0.2031\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3559 - dense_42_loss: 0.1523 - dense_43_loss: 0.2036 - val_loss: 0.3476 - val_dense_42_loss: 0.1313 - val_dense_43_loss: 0.2163\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3681 - dense_42_loss: 0.1543 - dense_43_loss: 0.2138 - val_loss: 0.2971 - val_dense_42_loss: 0.1229 - val_dense_43_loss: 0.1742\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3561 - dense_42_loss: 0.1540 - dense_43_loss: 0.2021 - val_loss: 0.3363 - val_dense_42_loss: 0.1283 - val_dense_43_loss: 0.2080\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3543 - dense_42_loss: 0.1502 - dense_43_loss: 0.2041 - val_loss: 0.3048 - val_dense_42_loss: 0.1121 - val_dense_43_loss: 0.1927\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3527 - dense_42_loss: 0.1561 - dense_43_loss: 0.1967 - val_loss: 0.3279 - val_dense_42_loss: 0.1386 - val_dense_43_loss: 0.1893\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3516 - dense_42_loss: 0.1478 - dense_43_loss: 0.2038 - val_loss: 0.3187 - val_dense_42_loss: 0.1271 - val_dense_43_loss: 0.1916\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3318 - dense_42_loss: 0.1356 - dense_43_loss: 0.1962 - val_loss: 0.2866 - val_dense_42_loss: 0.1045 - val_dense_43_loss: 0.1820\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3520 - dense_42_loss: 0.1460 - dense_43_loss: 0.2059 - val_loss: 0.2874 - val_dense_42_loss: 0.1167 - val_dense_43_loss: 0.1707\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3502 - dense_42_loss: 0.1481 - dense_43_loss: 0.2022 - val_loss: 0.3171 - val_dense_42_loss: 0.1228 - val_dense_43_loss: 0.1943\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3432 - dense_42_loss: 0.1452 - dense_43_loss: 0.1980 - val_loss: 0.2884 - val_dense_42_loss: 0.1126 - val_dense_43_loss: 0.1758\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3459 - dense_42_loss: 0.1475 - dense_43_loss: 0.1984 - val_loss: 0.2946 - val_dense_42_loss: 0.1193 - val_dense_43_loss: 0.1753\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3445 - dense_42_loss: 0.1502 - dense_43_loss: 0.1943 - val_loss: 0.3019 - val_dense_42_loss: 0.1204 - val_dense_43_loss: 0.1815\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3512 - dense_42_loss: 0.1478 - dense_43_loss: 0.2034 - val_loss: 0.2736 - val_dense_42_loss: 0.1012 - val_dense_43_loss: 0.1724\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.3330 - dense_42_loss: 0.1387 - dense_43_loss: 0.1943 - val_loss: 0.2861 - val_dense_42_loss: 0.1120 - val_dense_43_loss: 0.1742\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3435 - dense_42_loss: 0.1472 - dense_43_loss: 0.1963 - val_loss: 0.2748 - val_dense_42_loss: 0.1037 - val_dense_43_loss: 0.1711\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3390 - dense_42_loss: 0.1444 - dense_43_loss: 0.1946 - val_loss: 0.2729 - val_dense_42_loss: 0.1095 - val_dense_43_loss: 0.1634\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3456 - dense_42_loss: 0.1423 - dense_43_loss: 0.2033 - val_loss: 0.2620 - val_dense_42_loss: 0.1022 - val_dense_43_loss: 0.1598\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3338 - dense_42_loss: 0.1429 - dense_43_loss: 0.1909 - val_loss: 0.2684 - val_dense_42_loss: 0.1027 - val_dense_43_loss: 0.1657\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3325 - dense_42_loss: 0.1419 - dense_43_loss: 0.1906 - val_loss: 0.2639 - val_dense_42_loss: 0.1061 - val_dense_43_loss: 0.1578\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3201 - dense_42_loss: 0.1410 - dense_43_loss: 0.1791 - val_loss: 0.3080 - val_dense_42_loss: 0.1043 - val_dense_43_loss: 0.2037\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3412 - dense_42_loss: 0.1480 - dense_43_loss: 0.1932 - val_loss: 0.3020 - val_dense_42_loss: 0.1138 - val_dense_43_loss: 0.1882\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3692 - dense_42_loss: 0.1559 - dense_43_loss: 0.2133 - val_loss: 0.3262 - val_dense_42_loss: 0.1170 - val_dense_43_loss: 0.2093\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3560 - dense_42_loss: 0.1449 - dense_43_loss: 0.2111 - val_loss: 0.2841 - val_dense_42_loss: 0.1045 - val_dense_43_loss: 0.1796\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3383 - dense_42_loss: 0.1466 - dense_43_loss: 0.1917 - val_loss: 0.2832 - val_dense_42_loss: 0.1097 - val_dense_43_loss: 0.1735\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3395 - dense_42_loss: 0.1427 - dense_43_loss: 0.1968 - val_loss: 0.2954 - val_dense_42_loss: 0.1134 - val_dense_43_loss: 0.1820\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3433 - dense_42_loss: 0.1501 - dense_43_loss: 0.1933 - val_loss: 0.2829 - val_dense_42_loss: 0.1035 - val_dense_43_loss: 0.1794\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.3304 - dense_42_loss: 0.1444 - dense_43_loss: 0.1861 - val_loss: 0.2606 - val_dense_42_loss: 0.0980 - val_dense_43_loss: 0.1626\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3276 - dense_42_loss: 0.1395 - dense_43_loss: 0.1881 - val_loss: 0.2633 - val_dense_42_loss: 0.0953 - val_dense_43_loss: 0.1679\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3279 - dense_42_loss: 0.1419 - dense_43_loss: 0.1860 - val_loss: 0.2696 - val_dense_42_loss: 0.1054 - val_dense_43_loss: 0.1643\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3344 - dense_42_loss: 0.1461 - dense_43_loss: 0.1883 - val_loss: 0.2541 - val_dense_42_loss: 0.0969 - val_dense_43_loss: 0.1573\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3221 - dense_42_loss: 0.1383 - dense_43_loss: 0.1839 - val_loss: 0.2709 - val_dense_42_loss: 0.1038 - val_dense_43_loss: 0.1671\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3153 - dense_42_loss: 0.1356 - dense_43_loss: 0.1797 - val_loss: 0.2642 - val_dense_42_loss: 0.0915 - val_dense_43_loss: 0.1727\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3121 - dense_42_loss: 0.1365 - dense_43_loss: 0.1756 - val_loss: 0.2722 - val_dense_42_loss: 0.1026 - val_dense_43_loss: 0.1696\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3246 - dense_42_loss: 0.1386 - dense_43_loss: 0.1860 - val_loss: 0.2876 - val_dense_42_loss: 0.0982 - val_dense_43_loss: 0.1894\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3287 - dense_42_loss: 0.1420 - dense_43_loss: 0.1868 - val_loss: 0.2511 - val_dense_42_loss: 0.0937 - val_dense_43_loss: 0.1573\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3214 - dense_42_loss: 0.1390 - dense_43_loss: 0.1824 - val_loss: 0.2739 - val_dense_42_loss: 0.1035 - val_dense_43_loss: 0.1704\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3349 - dense_42_loss: 0.1368 - dense_43_loss: 0.1981 - val_loss: 0.3033 - val_dense_42_loss: 0.1174 - val_dense_43_loss: 0.1859\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3399 - dense_42_loss: 0.1442 - dense_43_loss: 0.1957 - val_loss: 0.2588 - val_dense_42_loss: 0.0959 - val_dense_43_loss: 0.1629\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3242 - dense_42_loss: 0.1421 - dense_43_loss: 0.1821 - val_loss: 0.2459 - val_dense_42_loss: 0.0930 - val_dense_43_loss: 0.1528\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3197 - dense_42_loss: 0.1356 - dense_43_loss: 0.1841 - val_loss: 0.2726 - val_dense_42_loss: 0.1008 - val_dense_43_loss: 0.1718\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3434 - dense_42_loss: 0.1410 - dense_43_loss: 0.2024 - val_loss: 0.2661 - val_dense_42_loss: 0.0962 - val_dense_43_loss: 0.1699\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3264 - dense_42_loss: 0.1346 - dense_43_loss: 0.1918 - val_loss: 0.2670 - val_dense_42_loss: 0.0970 - val_dense_43_loss: 0.1700\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3213 - dense_42_loss: 0.1319 - dense_43_loss: 0.1894 - val_loss: 0.2654 - val_dense_42_loss: 0.0996 - val_dense_43_loss: 0.1659\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3271 - dense_42_loss: 0.1361 - dense_43_loss: 0.1911 - val_loss: 0.2710 - val_dense_42_loss: 0.0932 - val_dense_43_loss: 0.1778\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3232 - dense_42_loss: 0.1346 - dense_43_loss: 0.1887 - val_loss: 0.2716 - val_dense_42_loss: 0.0991 - val_dense_43_loss: 0.1725\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3246 - dense_42_loss: 0.1349 - dense_43_loss: 0.1897 - val_loss: 0.2576 - val_dense_42_loss: 0.0976 - val_dense_43_loss: 0.1600\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3231 - dense_42_loss: 0.1321 - dense_43_loss: 0.1909 - val_loss: 0.2690 - val_dense_42_loss: 0.0983 - val_dense_43_loss: 0.1707\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3187 - dense_42_loss: 0.1380 - dense_43_loss: 0.1807 - val_loss: 0.2591 - val_dense_42_loss: 0.0844 - val_dense_43_loss: 0.1746\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3327 - dense_42_loss: 0.1364 - dense_43_loss: 0.1964 - val_loss: 0.2652 - val_dense_42_loss: 0.0918 - val_dense_43_loss: 0.1734\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3230 - dense_42_loss: 0.1330 - dense_43_loss: 0.1900 - val_loss: 0.2568 - val_dense_42_loss: 0.0936 - val_dense_43_loss: 0.1632\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3134 - dense_42_loss: 0.1338 - dense_43_loss: 0.1796 - val_loss: 0.2648 - val_dense_42_loss: 0.0914 - val_dense_43_loss: 0.1734\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3109 - dense_42_loss: 0.1337 - dense_43_loss: 0.1772 - val_loss: 0.2566 - val_dense_42_loss: 0.0911 - val_dense_43_loss: 0.1655\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3130 - dense_42_loss: 0.1353 - dense_43_loss: 0.1777 - val_loss: 0.2467 - val_dense_42_loss: 0.0907 - val_dense_43_loss: 0.1560\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3093 - dense_42_loss: 0.1370 - dense_43_loss: 0.1722 - val_loss: 0.2550 - val_dense_42_loss: 0.0898 - val_dense_43_loss: 0.1652\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3093 - dense_42_loss: 0.1312 - dense_43_loss: 0.1781 - val_loss: 0.2705 - val_dense_42_loss: 0.0919 - val_dense_43_loss: 0.1785\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "INFO:tensorflow:Assets written to: Model/trained/model3.model/assets\n",
      "*********** Model 4 ************\n",
      "Epoch 1/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.2895 - dense_53_loss: 0.1127 - dense_54_loss: 0.1767 - val_loss: 0.2265 - val_dense_53_loss: 0.0843 - val_dense_54_loss: 0.1422\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1936 - dense_53_loss: 0.0733 - dense_54_loss: 0.1203 - val_loss: 0.1861 - val_dense_53_loss: 0.0742 - val_dense_54_loss: 0.1119\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1698 - dense_53_loss: 0.0642 - dense_54_loss: 0.1056 - val_loss: 0.1714 - val_dense_53_loss: 0.0629 - val_dense_54_loss: 0.1085\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1551 - dense_53_loss: 0.0596 - dense_54_loss: 0.0956 - val_loss: 0.1567 - val_dense_53_loss: 0.0575 - val_dense_54_loss: 0.0992\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1417 - dense_53_loss: 0.0556 - dense_54_loss: 0.0861 - val_loss: 0.1538 - val_dense_53_loss: 0.0550 - val_dense_54_loss: 0.0988\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1348 - dense_53_loss: 0.0530 - dense_54_loss: 0.0818 - val_loss: 0.1468 - val_dense_53_loss: 0.0593 - val_dense_54_loss: 0.0874\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1284 - dense_53_loss: 0.0506 - dense_54_loss: 0.0778 - val_loss: 0.1501 - val_dense_53_loss: 0.0564 - val_dense_54_loss: 0.0937\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1214 - dense_53_loss: 0.0488 - dense_54_loss: 0.0726 - val_loss: 0.1616 - val_dense_53_loss: 0.0526 - val_dense_54_loss: 0.1089\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1154 - dense_53_loss: 0.0468 - dense_54_loss: 0.0686 - val_loss: 0.1385 - val_dense_53_loss: 0.0554 - val_dense_54_loss: 0.0831\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1082 - dense_53_loss: 0.0447 - dense_54_loss: 0.0634 - val_loss: 0.1242 - val_dense_53_loss: 0.0505 - val_dense_54_loss: 0.0736\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1061 - dense_53_loss: 0.0435 - dense_54_loss: 0.0626 - val_loss: 0.1251 - val_dense_53_loss: 0.0528 - val_dense_54_loss: 0.0724\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.1024 - dense_53_loss: 0.0423 - dense_54_loss: 0.0600 - val_loss: 0.1291 - val_dense_53_loss: 0.0512 - val_dense_54_loss: 0.0780\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0963 - dense_53_loss: 0.0397 - dense_54_loss: 0.0566 - val_loss: 0.1141 - val_dense_53_loss: 0.0454 - val_dense_54_loss: 0.0687\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0955 - dense_53_loss: 0.0397 - dense_54_loss: 0.0559 - val_loss: 0.1293 - val_dense_53_loss: 0.0523 - val_dense_54_loss: 0.0771\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0932 - dense_53_loss: 0.0388 - dense_54_loss: 0.0544 - val_loss: 0.1359 - val_dense_53_loss: 0.0499 - val_dense_54_loss: 0.0860\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0895 - dense_53_loss: 0.0374 - dense_54_loss: 0.0522 - val_loss: 0.1201 - val_dense_53_loss: 0.0460 - val_dense_54_loss: 0.0740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0888 - dense_53_loss: 0.0371 - dense_54_loss: 0.0517 - val_loss: 0.1111 - val_dense_53_loss: 0.0440 - val_dense_54_loss: 0.0671\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0876 - dense_53_loss: 0.0367 - dense_54_loss: 0.0509 - val_loss: 0.1076 - val_dense_53_loss: 0.0436 - val_dense_54_loss: 0.0640\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0861 - dense_53_loss: 0.0363 - dense_54_loss: 0.0498 - val_loss: 0.1063 - val_dense_53_loss: 0.0424 - val_dense_54_loss: 0.0639\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0868 - dense_53_loss: 0.0354 - dense_54_loss: 0.0514 - val_loss: 0.1263 - val_dense_53_loss: 0.0461 - val_dense_54_loss: 0.0802\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0857 - dense_53_loss: 0.0349 - dense_54_loss: 0.0508 - val_loss: 0.1119 - val_dense_53_loss: 0.0441 - val_dense_54_loss: 0.0678\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0848 - dense_53_loss: 0.0349 - dense_54_loss: 0.0499 - val_loss: 0.1145 - val_dense_53_loss: 0.0425 - val_dense_54_loss: 0.0721\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 20s 30ms/step - loss: 0.0808 - dense_53_loss: 0.0337 - dense_54_loss: 0.0471 - val_loss: 0.1168 - val_dense_53_loss: 0.0445 - val_dense_54_loss: 0.0723\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0843 - dense_53_loss: 0.0342 - dense_54_loss: 0.0500 - val_loss: 0.1071 - val_dense_53_loss: 0.0422 - val_dense_54_loss: 0.0649\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0772 - dense_53_loss: 0.0328 - dense_54_loss: 0.0444 - val_loss: 0.1047 - val_dense_53_loss: 0.0489 - val_dense_54_loss: 0.0558\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0739 - dense_53_loss: 0.0329 - dense_54_loss: 0.0410 - val_loss: 0.1011 - val_dense_53_loss: 0.0416 - val_dense_54_loss: 0.0595\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0732 - dense_53_loss: 0.0315 - dense_54_loss: 0.0416 - val_loss: 0.1262 - val_dense_53_loss: 0.0405 - val_dense_54_loss: 0.0857\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0807 - dense_53_loss: 0.0333 - dense_54_loss: 0.0474 - val_loss: 0.0965 - val_dense_53_loss: 0.0432 - val_dense_54_loss: 0.0532\n",
      "Epoch 29/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0689 - dense_53_loss: 0.0304 - dense_54_loss: 0.0386 - val_loss: 0.1039 - val_dense_53_loss: 0.0421 - val_dense_54_loss: 0.0618\n",
      "Epoch 30/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0702 - dense_53_loss: 0.0308 - dense_54_loss: 0.0395 - val_loss: 0.1033 - val_dense_53_loss: 0.0427 - val_dense_54_loss: 0.0606\n",
      "Epoch 31/200\n",
      "690/690 [==============================] - 20s 30ms/step - loss: 0.0695 - dense_53_loss: 0.0305 - dense_54_loss: 0.0389 - val_loss: 0.1027 - val_dense_53_loss: 0.0407 - val_dense_54_loss: 0.0620\n",
      "Epoch 32/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0684 - dense_53_loss: 0.0302 - dense_54_loss: 0.0382 - val_loss: 0.0986 - val_dense_53_loss: 0.0400 - val_dense_54_loss: 0.0586\n",
      "Epoch 33/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0673 - dense_53_loss: 0.0307 - dense_54_loss: 0.0365 - val_loss: 0.1040 - val_dense_53_loss: 0.0421 - val_dense_54_loss: 0.0619\n",
      "Epoch 34/200\n",
      "690/690 [==============================] - 20s 30ms/step - loss: 0.0659 - dense_53_loss: 0.0301 - dense_54_loss: 0.0358 - val_loss: 0.0981 - val_dense_53_loss: 0.0395 - val_dense_54_loss: 0.0586\n",
      "Epoch 35/200\n",
      "690/690 [==============================] - 20s 30ms/step - loss: 0.0618 - dense_53_loss: 0.0288 - dense_54_loss: 0.0329 - val_loss: 0.0972 - val_dense_53_loss: 0.0424 - val_dense_54_loss: 0.0548\n",
      "Epoch 36/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0651 - dense_53_loss: 0.0295 - dense_54_loss: 0.0356 - val_loss: 0.0887 - val_dense_53_loss: 0.0388 - val_dense_54_loss: 0.0498\n",
      "Epoch 37/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0616 - dense_53_loss: 0.0281 - dense_54_loss: 0.0335 - val_loss: 0.0922 - val_dense_53_loss: 0.0411 - val_dense_54_loss: 0.0510\n",
      "Epoch 38/200\n",
      "690/690 [==============================] - 21s 30ms/step - loss: 0.0615 - dense_53_loss: 0.0286 - dense_54_loss: 0.0329 - val_loss: 0.0915 - val_dense_53_loss: 0.0402 - val_dense_54_loss: 0.0513\n",
      "Epoch 39/200\n",
      "690/690 [==============================] - 20s 29ms/step - loss: 0.0690 - dense_53_loss: 0.0307 - dense_54_loss: 0.0383 - val_loss: 0.0981 - val_dense_53_loss: 0.0398 - val_dense_54_loss: 0.0583\n",
      "Epoch 40/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0627 - dense_53_loss: 0.0293 - dense_54_loss: 0.0334 - val_loss: 0.0991 - val_dense_53_loss: 0.0422 - val_dense_54_loss: 0.0569\n",
      "Epoch 41/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0701 - dense_53_loss: 0.0307 - dense_54_loss: 0.0393 - val_loss: 0.0961 - val_dense_53_loss: 0.0420 - val_dense_54_loss: 0.0542\n",
      "Epoch 42/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0619 - dense_53_loss: 0.0293 - dense_54_loss: 0.0326 - val_loss: 0.1114 - val_dense_53_loss: 0.0382 - val_dense_54_loss: 0.0732\n",
      "Epoch 43/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0647 - dense_53_loss: 0.0291 - dense_54_loss: 0.0356 - val_loss: 0.0914 - val_dense_53_loss: 0.0401 - val_dense_54_loss: 0.0513\n",
      "Epoch 44/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0616 - dense_53_loss: 0.0292 - dense_54_loss: 0.0324 - val_loss: 0.0947 - val_dense_53_loss: 0.0434 - val_dense_54_loss: 0.0513\n",
      "Epoch 45/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0633 - dense_53_loss: 0.0289 - dense_54_loss: 0.0344 - val_loss: 0.0965 - val_dense_53_loss: 0.0389 - val_dense_54_loss: 0.0576\n",
      "Epoch 46/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0599 - dense_53_loss: 0.0279 - dense_54_loss: 0.0320 - val_loss: 0.0968 - val_dense_53_loss: 0.0387 - val_dense_54_loss: 0.0581\n",
      "Epoch 47/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0635 - dense_53_loss: 0.0288 - dense_54_loss: 0.0347 - val_loss: 0.0900 - val_dense_53_loss: 0.0355 - val_dense_54_loss: 0.0546\n",
      "Epoch 48/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0647 - dense_53_loss: 0.0297 - dense_54_loss: 0.0349 - val_loss: 0.0904 - val_dense_53_loss: 0.0370 - val_dense_54_loss: 0.0534\n",
      "Epoch 49/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0598 - dense_53_loss: 0.0283 - dense_54_loss: 0.0315 - val_loss: 0.0836 - val_dense_53_loss: 0.0360 - val_dense_54_loss: 0.0477\n",
      "Epoch 50/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0557 - dense_53_loss: 0.0266 - dense_54_loss: 0.0292 - val_loss: 0.0883 - val_dense_53_loss: 0.0391 - val_dense_54_loss: 0.0492\n",
      "Epoch 51/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0635 - dense_53_loss: 0.0289 - dense_54_loss: 0.0346 - val_loss: 0.1006 - val_dense_53_loss: 0.0387 - val_dense_54_loss: 0.0619\n",
      "Epoch 52/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0599 - dense_53_loss: 0.0273 - dense_54_loss: 0.0326 - val_loss: 0.1198 - val_dense_53_loss: 0.0409 - val_dense_54_loss: 0.0789\n",
      "Epoch 53/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0616 - dense_53_loss: 0.0280 - dense_54_loss: 0.0336 - val_loss: 0.0859 - val_dense_53_loss: 0.0363 - val_dense_54_loss: 0.0496\n",
      "Epoch 54/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0609 - dense_53_loss: 0.0277 - dense_54_loss: 0.0331 - val_loss: 0.0893 - val_dense_53_loss: 0.0387 - val_dense_54_loss: 0.0506\n",
      "Epoch 55/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0552 - dense_53_loss: 0.0255 - dense_54_loss: 0.0297 - val_loss: 0.0877 - val_dense_53_loss: 0.0377 - val_dense_54_loss: 0.0500\n",
      "Epoch 56/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0594 - dense_53_loss: 0.0266 - dense_54_loss: 0.0329 - val_loss: 0.0866 - val_dense_53_loss: 0.0385 - val_dense_54_loss: 0.0481\n",
      "Epoch 57/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0551 - dense_53_loss: 0.0259 - dense_54_loss: 0.0293 - val_loss: 0.0855 - val_dense_53_loss: 0.0358 - val_dense_54_loss: 0.0497\n",
      "Epoch 58/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0599 - dense_53_loss: 0.0267 - dense_54_loss: 0.0332 - val_loss: 0.0875 - val_dense_53_loss: 0.0353 - val_dense_54_loss: 0.0522\n",
      "Epoch 59/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0590 - dense_53_loss: 0.0271 - dense_54_loss: 0.0319 - val_loss: 0.0851 - val_dense_53_loss: 0.0346 - val_dense_54_loss: 0.0506\n",
      "Epoch 60/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0556 - dense_53_loss: 0.0250 - dense_54_loss: 0.0305 - val_loss: 0.0878 - val_dense_53_loss: 0.0366 - val_dense_54_loss: 0.0511\n",
      "Epoch 61/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0582 - dense_53_loss: 0.0263 - dense_54_loss: 0.0319 - val_loss: 0.0926 - val_dense_53_loss: 0.0366 - val_dense_54_loss: 0.0560\n",
      "Epoch 62/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0568 - dense_53_loss: 0.0258 - dense_54_loss: 0.0310 - val_loss: 0.1141 - val_dense_53_loss: 0.0399 - val_dense_54_loss: 0.0742\n",
      "Epoch 63/200\n",
      "690/690 [==============================] - 19s 28ms/step - loss: 0.0588 - dense_53_loss: 0.0262 - dense_54_loss: 0.0326 - val_loss: 0.0877 - val_dense_53_loss: 0.0355 - val_dense_54_loss: 0.0522\n",
      "Epoch 64/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0572 - dense_53_loss: 0.0263 - dense_54_loss: 0.0310 - val_loss: 0.0964 - val_dense_53_loss: 0.0383 - val_dense_54_loss: 0.0582\n",
      "Epoch 65/200\n",
      "690/690 [==============================] - 19s 27ms/step - loss: 0.0591 - dense_53_loss: 0.0260 - dense_54_loss: 0.0331 - val_loss: 0.0870 - val_dense_53_loss: 0.0365 - val_dense_54_loss: 0.0505\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "<keras.engine.input_layer.InputLayer object at 0x7feeac79a7f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac7eca30> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac786b80> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac780610> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac7eac70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac7f5880> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac7f06d0> False\n",
      "<keras.layers.core.Flatten object at 0x7feeac7f3ee0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7f3a90> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fef35a76130> False\n",
      "<keras.layers.merge.Concatenate object at 0x7feeac7e7b80> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7e7c10> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7ac280> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7ac3a0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7ac970> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7b42e0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac7b4550> False\n",
      "<keras.layers.core.Dense object at 0x7feeac73b220> False\n",
      "<keras.layers.core.Dense object at 0x7feeac73b130> False\n",
      "<keras.layers.core.Dense object at 0x7feeac73b700> True\n",
      "<keras.layers.core.Dense object at 0x7feeac7451c0> True\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2179 - dense_53_loss: 0.0765 - dense_54_loss: 0.1414 - val_loss: 0.1996 - val_dense_53_loss: 0.0603 - val_dense_54_loss: 0.1393\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1421 - dense_53_loss: 0.0458 - dense_54_loss: 0.0963 - val_loss: 0.1908 - val_dense_53_loss: 0.0497 - val_dense_54_loss: 0.1411\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1228 - dense_53_loss: 0.0373 - dense_54_loss: 0.0855 - val_loss: 0.1462 - val_dense_53_loss: 0.0413 - val_dense_54_loss: 0.1049\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1007 - dense_53_loss: 0.0329 - dense_54_loss: 0.0678 - val_loss: 0.1329 - val_dense_53_loss: 0.0376 - val_dense_54_loss: 0.0953\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0924 - dense_53_loss: 0.0308 - dense_54_loss: 0.0616 - val_loss: 0.1623 - val_dense_53_loss: 0.0438 - val_dense_54_loss: 0.1186\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0902 - dense_53_loss: 0.0305 - dense_54_loss: 0.0596 - val_loss: 0.1371 - val_dense_53_loss: 0.0375 - val_dense_54_loss: 0.0996\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0813 - dense_53_loss: 0.0292 - dense_54_loss: 0.0522 - val_loss: 0.1509 - val_dense_53_loss: 0.0378 - val_dense_54_loss: 0.1130\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0750 - dense_53_loss: 0.0274 - dense_54_loss: 0.0476 - val_loss: 0.1104 - val_dense_53_loss: 0.0310 - val_dense_54_loss: 0.0794\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0658 - dense_53_loss: 0.0258 - dense_54_loss: 0.0399 - val_loss: 0.1013 - val_dense_53_loss: 0.0312 - val_dense_54_loss: 0.0701\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0701 - dense_53_loss: 0.0252 - dense_54_loss: 0.0449 - val_loss: 0.0995 - val_dense_53_loss: 0.0352 - val_dense_54_loss: 0.0643\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0604 - dense_53_loss: 0.0262 - dense_54_loss: 0.0342 - val_loss: 0.0952 - val_dense_53_loss: 0.0331 - val_dense_54_loss: 0.0621\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0568 - dense_53_loss: 0.0244 - dense_54_loss: 0.0324 - val_loss: 0.1176 - val_dense_53_loss: 0.0311 - val_dense_54_loss: 0.0864\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0511 - dense_53_loss: 0.0230 - dense_54_loss: 0.0281 - val_loss: 0.0952 - val_dense_53_loss: 0.0356 - val_dense_54_loss: 0.0596\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0715 - dense_53_loss: 0.0253 - dense_54_loss: 0.0462 - val_loss: 0.1177 - val_dense_53_loss: 0.0380 - val_dense_54_loss: 0.0797\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0546 - dense_53_loss: 0.0239 - dense_54_loss: 0.0307 - val_loss: 0.1045 - val_dense_53_loss: 0.0345 - val_dense_54_loss: 0.0700\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0520 - dense_53_loss: 0.0245 - dense_54_loss: 0.0274 - val_loss: 0.1042 - val_dense_53_loss: 0.0363 - val_dense_54_loss: 0.0679\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0519 - dense_53_loss: 0.0244 - dense_54_loss: 0.0275 - val_loss: 0.0907 - val_dense_53_loss: 0.0399 - val_dense_54_loss: 0.0508\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0483 - dense_53_loss: 0.0240 - dense_54_loss: 0.0244 - val_loss: 0.1023 - val_dense_53_loss: 0.0380 - val_dense_54_loss: 0.0643\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0484 - dense_53_loss: 0.0227 - dense_54_loss: 0.0257 - val_loss: 0.0965 - val_dense_53_loss: 0.0368 - val_dense_54_loss: 0.0598\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0553 - dense_53_loss: 0.0233 - dense_54_loss: 0.0320 - val_loss: 0.1076 - val_dense_53_loss: 0.0417 - val_dense_54_loss: 0.0659\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0482 - dense_53_loss: 0.0231 - dense_54_loss: 0.0251 - val_loss: 0.0864 - val_dense_53_loss: 0.0351 - val_dense_54_loss: 0.0513\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0448 - dense_53_loss: 0.0224 - dense_54_loss: 0.0225 - val_loss: 0.0791 - val_dense_53_loss: 0.0339 - val_dense_54_loss: 0.0451\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0465 - dense_53_loss: 0.0222 - dense_54_loss: 0.0242 - val_loss: 0.0855 - val_dense_53_loss: 0.0314 - val_dense_54_loss: 0.0541\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0469 - dense_53_loss: 0.0226 - dense_54_loss: 0.0243 - val_loss: 0.1117 - val_dense_53_loss: 0.0302 - val_dense_54_loss: 0.0815\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0533 - dense_53_loss: 0.0223 - dense_54_loss: 0.0310 - val_loss: 0.1165 - val_dense_53_loss: 0.0299 - val_dense_54_loss: 0.0867\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0546 - dense_53_loss: 0.0229 - dense_54_loss: 0.0318 - val_loss: 0.1007 - val_dense_53_loss: 0.0289 - val_dense_54_loss: 0.0718\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0438 - dense_53_loss: 0.0206 - dense_54_loss: 0.0232 - val_loss: 0.0823 - val_dense_53_loss: 0.0350 - val_dense_54_loss: 0.0473\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0437 - dense_53_loss: 0.0212 - dense_54_loss: 0.0226 - val_loss: 0.0960 - val_dense_53_loss: 0.0295 - val_dense_54_loss: 0.0665\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0425 - dense_53_loss: 0.0216 - dense_54_loss: 0.0209 - val_loss: 0.0990 - val_dense_53_loss: 0.0283 - val_dense_54_loss: 0.0707\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0449 - dense_53_loss: 0.0209 - dense_54_loss: 0.0240 - val_loss: 0.0833 - val_dense_53_loss: 0.0282 - val_dense_54_loss: 0.0551\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0415 - dense_53_loss: 0.0206 - dense_54_loss: 0.0208 - val_loss: 0.0933 - val_dense_53_loss: 0.0317 - val_dense_54_loss: 0.0616\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0483 - dense_53_loss: 0.0205 - dense_54_loss: 0.0278 - val_loss: 0.0947 - val_dense_53_loss: 0.0283 - val_dense_54_loss: 0.0664\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0421 - dense_53_loss: 0.0192 - dense_54_loss: 0.0229 - val_loss: 0.0906 - val_dense_53_loss: 0.0272 - val_dense_54_loss: 0.0634\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0390 - dense_53_loss: 0.0196 - dense_54_loss: 0.0194 - val_loss: 0.0847 - val_dense_53_loss: 0.0294 - val_dense_54_loss: 0.0553\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0399 - dense_53_loss: 0.0202 - dense_54_loss: 0.0197 - val_loss: 0.0999 - val_dense_53_loss: 0.0254 - val_dense_54_loss: 0.0745\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0399 - dense_53_loss: 0.0189 - dense_54_loss: 0.0210 - val_loss: 0.0854 - val_dense_53_loss: 0.0322 - val_dense_54_loss: 0.0532\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0410 - dense_53_loss: 0.0209 - dense_54_loss: 0.0200 - val_loss: 0.0814 - val_dense_53_loss: 0.0384 - val_dense_54_loss: 0.0430\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0402 - dense_53_loss: 0.0220 - dense_54_loss: 0.0182 - val_loss: 0.0705 - val_dense_53_loss: 0.0328 - val_dense_54_loss: 0.0377\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0375 - dense_53_loss: 0.0195 - dense_54_loss: 0.0180 - val_loss: 0.0755 - val_dense_53_loss: 0.0327 - val_dense_54_loss: 0.0428\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0379 - dense_53_loss: 0.0197 - dense_54_loss: 0.0181 - val_loss: 0.0710 - val_dense_53_loss: 0.0298 - val_dense_54_loss: 0.0412\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0357 - dense_53_loss: 0.0174 - dense_54_loss: 0.0182 - val_loss: 0.0716 - val_dense_53_loss: 0.0318 - val_dense_54_loss: 0.0398\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0353 - dense_53_loss: 0.0172 - dense_54_loss: 0.0181 - val_loss: 0.0680 - val_dense_53_loss: 0.0291 - val_dense_54_loss: 0.0388\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0343 - dense_53_loss: 0.0161 - dense_54_loss: 0.0181 - val_loss: 0.0664 - val_dense_53_loss: 0.0281 - val_dense_54_loss: 0.0383\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0352 - dense_53_loss: 0.0167 - dense_54_loss: 0.0185 - val_loss: 0.0635 - val_dense_53_loss: 0.0280 - val_dense_54_loss: 0.0355\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0343 - dense_53_loss: 0.0166 - dense_54_loss: 0.0177 - val_loss: 0.0642 - val_dense_53_loss: 0.0275 - val_dense_54_loss: 0.0367\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0330 - dense_53_loss: 0.0151 - dense_54_loss: 0.0179 - val_loss: 0.0629 - val_dense_53_loss: 0.0263 - val_dense_54_loss: 0.0366\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0331 - dense_53_loss: 0.0143 - dense_54_loss: 0.0189 - val_loss: 0.0674 - val_dense_53_loss: 0.0291 - val_dense_54_loss: 0.0382\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0324 - dense_53_loss: 0.0146 - dense_54_loss: 0.0179 - val_loss: 0.0697 - val_dense_53_loss: 0.0292 - val_dense_54_loss: 0.0405\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0321 - dense_53_loss: 0.0147 - dense_54_loss: 0.0174 - val_loss: 0.0673 - val_dense_53_loss: 0.0272 - val_dense_54_loss: 0.0400\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0304 - dense_53_loss: 0.0128 - dense_54_loss: 0.0176 - val_loss: 0.0701 - val_dense_53_loss: 0.0301 - val_dense_54_loss: 0.0399\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0327 - dense_53_loss: 0.0144 - dense_54_loss: 0.0183 - val_loss: 0.0747 - val_dense_53_loss: 0.0294 - val_dense_54_loss: 0.0453\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0361 - dense_53_loss: 0.0183 - dense_54_loss: 0.0178 - val_loss: 0.0830 - val_dense_53_loss: 0.0318 - val_dense_54_loss: 0.0512\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0344 - dense_53_loss: 0.0156 - dense_54_loss: 0.0189 - val_loss: 0.0820 - val_dense_53_loss: 0.0315 - val_dense_54_loss: 0.0505\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0310 - dense_53_loss: 0.0132 - dense_54_loss: 0.0178 - val_loss: 0.0737 - val_dense_53_loss: 0.0306 - val_dense_54_loss: 0.0431\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0288 - dense_53_loss: 0.0120 - dense_54_loss: 0.0168 - val_loss: 0.0770 - val_dense_53_loss: 0.0316 - val_dense_54_loss: 0.0454\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0297 - dense_53_loss: 0.0129 - dense_54_loss: 0.0168 - val_loss: 0.0779 - val_dense_53_loss: 0.0314 - val_dense_54_loss: 0.0465\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0288 - dense_53_loss: 0.0118 - dense_54_loss: 0.0171 - val_loss: 0.0734 - val_dense_53_loss: 0.0301 - val_dense_54_loss: 0.0433\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0299 - dense_53_loss: 0.0129 - dense_54_loss: 0.0170 - val_loss: 0.0739 - val_dense_53_loss: 0.0312 - val_dense_54_loss: 0.0427\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0277 - dense_53_loss: 0.0109 - dense_54_loss: 0.0168 - val_loss: 0.0729 - val_dense_53_loss: 0.0305 - val_dense_54_loss: 0.0424\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0281 - dense_53_loss: 0.0103 - dense_54_loss: 0.0177 - val_loss: 0.0720 - val_dense_53_loss: 0.0304 - val_dense_54_loss: 0.0416\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0278 - dense_53_loss: 0.0101 - dense_54_loss: 0.0177 - val_loss: 0.0736 - val_dense_53_loss: 0.0324 - val_dense_54_loss: 0.0412\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0268 - dense_53_loss: 0.0098 - dense_54_loss: 0.0169 - val_loss: 0.0746 - val_dense_53_loss: 0.0313 - val_dense_54_loss: 0.0433\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "INFO:tensorflow:Assets written to: Model/trained/model4.model/assets\n",
      "*********** Model 5 ************\n",
      "Epoch 1/200\n",
      "690/690 [==============================] - 26s 36ms/step - loss: 0.5371 - dense_97_loss: 0.1710 - dense_98_loss: 0.3661 - val_loss: 0.4504 - val_dense_97_loss: 0.1265 - val_dense_98_loss: 0.3238\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.4141 - dense_97_loss: 0.1137 - dense_98_loss: 0.3004 - val_loss: 0.4225 - val_dense_97_loss: 0.1143 - val_dense_98_loss: 0.3083\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.4007 - dense_97_loss: 0.1015 - dense_98_loss: 0.2992 - val_loss: 0.4310 - val_dense_97_loss: 0.1226 - val_dense_98_loss: 0.3084\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3940 - dense_97_loss: 0.0948 - dense_98_loss: 0.2991 - val_loss: 0.4212 - val_dense_97_loss: 0.1129 - val_dense_98_loss: 0.3083\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3896 - dense_97_loss: 0.0904 - dense_98_loss: 0.2992 - val_loss: 0.4231 - val_dense_97_loss: 0.1148 - val_dense_98_loss: 0.3083\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3856 - dense_97_loss: 0.0865 - dense_98_loss: 0.2991 - val_loss: 0.4149 - val_dense_97_loss: 0.1066 - val_dense_98_loss: 0.3084\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3825 - dense_97_loss: 0.0833 - dense_98_loss: 0.2992 - val_loss: 0.4225 - val_dense_97_loss: 0.1142 - val_dense_98_loss: 0.3083\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3758 - dense_97_loss: 0.0767 - dense_98_loss: 0.2991 - val_loss: 0.4018 - val_dense_97_loss: 0.0936 - val_dense_98_loss: 0.3083\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3711 - dense_97_loss: 0.0719 - dense_98_loss: 0.2991 - val_loss: 0.3987 - val_dense_97_loss: 0.0904 - val_dense_98_loss: 0.3083\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3686 - dense_97_loss: 0.0694 - dense_98_loss: 0.2991 - val_loss: 0.3967 - val_dense_97_loss: 0.0884 - val_dense_98_loss: 0.3083\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3666 - dense_97_loss: 0.0675 - dense_98_loss: 0.2991 - val_loss: 0.3912 - val_dense_97_loss: 0.0830 - val_dense_98_loss: 0.3083\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3648 - dense_97_loss: 0.0657 - dense_98_loss: 0.2991 - val_loss: 0.3977 - val_dense_97_loss: 0.0894 - val_dense_98_loss: 0.3083\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3634 - dense_97_loss: 0.0642 - dense_98_loss: 0.2992 - val_loss: 0.3934 - val_dense_97_loss: 0.0851 - val_dense_98_loss: 0.3084\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3640 - dense_97_loss: 0.0648 - dense_98_loss: 0.2991 - val_loss: 0.4094 - val_dense_97_loss: 0.1011 - val_dense_98_loss: 0.3083\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3612 - dense_97_loss: 0.0620 - dense_98_loss: 0.2992 - val_loss: 0.3839 - val_dense_97_loss: 0.0756 - val_dense_98_loss: 0.3083\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3608 - dense_97_loss: 0.0617 - dense_98_loss: 0.2992 - val_loss: 0.4007 - val_dense_97_loss: 0.0924 - val_dense_98_loss: 0.3083\n",
      "Epoch 17/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3605 - dense_97_loss: 0.0614 - dense_98_loss: 0.2991 - val_loss: 0.3859 - val_dense_97_loss: 0.0775 - val_dense_98_loss: 0.3084\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3595 - dense_97_loss: 0.0604 - dense_98_loss: 0.2991 - val_loss: 0.3950 - val_dense_97_loss: 0.0867 - val_dense_98_loss: 0.3083\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3590 - dense_97_loss: 0.0599 - dense_98_loss: 0.2991 - val_loss: 0.3948 - val_dense_97_loss: 0.0865 - val_dense_98_loss: 0.3083\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3580 - dense_97_loss: 0.0588 - dense_98_loss: 0.2992 - val_loss: 0.4064 - val_dense_97_loss: 0.0981 - val_dense_98_loss: 0.3083\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3578 - dense_97_loss: 0.0587 - dense_98_loss: 0.2991 - val_loss: 0.4145 - val_dense_97_loss: 0.1061 - val_dense_98_loss: 0.3084\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3583 - dense_97_loss: 0.0591 - dense_98_loss: 0.2992 - val_loss: 0.4077 - val_dense_97_loss: 0.0992 - val_dense_98_loss: 0.3084\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 25s 37ms/step - loss: 0.3560 - dense_97_loss: 0.0569 - dense_98_loss: 0.2991 - val_loss: 0.3981 - val_dense_97_loss: 0.0897 - val_dense_98_loss: 0.3084\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3569 - dense_97_loss: 0.0577 - dense_98_loss: 0.2992 - val_loss: 0.3994 - val_dense_97_loss: 0.0911 - val_dense_98_loss: 0.3083\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3557 - dense_97_loss: 0.0565 - dense_98_loss: 0.2992 - val_loss: 0.4077 - val_dense_97_loss: 0.0994 - val_dense_98_loss: 0.3083\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3564 - dense_97_loss: 0.0572 - dense_98_loss: 0.2992 - val_loss: 0.3888 - val_dense_97_loss: 0.0804 - val_dense_98_loss: 0.3083\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3563 - dense_97_loss: 0.0572 - dense_98_loss: 0.2991 - val_loss: 0.4069 - val_dense_97_loss: 0.0985 - val_dense_98_loss: 0.3084\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3541 - dense_97_loss: 0.0549 - dense_98_loss: 0.2991 - val_loss: 0.3954 - val_dense_97_loss: 0.0871 - val_dense_98_loss: 0.3083\n",
      "Epoch 29/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3544 - dense_97_loss: 0.0553 - dense_98_loss: 0.2991 - val_loss: 0.3985 - val_dense_97_loss: 0.0902 - val_dense_98_loss: 0.3083\n",
      "Epoch 30/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3533 - dense_97_loss: 0.0541 - dense_98_loss: 0.2991 - val_loss: 0.4089 - val_dense_97_loss: 0.1007 - val_dense_98_loss: 0.3083\n",
      "Epoch 31/200\n",
      "690/690 [==============================] - 25s 36ms/step - loss: 0.3528 - dense_97_loss: 0.0536 - dense_98_loss: 0.2991 - val_loss: 0.3991 - val_dense_97_loss: 0.0907 - val_dense_98_loss: 0.3084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "<keras.engine.input_layer.InputLayer object at 0x7feeac3d15b0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac3ea280> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3ea0a0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac3ea8e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac37e250> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac37ea90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac37e370> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7feeac3840a0> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3847f0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7feeac3840d0> False\n",
      "<keras.layers.core.Flatten object at 0x7feeac384ac0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac384f10> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac38d640> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7feeac38d670> False\n",
      "<keras.layers.merge.Concatenate object at 0x7feeac38dc10> False\n",
      "<keras.layers.core.Dense object at 0x7feeac38dca0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac399310> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac399af0> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac399b20> False\n",
      "<keras.layers.core.Dense object at 0x7feeac399d30> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3a02b0> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3a0a90> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3a0ac0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3a0cd0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3aa250> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3aaa30> False\n",
      "<keras.layers.core.Dropout object at 0x7feeac3aaa60> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3aac70> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3b21f0> False\n",
      "<keras.layers.core.Dense object at 0x7feeac3b2310> True\n",
      "<keras.layers.core.Dense object at 0x7feeac3b2910> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 37ms/step - loss: 0.4126 - dense_97_loss: 0.0798 - dense_98_loss: 0.3328 - val_loss: 0.4360 - val_dense_97_loss: 0.0970 - val_dense_98_loss: 0.3390\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3881 - dense_97_loss: 0.0553 - dense_98_loss: 0.3328 - val_loss: 0.4359 - val_dense_97_loss: 0.0970 - val_dense_98_loss: 0.3389\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3818 - dense_97_loss: 0.0490 - dense_98_loss: 0.3328 - val_loss: 0.4347 - val_dense_97_loss: 0.0957 - val_dense_98_loss: 0.3390\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3778 - dense_97_loss: 0.0449 - dense_98_loss: 0.3328 - val_loss: 0.4092 - val_dense_97_loss: 0.0703 - val_dense_98_loss: 0.3389\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3790 - dense_97_loss: 0.0462 - dense_98_loss: 0.3328 - val_loss: 0.4194 - val_dense_97_loss: 0.0805 - val_dense_98_loss: 0.3389\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3711 - dense_97_loss: 0.0384 - dense_98_loss: 0.3327 - val_loss: 0.4086 - val_dense_97_loss: 0.0695 - val_dense_98_loss: 0.3391\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3705 - dense_97_loss: 0.0375 - dense_98_loss: 0.3330 - val_loss: 0.4168 - val_dense_97_loss: 0.0779 - val_dense_98_loss: 0.3390\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3679 - dense_97_loss: 0.0352 - dense_98_loss: 0.3328 - val_loss: 0.4156 - val_dense_97_loss: 0.0767 - val_dense_98_loss: 0.3389\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3686 - dense_97_loss: 0.0358 - dense_98_loss: 0.3328 - val_loss: 0.4258 - val_dense_97_loss: 0.0868 - val_dense_98_loss: 0.3390\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3701 - dense_97_loss: 0.0373 - dense_98_loss: 0.3328 - val_loss: 0.4139 - val_dense_97_loss: 0.0749 - val_dense_98_loss: 0.3390\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3678 - dense_97_loss: 0.0350 - dense_98_loss: 0.3328 - val_loss: 0.4098 - val_dense_97_loss: 0.0709 - val_dense_98_loss: 0.3389\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3678 - dense_97_loss: 0.0350 - dense_98_loss: 0.3328 - val_loss: 0.4144 - val_dense_97_loss: 0.0755 - val_dense_98_loss: 0.3389\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3668 - dense_97_loss: 0.0340 - dense_98_loss: 0.3328 - val_loss: 0.4193 - val_dense_97_loss: 0.0803 - val_dense_98_loss: 0.3389\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3656 - dense_97_loss: 0.0329 - dense_98_loss: 0.3328 - val_loss: 0.4187 - val_dense_97_loss: 0.0796 - val_dense_98_loss: 0.3391\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3661 - dense_97_loss: 0.0333 - dense_98_loss: 0.3328 - val_loss: 0.4198 - val_dense_97_loss: 0.0809 - val_dense_98_loss: 0.3389\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3674 - dense_97_loss: 0.0346 - dense_98_loss: 0.3328 - val_loss: 0.4212 - val_dense_97_loss: 0.0823 - val_dense_98_loss: 0.3389\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3680 - dense_97_loss: 0.0352 - dense_98_loss: 0.3328 - val_loss: 0.4289 - val_dense_97_loss: 0.0900 - val_dense_98_loss: 0.3389\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3651 - dense_97_loss: 0.0322 - dense_98_loss: 0.3329 - val_loss: 0.4342 - val_dense_97_loss: 0.0952 - val_dense_98_loss: 0.3390\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3718 - dense_97_loss: 0.0390 - dense_98_loss: 0.3328 - val_loss: 0.4126 - val_dense_97_loss: 0.0738 - val_dense_98_loss: 0.3389\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3714 - dense_97_loss: 0.0386 - dense_98_loss: 0.3328 - val_loss: 0.4172 - val_dense_97_loss: 0.0783 - val_dense_98_loss: 0.3389\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3713 - dense_97_loss: 0.0384 - dense_98_loss: 0.3329 - val_loss: 0.4158 - val_dense_97_loss: 0.0769 - val_dense_98_loss: 0.3389\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3665 - dense_97_loss: 0.0336 - dense_98_loss: 0.3328 - val_loss: 0.4062 - val_dense_97_loss: 0.0672 - val_dense_98_loss: 0.3390\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3679 - dense_97_loss: 0.0352 - dense_98_loss: 0.3328 - val_loss: 0.4239 - val_dense_97_loss: 0.0850 - val_dense_98_loss: 0.3389\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3677 - dense_97_loss: 0.0348 - dense_98_loss: 0.3328 - val_loss: 0.4117 - val_dense_97_loss: 0.0726 - val_dense_98_loss: 0.3391\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3635 - dense_97_loss: 0.0306 - dense_98_loss: 0.3329 - val_loss: 0.4164 - val_dense_97_loss: 0.0773 - val_dense_98_loss: 0.3391\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3648 - dense_97_loss: 0.0320 - dense_98_loss: 0.3328 - val_loss: 0.4114 - val_dense_97_loss: 0.0724 - val_dense_98_loss: 0.3390\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3619 - dense_97_loss: 0.0292 - dense_98_loss: 0.3328 - val_loss: 0.4132 - val_dense_97_loss: 0.0743 - val_dense_98_loss: 0.3389\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3650 - dense_97_loss: 0.0322 - dense_98_loss: 0.3328 - val_loss: 0.4114 - val_dense_97_loss: 0.0724 - val_dense_98_loss: 0.3390\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3636 - dense_97_loss: 0.0307 - dense_98_loss: 0.3329 - val_loss: 0.4103 - val_dense_97_loss: 0.0713 - val_dense_98_loss: 0.3390\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3636 - dense_97_loss: 0.0308 - dense_98_loss: 0.3328 - val_loss: 0.4118 - val_dense_97_loss: 0.0729 - val_dense_98_loss: 0.3389\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3622 - dense_97_loss: 0.0294 - dense_98_loss: 0.3328 - val_loss: 0.4117 - val_dense_97_loss: 0.0728 - val_dense_98_loss: 0.3389\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3631 - dense_97_loss: 0.0303 - dense_98_loss: 0.3328 - val_loss: 0.4053 - val_dense_97_loss: 0.0663 - val_dense_98_loss: 0.3390\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3621 - dense_97_loss: 0.0292 - dense_98_loss: 0.3328 - val_loss: 0.4099 - val_dense_97_loss: 0.0708 - val_dense_98_loss: 0.3391\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3634 - dense_97_loss: 0.0305 - dense_98_loss: 0.3329 - val_loss: 0.4057 - val_dense_97_loss: 0.0665 - val_dense_98_loss: 0.3391\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.3640 - dense_97_loss: 0.0308 - dense_98_loss: 0.3332 - val_loss: 0.4131 - val_dense_97_loss: 0.0740 - val_dense_98_loss: 0.3391\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.3636 - dense_97_loss: 0.0308 - dense_98_loss: 0.3328 - val_loss: 0.4148 - val_dense_97_loss: 0.0755 - val_dense_98_loss: 0.3393\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3633 - dense_97_loss: 0.0304 - dense_98_loss: 0.3329 - val_loss: 0.4100 - val_dense_97_loss: 0.0711 - val_dense_98_loss: 0.3389\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.3639 - dense_97_loss: 0.0312 - dense_98_loss: 0.3328 - val_loss: 0.4127 - val_dense_97_loss: 0.0738 - val_dense_98_loss: 0.3389\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.3635 - dense_97_loss: 0.0307 - dense_98_loss: 0.3328 - val_loss: 0.4142 - val_dense_97_loss: 0.0753 - val_dense_98_loss: 0.3389\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.3641 - dense_97_loss: 0.0313 - dense_98_loss: 0.3328 - val_loss: 0.4163 - val_dense_97_loss: 0.0772 - val_dense_98_loss: 0.3391\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.3632 - dense_97_loss: 0.0304 - dense_98_loss: 0.3328 - val_loss: 0.4117 - val_dense_97_loss: 0.0727 - val_dense_98_loss: 0.3390\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3631 - dense_97_loss: 0.0303 - dense_98_loss: 0.3328 - val_loss: 0.4068 - val_dense_97_loss: 0.0679 - val_dense_98_loss: 0.3389\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3612 - dense_97_loss: 0.0284 - dense_98_loss: 0.3328 - val_loss: 0.4067 - val_dense_97_loss: 0.0677 - val_dense_98_loss: 0.3390\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3629 - dense_97_loss: 0.0302 - dense_98_loss: 0.3328 - val_loss: 0.4110 - val_dense_97_loss: 0.0720 - val_dense_98_loss: 0.3390\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3602 - dense_97_loss: 0.0274 - dense_98_loss: 0.3328 - val_loss: 0.4121 - val_dense_97_loss: 0.0733 - val_dense_98_loss: 0.3389\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3604 - dense_97_loss: 0.0276 - dense_98_loss: 0.3328 - val_loss: 0.4105 - val_dense_97_loss: 0.0716 - val_dense_98_loss: 0.3389\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3590 - dense_97_loss: 0.0262 - dense_98_loss: 0.3328 - val_loss: 0.4071 - val_dense_97_loss: 0.0682 - val_dense_98_loss: 0.3389\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.3589 - dense_97_loss: 0.0262 - dense_98_loss: 0.3327 - val_loss: 0.4078 - val_dense_97_loss: 0.0689 - val_dense_98_loss: 0.3389\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00048: early stopping\n",
      "INFO:tensorflow:Assets written to: Model/trained/model5.model/assets\n",
      "*********** Model 6 ************\n",
      "Epoch 1/200\n",
      "690/690 [==============================] - 28s 39ms/step - loss: 0.7186 - dense_108_loss: 0.3527 - dense_109_loss: 0.3659 - val_loss: 0.6189 - val_dense_108_loss: 0.2966 - val_dense_109_loss: 0.3224\n",
      "Epoch 2/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.5871 - dense_108_loss: 0.2869 - dense_109_loss: 0.3002 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 3/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5984 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 4/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5985 - val_dense_108_loss: 0.2902 - val_dense_109_loss: 0.3083\n",
      "Epoch 5/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5987 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3087\n",
      "Epoch 6/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 7/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5984 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3084\n",
      "Epoch 8/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5986 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3085\n",
      "Epoch 9/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 10/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 11/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5984 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3084\n",
      "Epoch 12/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 13/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5987 - val_dense_108_loss: 0.2902 - val_dense_109_loss: 0.3085\n",
      "Epoch 14/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 15/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 16/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5985 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3085\n",
      "Epoch 17/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5985 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 18/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 19/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5985 - val_dense_108_loss: 0.2902 - val_dense_109_loss: 0.3083\n",
      "Epoch 20/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5986 - val_dense_108_loss: 0.2902 - val_dense_109_loss: 0.3084\n",
      "Epoch 21/200\n",
      "690/690 [==============================] - 27s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5985 - val_dense_108_loss: 0.2902 - val_dense_109_loss: 0.3083\n",
      "Epoch 22/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.5844 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 23/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2992 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 24/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.5873 - dense_108_loss: 0.2882 - dense_109_loss: 0.2991 - val_loss: 0.5985 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3084\n",
      "Epoch 25/200\n",
      "690/690 [==============================] - 26s 38ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Epoch 26/200\n",
      "690/690 [==============================] - 31s 45ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5987 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3086\n",
      "Epoch 27/200\n",
      "690/690 [==============================] - 27s 39ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5983 - val_dense_108_loss: 0.2900 - val_dense_109_loss: 0.3083\n",
      "Epoch 28/200\n",
      "690/690 [==============================] - 28s 41ms/step - loss: 0.5845 - dense_108_loss: 0.2853 - dense_109_loss: 0.2991 - val_loss: 0.5984 - val_dense_108_loss: 0.2901 - val_dense_109_loss: 0.3083\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fee895c06a0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fee895c2310> False\n",
      "<keras.layers.core.Dropout object at 0x7fee896365b0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fee895cff10> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fee895cf400> False\n",
      "<keras.layers.core.Dropout object at 0x7fee895bb6a0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fee896388e0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fee896389a0> False\n",
      "<keras.layers.core.Dropout object at 0x7fee895e49d0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fee895e4a60> False\n",
      "<keras.layers.core.Flatten object at 0x7fee895e4c40> False\n",
      "<keras.layers.core.Dense object at 0x7fee895f7100> False\n",
      "<keras.layers.core.Dropout object at 0x7fee895f77c0> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fee895f77f0> False\n",
      "<keras.layers.merge.Concatenate object at 0x7fee895f7d90> False\n",
      "<keras.layers.core.Dense object at 0x7fee895f7e20> False\n",
      "<keras.layers.core.Dense object at 0x7fee8957f0d0> False\n",
      "<keras.layers.core.Dropout object at 0x7fee8957fc70> False\n",
      "<keras.layers.core.Dropout object at 0x7fee8957fca0> False\n",
      "<keras.layers.core.Dense object at 0x7fee8957feb0> False\n",
      "<keras.layers.core.Dense object at 0x7fee895882e0> False\n",
      "<keras.layers.core.Dropout object at 0x7fee89588c10> False\n",
      "<keras.layers.core.Dropout object at 0x7fee89588c40> False\n",
      "<keras.layers.core.Dense object at 0x7fee89588e50> False\n",
      "<keras.layers.core.Dense object at 0x7fee895913d0> False\n",
      "<keras.layers.core.Dropout object at 0x7fee89591bb0> False\n",
      "<keras.layers.core.Dropout object at 0x7fee89591be0> False\n",
      "<keras.layers.core.Dense object at 0x7fee89591df0> False\n",
      "<keras.layers.core.Dense object at 0x7fee8959b370> False\n",
      "<keras.layers.core.Dense object at 0x7fee8959b490> True\n",
      "<keras.layers.core.Dense object at 0x7fee895a40a0> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3444 - val_dense_109_loss: 0.3390\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.6650 - dense_108_loss: 0.3321 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6836 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3446 - val_dense_109_loss: 0.3389\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3446 - val_dense_109_loss: 0.3390\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6838 - val_dense_108_loss: 0.3449 - val_dense_109_loss: 0.3389\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6651 - dense_108_loss: 0.3323 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6650 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3444 - val_dense_109_loss: 0.3389\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6649 - dense_108_loss: 0.3321 - dense_109_loss: 0.3327 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3327 - val_loss: 0.6835 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3390\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6835 - val_dense_108_loss: 0.3446 - val_dense_109_loss: 0.3389\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6649 - dense_108_loss: 0.3322 - dense_109_loss: 0.3328 - val_loss: 0.6834 - val_dense_108_loss: 0.3445 - val_dense_109_loss: 0.3389\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "INFO:tensorflow:Assets written to: Model/trained/model6.model/assets\n",
      "Training Fineshed!\n",
      "145.264885421594\n",
      "[[0.162044351718706, 0.18415392705372402, 0.0529449621618964, 0.0982909448933141, 0.28965567557005645], [0.139193580074416, 0.1604107923985643, 0.09520095859504776, 0.1218541066849462, 0.28951500981608913], [0.22656937110451073, 0.2462471262938311, 0.21981846701215815, 0.24585645414061016, 0.2660314537828358], [0.04981997552933295, 0.08363260061118584, 0.03177237195684287, 0.06291653014745356, 0.27484880649980203], [0.3713376569772145, 0.38394481263829466, 0.3875146931752327, 0.405340611538203, 0.4153256449256113], [0.5843436054469777, 0.5982819721650104, 0.6648404231042038, 0.6833596554067399, 0.5576998385099264]]\n"
     ]
    }
   ],
   "source": [
    "raw_models_dir = PATH2PROJECT + \"Model/Models/raw/\"\n",
    "trained_models_dir = PATH2PROJECT + \"Model/Models/trained1/\"\n",
    "raw_models_folders = os.listdir(raw_models_dir)\n",
    "\n",
    "t1 = time.time()\n",
    "losses = []\n",
    "for model_fol in raw_models_folders:\n",
    "    model = load_model(raw_models_dir + model_fol)\n",
    "    print(f\"*********** {model_fol} ************\")\n",
    "    model.fit(x_train_list,\n",
    "              y_train_list,\n",
    "              validation_data=(x_test_list, y_test_list),\n",
    "              epochs=N_EPOCHS,\n",
    "              callbacks=cb)\n",
    "\n",
    "    yhat_train_list = model.predict(x_train_list)\n",
    "    yhat_test_list = model.predict(x_test_list)\n",
    "    \n",
    "    y_train = np.concatenate((np.expand_dims(y_train_list[0], 1), np.expand_dims(y_train_list[1], 1)), 1)\n",
    "    yhat_train = np.concatenate((yhat_train_list[0], yhat_train_list[1]), 1)\n",
    "    y_test = np.concatenate((np.expand_dims(y_test_list[0], 1), np.expand_dims(y_test_list[1], 1)), 1)\n",
    "    yhat_test = np.concatenate((yhat_test_list[0], yhat_test_list[1]), 1)\n",
    "\n",
    "    train_loss = np.abs(y_train - yhat_train).sum(0) / n_train\n",
    "    test_loss = np.abs(y_test - yhat_test).sum(0) / n_test\n",
    "\n",
    "    for layer in model.layers[:-TRAINABLE_LAYERS]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "  \n",
    "    model.fit(x_train_seen_list,\n",
    "              y_train_seen_list,\n",
    "              validation_data=(x_test_seen_list, y_test_seen_list),\n",
    "              epochs=N_EPOCHS,\n",
    "              callbacks=cb)\n",
    "    \n",
    "    yhat_train_seen_list = model.predict(x_train_seen_list)\n",
    "    yhat_test_seen_list = model.predict(x_test_seen_list)\n",
    "    yhat_unseen_list = model.predict(x_unseen_list)\n",
    "    \n",
    "    y_train_seen = np.concatenate((np.expand_dims(y_train_seen_list[0], 1),\n",
    "                                   np.expand_dims(y_train_seen_list[1], 1)), 1)\n",
    "    yhat_train_seen = np.concatenate((yhat_train_seen_list[0],\n",
    "                                      yhat_train_seen_list[1]), 1)\n",
    "    y_test_seen = np.concatenate((np.expand_dims(y_test_seen_list[0], 1),\n",
    "                             np.expand_dims(y_test_seen_list[1], 1)), 1)\n",
    "    yhat_test_seen = np.concatenate((yhat_test_seen_list[0],\n",
    "                                     yhat_test_seen_list[1]), 1)\n",
    "    y_unseen_new = np.concatenate((np.expand_dims(y_unseen_list[0], 1),\n",
    "                                   np.expand_dims(y_unseen_list[1], 1)), 1)\n",
    "    yhat_unseen = np.concatenate((yhat_unseen_list[0],\n",
    "                                  yhat_unseen_list[1]), 1)\n",
    "    \n",
    "    train_seen_loss = np.abs(y_train_seen - yhat_train_seen).sum(0) / n_train_seen\n",
    "    test_seen_loss = np.abs(y_test_seen - yhat_test_seen).sum(0) / n_test_seen\n",
    "    unseen_loss = np.abs(y_unseen - yhat_unseen).sum(0) / n_unseen\n",
    "    \n",
    "    loss = [train_loss, test_loss, train_seen_loss, test_seen_loss, unseen_loss]\n",
    "    losses.append(loss)\n",
    "    \n",
    "    model.save(trained_models_dir + model_fol\")\n",
    "    print(loss)\n",
    "\n",
    "jdump(losses, trained_models_dir)\n",
    "elapsed_time = (time.time() - t1) / 60\n",
    "print(\"Training Fineshed!\")\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0ccc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16204435 0.18415393 0.05294496 0.09829094 0.28965568]\n",
      " [0.13919358 0.16041079 0.09520096 0.12185411 0.28951501]\n",
      " [0.22656937 0.24624713 0.21981847 0.24585645 0.26603145]\n",
      " [0.04981998 0.0836326  0.03177237 0.06291653 0.27484881]\n",
      " [0.37133766 0.38394481 0.38751469 0.40534061 0.41532564]\n",
      " [0.58434361 0.59828197 0.66484042 0.68335966 0.55769984]]\n"
     ]
    }
   ],
   "source": [
    "losses = np.array(losses)\n",
    "print(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EyeTracker",
   "language": "python",
   "name": "eyetracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
