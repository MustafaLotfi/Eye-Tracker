{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rtn_2mdl_et_35p_predict_tst.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4mSPpqO8oEz"
      },
      "source": [
        "## Retraining 'eye_tracking' model for subject and predicting eye track (pixel coordinate)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks_AbdKIb-xZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "from joblib import load as jload\n",
        "from joblib import dump as jdump\n",
        "import time\n",
        "import os\n",
        "# import tuning_parameters as tp"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0CCDk0XctDo",
        "outputId": "6680cd7a-1258-46c7-f3b8-ebf1b678683e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5XUNQBvcGf6"
      },
      "source": [
        "# Parameters\n",
        "PATH2PROJECT = \"/content/drive/MyDrive/Projects/EyeTracker/\"\n",
        "target_folder = \"subjects/\"\n",
        "\n",
        "# et_public_scaler_dir = PATH2PROJECT + f\"models/eye_tracking/trained/scalers{tp.EYE_TRACKING_MODEL_NUMBER}.bin\"\n",
        "# et_public_model_dir = PATH2PROJECT + f\"models/eye_tracking/trained/model{tp.EYE_TRACKING_MODEL_NUMBER}\"\n",
        "\n",
        "EYE_TRACKING_MODEL_NUMBER = 3\n",
        "et_public_scaler_dir = PATH2PROJECT + f\"models/eye_tracking/trained/scalers{EYE_TRACKING_MODEL_NUMBER}.bin\"\n",
        "et_public_model_dir = PATH2PROJECT + f\"models/eye_tracking/trained/model{EYE_TRACKING_MODEL_NUMBER}\"\n",
        "SUBJECT_NUM = 2\n",
        "CHOSEN_INPUTS = [0, 1, 2, 6, 7, 8, 9]\n",
        "\n",
        "R_TRAIN = 0.85\n",
        "N_EPOCHS = 100\n",
        "PATIENCE = 10\n",
        "TRAINABLE_LAYERS = 1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8AhjPqb8oE_"
      },
      "source": [
        "# subject_dir = PATH2PROJECT + target_folder + f\"/{tp.NUMBER}/\"\n",
        "subject_dir = PATH2PROJECT + target_folder + f\"{SUBJECT_NUM}/\"\n",
        "ibo_subject_scaler_dir = subject_dir + \"scalers_in_blink_out.bin\"\n",
        "ibo_subject_model_dir = subject_dir + \"model_in_blink_out\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGy7E9iA8oFA"
      },
      "source": [
        "### Retraining 'eye_tracking' model with subject calibration data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvzEN-j4cGFQ",
        "outputId": "8ae84f7e-2cca-4f92-d03d-43e5e5f431a4"
      },
      "source": [
        "et_clb_fol = subject_dir + \"eye_tracking data-calibration/\"\n",
        "print(f\"\\nLoading subject data in {et_clb_fol}\")\n",
        "with open(et_clb_fol + \"x1.pickle\", \"rb\") as f:\n",
        "    x1_load = pickle.load(f)\n",
        "with open(et_clb_fol + \"x2.pickle\", \"rb\") as f:\n",
        "    x2_load = pickle.load(f)\n",
        "with open(et_clb_fol + \"y.pickle\", \"rb\") as f:\n",
        "    y_load = pickle.load(f)\n",
        "n_smp, frame_height, frame_width = x1_load.shape[:-1]\n",
        "print(f\"Samples number: {n_smp}\")\n",
        "time.sleep(2)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading subject data in /content/drive/MyDrive/Projects/EyeTracker/subjects/2/eye_tracking data-calibration/\n",
            "Samples number: 7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdBBcjud--4"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "x4GOLYKnAWR-",
        "outputId": "2352588f-265d-49a7-d627-2ea272a4c1f2"
      },
      "source": [
        "# Displaying data\n",
        "SAMPLE_NUMBER = 50\n",
        "print(x2_load[SAMPLE_NUMBER])\n",
        "print(y_load[SAMPLE_NUMBER])\n",
        "plt.imshow(x1_load[SAMPLE_NUMBER].reshape((frame_height, frame_width)),\n",
        "           cmap=\"gray\", vmin=0, vmax=255)\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.77370058e+00 -7.44353733e-02 -2.00434757e-02  3.10411937e+00\n",
            "  3.51741753e+00  6.38527849e+01  4.75242794e-01  4.60822523e-01\n",
            "  4.91144359e-01  4.77497756e-01]\n",
            "[1844  508]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AzfSjqn8oFD"
      },
      "source": [
        "#### Getting those data that looking 'in' screen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWA57YKb8oFE",
        "outputId": "bcf52386-ae85-4ff9-af25-1f9415bebd56"
      },
      "source": [
        "print(\"\\nNormalizing data...\")\n",
        "# x2_chs_inp = x2_load[:, tp.CHOSEN_INPUTS]\n",
        "x2_chs_inp = x2_load[:, CHOSEN_INPUTS]\n",
        "scalers_ibo = jload(ibo_subject_scaler_dir)\n",
        "x1_scaler_ibo, x2_scaler_ibo = scalers_ibo\n",
        "x1 = x1_load / x1_scaler_ibo\n",
        "x2 = x2_scaler_ibo.transform(x2_chs_inp)\n",
        "time.sleep(2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ-ojxa18oFG",
        "outputId": "92885191-edcc-4664-fa23-d57e7c2b770e"
      },
      "source": [
        "print(\"\\nLoading in_blink_out model...\")\n",
        "model_ibo = load_model(ibo_subject_model_dir)\n",
        "print(model_ibo.summary())\n",
        "time.sleep(2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading in_blink_out model...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 44, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 48, 44, 16)   416         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 22, 16)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 24, 22, 32)   12832       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 11, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 10, 9, 64)    18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 5, 4, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          327936      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 263)          0           dense[0][0]                      \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          33792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           528         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 3)            51          dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 3)            12          dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 398,191\n",
            "Trainable params: 398,191\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGqOn_458oFH",
        "outputId": "9080e5e9-11ac-4e42-b39f-7c5aa5181ffb"
      },
      "source": [
        "print(\"\\nPredicting those data that looking 'in' screen.\")\n",
        "x = [x1, x2]\n",
        "yhat_ibo = model_ibo.predict(x).argmax(1)\n",
        "time.sleep(2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting those data that looking 'in' screen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFqmNyd8oFI",
        "outputId": "75cea127-1407-47f9-a7a9-ab1be5bcdf09"
      },
      "source": [
        "# Choosing those data\n",
        "x1_new = []\n",
        "x2_new = []\n",
        "y_new = []\n",
        "for (x10, x20, y0, yht0) in zip(x1_load, x2_load, y_load, yhat_ibo):\n",
        "    if True: # yht0 != 1:\n",
        "        x1_new.append(x10)\n",
        "        x2_new.append(x20)\n",
        "        y_new.append(y0)\n",
        "\n",
        "x1_new = np.array(x1_new)\n",
        "x2_new = np.array(x2_new)\n",
        "y_new = np.array(y_new)\n",
        "n_smp_new = x1_new.shape[0]\n",
        "print(f\"New samples: {n_smp_new}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New samples: 7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVhzAjUV8oFJ"
      },
      "source": [
        "### Preparing modified calibration data to feeding in eye_tracking model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2yHN0I9cF6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfd1167-179f-48b5-c016-91e9249c46eb"
      },
      "source": [
        "print(\"\\nNormalizing modified calibration data to feeding in eye_tracking model...\")\n",
        "# x2_chs_inp_new = x2_new[:, tp.CHOSEN_INPUTS]\n",
        "x2_chs_inp_new = x2_new[:, CHOSEN_INPUTS]\n",
        "scalers_et = jload(et_public_scaler_dir)\n",
        "x1_scaler_et, x2_scaler_et, _ = scalers_et\n",
        "\n",
        "x1_nrm = x1_new / x1_scaler_et\n",
        "x2_nrm = x2_scaler_et.transform(x2_chs_inp_new)\n",
        "\n",
        "y_scalers_et = y_new.max(0)\n",
        "y_nrm = y_new / y_scalers_et\n",
        "\n",
        "scalers_et[2] = y_scalers_et\n",
        "jdump(scalers_et, subject_dir + \"scalers_eye_tracking.bin\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Normalizing modified calibration data to feeding in eye_tracking model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Projects/EyeTracker/subjects/2/scalers_eye_tracking.bin']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNwyQAwL2pGS",
        "outputId": "9812cee4-8a01-4734-b479-81feed0099c2"
      },
      "source": [
        "# Shuffling and splitting data to train and test\n",
        "x1_shf, x2_shf, yx_shf, yy_shf = shuffle(x1_nrm, x2_nrm, y_nrm[:, 0], y_nrm[:, 1])\n",
        "\n",
        "n_train = int(R_TRAIN * n_smp_new)\n",
        "n_test = n_smp_new - n_train\n",
        "x1_train, x2_train = x1_shf[:n_train], x2_shf[:n_train]\n",
        "x1_test, x2_test = x1_shf[n_train:], x2_shf[n_train:]\n",
        "yx_train, yy_train = yx_shf[:n_train], yy_shf[:n_train]\n",
        "yx_test, yy_test = yx_shf[n_train:], yy_shf[n_train:]\n",
        "\n",
        "x_train = [x1_train, x2_train]\n",
        "x_test = [x1_test, x2_test]\n",
        "\n",
        "print(x1_train.shape, x1_test.shape, yx_train.shape, yx_test.shape,\n",
        "      x2_train.shape, x2_test.shape, yy_train.shape, yy_test.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5950, 48, 44, 1) (1050, 48, 44, 1) (5950,) (1050,) (5950, 7) (1050, 7) (5950,) (1050,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqdkxbYFcpuf"
      },
      "source": [
        "# Callback for training\n",
        "cb = EarlyStopping(patience=PATIENCE, verbose=1, restore_best_weights=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpT4PjQUcprr",
        "outputId": "a3aa1dfd-0002-41de-a4b3-9719987a58ea"
      },
      "source": [
        "print(\"Loading public eye_tracking models...\")\n",
        "model_x = load_model(et_public_model_dir + \"_x\")\n",
        "model_y = load_model(et_public_model_dir + \"_y\")\n",
        "# print(model1.summary())\n",
        "time.sleep(2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading public eye_tracking models...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgxSezv4jY70",
        "outputId": "5c8f1c31-0c46-4388-c243-de3247676f9d"
      },
      "source": [
        "for (layer1, layer2) in zip(model_x.layers[:-TRAINABLE_LAYERS], model_y.layers[:-TRAINABLE_LAYERS]):\n",
        "    layer1.trainable = False\n",
        "    layer2.trainable = False\n",
        "\n",
        "print(model_x.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 48, 44, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 48, 44, 16)   416         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 22, 16)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 24, 22, 32)   12832       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 11, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 10, 9, 64)    18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 5, 4, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1280)         0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400)          512400      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 407)          0           dense[0][0]                      \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 180)          73440       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           11584       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           1040        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 6)            102         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            7           dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 630,317\n",
            "Trainable params: 7\n",
            "Non-trainable params: 630,310\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diMNdUZZjeLQ",
        "outputId": "282ee5b4-fde4-49ee-c57c-3fc9ae03c483"
      },
      "source": [
        "print(\"\\nStart of training for model 1 (x-pixels)\")\n",
        "results_x = model_x.fit(x_train,\n",
        "                        yx_train,\n",
        "                        validation_data=(x_test, yx_test),\n",
        "                        epochs=N_EPOCHS,\n",
        "                        callbacks=cb)\n",
        "time.sleep(2)\n",
        "print(\"End of training\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of training for model 1 (x-pixels)\n",
            "Epoch 1/100\n",
            "186/186 [==============================] - 3s 11ms/step - loss: 0.0370 - val_loss: 0.0327\n",
            "Epoch 2/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0279 - val_loss: 0.0342\n",
            "Epoch 3/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0252 - val_loss: 0.0279\n",
            "Epoch 4/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0219 - val_loss: 0.0293\n",
            "Epoch 5/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0217 - val_loss: 0.0254\n",
            "Epoch 6/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0215 - val_loss: 0.0276\n",
            "Epoch 7/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0199 - val_loss: 0.0257\n",
            "Epoch 8/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0200 - val_loss: 0.0260\n",
            "Epoch 9/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0189 - val_loss: 0.0236\n",
            "Epoch 10/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0183 - val_loss: 0.0245\n",
            "Epoch 11/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0207 - val_loss: 0.0237\n",
            "Epoch 12/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0172 - val_loss: 0.0236\n",
            "Epoch 13/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0179 - val_loss: 0.0263\n",
            "Epoch 14/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0176 - val_loss: 0.0247\n",
            "Epoch 15/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0181 - val_loss: 0.0229\n",
            "Epoch 16/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0178 - val_loss: 0.0242\n",
            "Epoch 17/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0172 - val_loss: 0.0251\n",
            "Epoch 18/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0183 - val_loss: 0.0235\n",
            "Epoch 19/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0166 - val_loss: 0.0222\n",
            "Epoch 20/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0168 - val_loss: 0.0229\n",
            "Epoch 21/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0245\n",
            "Epoch 22/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0168 - val_loss: 0.0251\n",
            "Epoch 23/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0177 - val_loss: 0.0241\n",
            "Epoch 24/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0161 - val_loss: 0.0238\n",
            "Epoch 25/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0160 - val_loss: 0.0217\n",
            "Epoch 26/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0174 - val_loss: 0.0319\n",
            "Epoch 27/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0158 - val_loss: 0.0234\n",
            "Epoch 28/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0167 - val_loss: 0.0234\n",
            "Epoch 29/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0156 - val_loss: 0.0228\n",
            "Epoch 30/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.0225\n",
            "Epoch 31/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0150 - val_loss: 0.0211\n",
            "Epoch 32/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0142 - val_loss: 0.0231\n",
            "Epoch 33/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0210\n",
            "Epoch 34/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0150 - val_loss: 0.0215\n",
            "Epoch 35/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0252\n",
            "Epoch 36/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0170 - val_loss: 0.0215\n",
            "Epoch 37/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0148 - val_loss: 0.0222\n",
            "Epoch 38/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0144 - val_loss: 0.0234\n",
            "Epoch 39/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0136 - val_loss: 0.0223\n",
            "Epoch 40/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0135 - val_loss: 0.0198\n",
            "Epoch 41/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0134 - val_loss: 0.0212\n",
            "Epoch 42/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0128 - val_loss: 0.0206\n",
            "Epoch 43/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0257\n",
            "Epoch 44/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.0223\n",
            "Epoch 45/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0221\n",
            "Epoch 46/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0148 - val_loss: 0.0224\n",
            "Epoch 47/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0190 - val_loss: 0.0213\n",
            "Epoch 48/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0158 - val_loss: 0.0223\n",
            "Epoch 49/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0135 - val_loss: 0.0212\n",
            "Epoch 50/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0130 - val_loss: 0.0204\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00050: early stopping\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQz7jjQ5CTS8",
        "outputId": "f9c25499-ae97-4d66-8bfd-d5e13d35585d"
      },
      "source": [
        "print(\"\\nStart of training for model 2 (y-pixels)\")\n",
        "results_y = model_y.fit(x_train,\n",
        "                        yy_train,\n",
        "                        validation_data=(x_test, yy_test),\n",
        "                        epochs=N_EPOCHS,\n",
        "                        callbacks=cb)\n",
        "time.sleep(2)\n",
        "print(\"End of training\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of training for model 2 (y-pixels)\n",
            "Epoch 1/100\n",
            "186/186 [==============================] - 2s 10ms/step - loss: 0.0885 - val_loss: 0.0698\n",
            "Epoch 2/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0621 - val_loss: 0.0574\n",
            "Epoch 3/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0553 - val_loss: 0.0715\n",
            "Epoch 4/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0526 - val_loss: 0.0526\n",
            "Epoch 5/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0472 - val_loss: 0.0540\n",
            "Epoch 6/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0468 - val_loss: 0.0481\n",
            "Epoch 7/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0407 - val_loss: 0.0442\n",
            "Epoch 8/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0391 - val_loss: 0.0549\n",
            "Epoch 9/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0409 - val_loss: 0.0424\n",
            "Epoch 10/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0381 - val_loss: 0.0363\n",
            "Epoch 11/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0357 - val_loss: 0.0404\n",
            "Epoch 12/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0352 - val_loss: 0.0460\n",
            "Epoch 13/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0323 - val_loss: 0.0429\n",
            "Epoch 14/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0358 - val_loss: 0.0394\n",
            "Epoch 15/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0342 - val_loss: 0.0383\n",
            "Epoch 16/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0320 - val_loss: 0.0459\n",
            "Epoch 17/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0321 - val_loss: 0.0353\n",
            "Epoch 18/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0306 - val_loss: 0.0343\n",
            "Epoch 19/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0293 - val_loss: 0.0377\n",
            "Epoch 20/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0268 - val_loss: 0.0311\n",
            "Epoch 21/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0260 - val_loss: 0.0346\n",
            "Epoch 22/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0245 - val_loss: 0.0348\n",
            "Epoch 23/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0295 - val_loss: 0.0283\n",
            "Epoch 24/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0268 - val_loss: 0.0329\n",
            "Epoch 25/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0265 - val_loss: 0.0340\n",
            "Epoch 26/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0264 - val_loss: 0.0307\n",
            "Epoch 27/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0253 - val_loss: 0.0397\n",
            "Epoch 28/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0238 - val_loss: 0.0364\n",
            "Epoch 29/100\n",
            "186/186 [==============================] - 2s 9ms/step - loss: 0.0225 - val_loss: 0.0252\n",
            "Epoch 30/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0219 - val_loss: 0.0255\n",
            "Epoch 31/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0217 - val_loss: 0.0309\n",
            "Epoch 32/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0239 - val_loss: 0.0279\n",
            "Epoch 33/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0194 - val_loss: 0.0286\n",
            "Epoch 34/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0194 - val_loss: 0.0257\n",
            "Epoch 35/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0199 - val_loss: 0.0306\n",
            "Epoch 36/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0224 - val_loss: 0.0295\n",
            "Epoch 37/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0200 - val_loss: 0.0297\n",
            "Epoch 38/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0180 - val_loss: 0.0265\n",
            "Epoch 39/100\n",
            "186/186 [==============================] - 2s 8ms/step - loss: 0.0168 - val_loss: 0.0282\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00039: early stopping\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCu14ufb8oFN",
        "outputId": "55beefd3-f9e9-4338-8b26-4486771d830e"
      },
      "source": [
        "print(\"\\nSaving models...\")\n",
        "model_x.save(subject_dir + \"model_eye_tracking_x\")\n",
        "model_y.save(subject_dir + \"model_eye_tracking_y\")\n",
        "time.sleep(2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving models...\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Projects/EyeTracker/subjects/2/model_eye_tracking_x/assets\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Projects/EyeTracker/subjects/2/model_eye_tracking_y/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9L074ihCXD6"
      },
      "source": [
        "# Predicting outputs for train and test data\n",
        "yx_hat_train = model_x.predict(x_train).reshape((n_train,))\n",
        "yx_hat_test = model_x.predict(x_test).reshape((n_test,))\n",
        "yy_hat_train = model_y.predict(x_train).reshape((n_train,))\n",
        "yy_hat_test = model_y.predict(x_test).reshape((n_test,))\n",
        "\n",
        "yx_hat_train[yx_hat_train < 0] = 0\n",
        "yx_hat_test[yx_hat_test < 0] = 0\n",
        "yy_hat_train[yy_hat_train < 0] = 0\n",
        "yy_hat_test[yy_hat_test < 0] = 0"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "FDC8rCcVjjDa",
        "outputId": "48c3b4f3-1946-4554-b0e9-6ae7c0ca6120"
      },
      "source": [
        "# Displaying data\n",
        "NUM = 2\n",
        "print(\"Train\")\n",
        "sample_train = (int(yx_train[NUM] * y_scalers_et[0]),\n",
        "                int(yy_train[NUM] * y_scalers_et[1]))\n",
        "sample_hat_train = (int(yx_hat_train[NUM] * y_scalers_et[0]),\n",
        "                    int(yy_hat_train[NUM] * y_scalers_et[1]))\n",
        "print(sample_train)\n",
        "print(sample_hat_train)\n",
        "\n",
        "print(\"Test\")\n",
        "sample_test = (int(yx_test[NUM] * y_scalers_et[0]),\n",
        "                int(yy_test[NUM] * y_scalers_et[1]))\n",
        "sample_hat_test = (int(yx_hat_test[NUM] * y_scalers_et[0]),\n",
        "                    int(yy_hat_test[NUM] * y_scalers_et[1]))\n",
        "print(sample_test)\n",
        "print(sample_hat_test)\n",
        "\n",
        "_, ax = plt.subplots(1,2)\n",
        "ax[0].imshow((x1_train[NUM] * x1_scaler_et).astype(np.uint8).\n",
        "           reshape((frame_height, frame_width)), cmap=\"gray\",vmin=0, vmax=255)\n",
        "ax[1].imshow((x1_test[NUM] * x1_scaler_et).astype(np.uint8).\n",
        "           reshape((frame_height, frame_width)), cmap=\"gray\",vmin=0, vmax=255)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "(3668, 507)\n",
            "(3632, 507)\n",
            "Test\n",
            "(1843, 507)\n",
            "(2008, 525)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fddd87b7850>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXSSVV778oFP"
      },
      "source": [
        "### Getting sampling data that looking 'in' screen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A89vgRT88oFP",
        "outputId": "7be8e6ed-6f3b-4ec0-d134-5c51d5c16a68"
      },
      "source": [
        "eye_tracking_smp_dir = subject_dir + \"sampling data/\"\n",
        "print(f\"\\nLoading subject sampling data in {eye_tracking_smp_dir}\")\n",
        "with open(eye_tracking_smp_dir + \"t.pickle\", \"rb\") as f:\n",
        "    t_smp_load = pickle.load(f)\n",
        "with open(eye_tracking_smp_dir + \"x1.pickle\", \"rb\") as f:\n",
        "    x1_smp_load = pickle.load(f)\n",
        "with open(eye_tracking_smp_dir + \"x2.pickle\", \"rb\") as f:\n",
        "    x2_smp_load = pickle.load(f)\n",
        "\n",
        "n_sampling= t_smp_load.shape[0]\n",
        "print(f\"Number of sampling data : {n_sampling}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading subject sampling data in /content/drive/MyDrive/Projects/EyeTracker/subjects/2/sampling data/\n",
            "Number of sampling data : 604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44uvMv2b8oFQ"
      },
      "source": [
        "# Normalizing Sampling data for 'in_blink_out' model\n",
        "# x2_smp_chs_inp = x2_smp_load[:, tp.CHOSEN_INPUTS]\n",
        "x2_smp_chs_inp = x2_smp_load[:, CHOSEN_INPUTS]\n",
        "x1_smp = x1_smp_load / x1_scaler_ibo\n",
        "x2_smp = x2_scaler_ibo.transform(x2_smp_chs_inp)\n",
        "x_smp = [x1_smp, x2_smp]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_UMXhI68oFR",
        "outputId": "0ed86366-9414-4c01-a0f3-f743e866e6e4"
      },
      "source": [
        "print(\"\\nPredicting those data that looking 'in' screen...\")\n",
        "yhat_smp_ibo = model_ibo.predict(x_smp).argmax(1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting those data that looking 'in' screen...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AZ_BVnU8oFR",
        "outputId": "88e61602-22d4-43fc-c8c0-89c52e02ef85"
      },
      "source": [
        "# Choosing those data\n",
        "t_smp_new = []\n",
        "x1_smp_new = []\n",
        "x2_smp_new = []\n",
        "for (t0, x10, x20, yht0) in zip(t_smp_load, x1_smp_load, x2_smp_load, yhat_smp_ibo):\n",
        "    if True: # yht0 == 0:\n",
        "        t_smp_new.append(t0)\n",
        "        x1_smp_new.append(x10)\n",
        "        x2_smp_new.append(x20)\n",
        "\n",
        "t_smp_new = np.array(t_smp_new)\n",
        "x1_smp_new = np.array(x1_smp_new)\n",
        "x2_smp_new = np.array(x2_smp_new)\n",
        "n_sampling_new = x1_smp_new.shape[0]\n",
        "print(f\"New samples: {n_sampling_new}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New samples: 604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1c4gEd_8oFS"
      },
      "source": [
        "### Predicting eye track for samling data in pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMJFqQru8oFS"
      },
      "source": [
        "# Normalizing Sampling data for 'eye_tracking' model\n",
        "# x2_smp_new_chs_inp = x2_smp_new[:, tp.CHOSEN_INPUTS]\n",
        "x2_smp_new_chs_inp = x2_smp_new[:, CHOSEN_INPUTS]\n",
        "x1_smp_nrm = x1_smp_new / x1_scaler_et\n",
        "x2_smp_nrm = x2_scaler_et.transform(x2_smp_new_chs_inp)\n",
        "x_smp = [x1_smp_nrm, x2_smp_nrm]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhGRU1Gp8oFS",
        "outputId": "b56be31f-2332-4b59-c6b4-c46b3ffc186b"
      },
      "source": [
        "print(\"\\nPredicting sampling data...\")\n",
        "yx_hat_smp = np.expand_dims(model_x.predict(x_smp).reshape((n_sampling_new,)), 1)\n",
        "yy_hat_smp = np.expand_dims(model_y.predict(x_smp).reshape((n_sampling_new,)), 1)\n",
        "\n",
        "pixels = (np.concatenate([yx_hat_smp, yy_hat_smp], 1) * y_scalers_et).astype(np.uint32)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting sampling data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz2knxtl8oFT",
        "outputId": "daa99dbb-be51-4072-9232-e7e313026a7d"
      },
      "source": [
        "eye_tracking_pixels_dir = subject_dir + \"sampling data-pixels/\"\n",
        "if not os.path.exists(eye_tracking_pixels_dir):\n",
        "    os.mkdir(eye_tracking_pixels_dir)\n",
        "\n",
        "with open(eye_tracking_pixels_dir + \"t.pickle\", 'wb') as f:\n",
        "    pickle.dump(t_smp_new, f)\n",
        "with open(eye_tracking_pixels_dir + \"pixels.pickle\", 'wb') as f:\n",
        "    pickle.dump(pixels, f)\n",
        "print(\"\\nPixel data saved!!\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pixel data saved!!\n"
          ]
        }
      ]
    }
  ]
}