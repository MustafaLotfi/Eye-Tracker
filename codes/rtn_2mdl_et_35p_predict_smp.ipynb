{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4mSPpqO8oEz"
   },
   "source": [
    "## Retraining 'eye_tracking' model for subject and predicting eye track (pixel coordinate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ks_AbdKIb-xZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import load as jload\n",
    "from joblib import dump as jdump\n",
    "import time\n",
    "import os\n",
    "import tuning_parameters as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "T5XUNQBvcGf6"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "target_folder = \"../subjects/\"\n",
    "et_public_scaler_dir = f\"../models/eye_tracking/trained/scalers{tp.EYE_TRACKING_MODEL_NUMBER}.bin\"\n",
    "et_public_model_dir = f\"../models/eye_tracking/trained/model{tp.EYE_TRACKING_MODEL_NUMBER}\"\n",
    "CHOSEN_INPUTS = [0, 1, 2, 6, 7, 8, 9]\n",
    "R_TRAIN = 0.85\n",
    "N_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "TRAINABLE_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C8AhjPqb8oE_"
   },
   "outputs": [],
   "source": [
    "subject_dir = target_folder + f\"{tp.NUMBER}/\"\n",
    "ibo_subject_scaler_dir = subject_dir + \"scalers_in_blink_out.bin\"\n",
    "ibo_subject_model_dir = subject_dir + \"model_in_blink_out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGy7E9iA8oFA"
   },
   "source": [
    "### Retraining 'eye_tracking' model with subject calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvzEN-j4cGFQ",
    "outputId": "8ae84f7e-2cca-4f92-d03d-43e5e5f431a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading subject data in ../subjects/6/eye_tracking data-calibration/\n",
      "Samples number: 52\n"
     ]
    }
   ],
   "source": [
    "et_clb_fol = subject_dir + \"eye_tracking data-calibration/\"\n",
    "print(f\"\\nLoading subject data in {et_clb_fol}\")\n",
    "with open(et_clb_fol + \"x1.pickle\", \"rb\") as f:\n",
    "    x1_load = pickle.load(f)\n",
    "with open(et_clb_fol + \"x2.pickle\", \"rb\") as f:\n",
    "    x2_load = pickle.load(f)\n",
    "with open(et_clb_fol + \"y.pickle\", \"rb\") as f:\n",
    "    y_load = pickle.load(f)\n",
    "n_smp, frame_height, frame_width = x1_load.shape[:-1]\n",
    "print(f\"Samples number: {n_smp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ygdBBcjud--4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "x4GOLYKnAWR-",
    "outputId": "2352588f-265d-49a7-d627-2ea272a4c1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.81267074e+00 -5.59678072e-02 -1.58439390e-02  2.69127362e+00\n",
      " -4.08844976e+00  4.11091549e+01  4.95338112e-01  4.82825249e-01\n",
      "  5.43821454e-01  4.88673061e-01]\n",
      "[3041   21]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOkAAAD6CAYAAABEdWDWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYYUlEQVR4nO2dX4hd13XGv6W/M9LIksc1Qlimdolp8EMrg3AT3Ifg1OC6IfaDKXFCUUGglxYckhLLLZQGWrBf4gRaUgQ2USFETpqAjEgJqupQAsW2LDupbeFIMYTIlq2WRrij/7JXH+4Zd2bdded8d8+59+6Rvh8Izdmzz97rnHPXnLvWXnstc3cIIepl1aQFEEIsjZRUiMqRkgpROVJSISpHSipE5UhJhaicZSmpmd1vZm+a2Ukz29uVUEKI/8dK10nNbDWAnwO4D8ApAC8BeMTd3xh0ztq1a31qaqpovjYmvd5rZkOfk8kcxxn3dcX5sutiZCq5H6Uw8mR9Su4tc11Zn9gWjy9evIgrV66kg68ZRsDA3QBOuvtbzaQHADwIYKCSTk1NYceOHUsOumpV/8s9XtAHH3zQ1yfe8KwPw+rVq5ccN5NnUFsbpUrKKBJDdo+uXr266Djej0HnRdasWc5Hazg+/PDDvrZ4HaV94r3Nris+j3Xr1vX1iefFPseOHes7Z57lfN29BcCvFhyfatqEEB0y8j93ZrYHwB4AWL9+/ainE+KaYzlv0rcB3LrgeHvTtgh33+fuO91959q1a5cxnRDXJ8t5k74E4A4zux095fwcgM+3Thi+m8fv810Z+Jlty1BqyzJkNk/JOdGWKh0naytxCmX3mrFtY1vpM8vOi5+z7Frjecw9yj4fcRzmHg7zWShWUne/amZ/DuBHAFYDeMbdXy8dTwiRsyyb1N1/COCHHckihEhQxJEQlTO+xSz0bJm2Nb2uFu+7skEy+4+xCUvsT5Y4f3bPor3HysOswTJjxXud2Y1xrTCzW5l1ygxm7ZixgZl7zbCcz7XepEJUjpRUiMqRkgpROVJSISpnrI6jjLbdAUDZLofsnMuXLy86zhxAjOMojsNSch1MwAG7CSCSOWoimaMmypTNzziXYmBAJk9b8Mug8+L8mZMo9snuWTyPCXZhAnKYZ/iRDK0zCiEmipRUiMqRkgpROWO1Sd29dbE8sx0YWy7ajpkteenSpUXHmW3J2FJMMENmuzB2Ujwvmyv2Yex41paLbVkmjWgnMvZvNn98Htn9iDunsufDBDgw9ncmY0kATNYnPrNhNhPoTSpE5UhJhagcKakQlSMlFaJyxh7M0MUul8wwv3LlyqLjc+fOFY3DOIXiXAAXhMA4yZi5oowlKSQHyRidORcvXuzrE3NVTU9P9/WJO1yY7AmZs40JHmCcSV2lIWWCIkrHHjhn8ZlCiLEgJRWicqSkQlTOxG3SkoDyzE6KtlS2wB1tuczei22ZjcoEYmfzx8CArA9jSzPZCmIbk9EP6L/+zCaM95pZ4M/sViYIIc7P2OhZW5ZOtqtSGCXZG5jginn0JhWicqSkQlSOlFSIypGSClE5Y3cclaS6ZJwHzK6P6HCKDpDsvKzIVFbaLjomst0jcazsOqKMpTtMGDLnRVeZIZhSlNFx1GW5RKZcZsnOmNJdMMM4iiJ6kwpROVJSISpHSipE5Uw8WyBjuzAL7ExGg8wGjER7c+PGjX19NmzY0HpeZrdGOymTkSnzEAMTmMwMrC+gqwX+KGNm20c7rSu7EeCuo6TMJVtCsm2ueKxsgUKsYKSkQlSOlFSIypGSClE51TmOMgO6ZJcBE/CQOXdmZmYWHWdOoixQITo4sl0XJVkGGMdRNld01DDZLErJZGSCOyKMA4YpKcGe15XjiGEYR1FEb1IhKkdKKkTltCqpmT1jZmfM7LUFbbNmdtjMTjT/3zhaMYW4fmFs0m8B+HsA/7SgbS+AI+7+hJntbY4fKxEgfsdnAhWYzHdMWYXMTtq0adOi42wRnsnO10VWxEHjxLkyGaNtndlS77//fl8bky2RIQbLZzJGmECWLMMEE8yR9YkylgYqlJS07DSYwd3/HcD/hOYHAexvft4P4KFWKYUQRZTapFvd/XTz87sAtnYkjxAisGzHkffe0wPf1Wa2x8yOmtnRrlz+QlxPlCrpe2a2DQCa/88M6uju+9x9p7vvzNbzhBBLUxrM8ByAXQCeaP4/yJzk7kWLwdFZkGVUiLVGM0dBDF5g0jyyZQWYgAtm9wrjgGL6MM42Ju0p87yYEhLZvY5yl8rDBHxkxD6lzj5mx1F0WnYazGBm3wHwHwB+28xOmdlu9JTzPjM7AeAPmmMhxAhofZO6+yMDfvXpjmURQiQo4kiIypl4tsASO4C1ryLRBskWz+fm5pY8h50rG5spDxFtNyYTX7THgX4baHZ2tq9PDHgAgHfeeWfRMVNmIwtUiBktss0McWzmvmbXmo1dkp2PyZ7IjMv4LOJKhzIzCLGCkZIKUTlSUiEqR0oqROVMPDMDk3qRqf1ZQmasR6M/C5xgHFdMtoKsT3TmnD9/vq9PJlOEqemaOWGiQyNzgsRrzXYTxWtlUqxm8sT5MycV83koDQphdmkxzlAm48Yg9CYVonKkpEJUjpRUiMqRkgpRORN3HHVFjARhDHMmVUjmKGDqmjJRMJnDI6ZvOXfuXKtMmXPnwoULi46zvbxMupAswiY6irK0p9HZx9RizRxHbXMD+Q6bOB+T4rV0x0+JU0gpPYW4hpCSClE5UlIhKmfsNmn8Th+/z2ff+ZlgBmYchjhOZrdmY8d+WZ9oS2bXMT09veh48+bNfX2ifRXtz0weNlUnU8Ii7nDJAgzitWY2YbRBGRlLsydk9ma8VmaHS3YdJQE5w6A3qRCVIyUVonKkpEJUjpRUiMoZq+PIzFodRxnxHDbNZjb/QpjdChlZH8ZRwqR1jNeWpThhUm9EpwzjOAH671F0ZGVt2fwx4CO7H0xQRmzLdvMw9YOY55oFoDA1ZRjH0TC7XiJ6kwpROVJSISpHSipE5Uw8wH5U5QCYcgRZMEGp3crs4I9jZ32YBfUYhJ/dw5jRgcmwkM3PyJMFIcRrY/owdmM2Dmtvl1CSKjYj3sdh5NObVIjKkZIKUTlSUiEqR0oqROVU5zjKFn0ZR1E8j9lRkc0VDXxmoTybL3M4xACD7LqYauhR7ixbQVyYZ+vCMgEXJQEopQWkSwNZsmfU1ofZ8ZR9Zkpq7g6TSURvUiEqR0oqROVISYWonInbpAxMgAGTvaHETmVqVg5qizCL90xAd7y2TMZ4HpPxIoMJKGeeBwMT8M8GqkeZMhs19mHsb8b+ZJ6HykwIcQ0hJRWicqSkQlROq5Ka2a1m9ryZvWFmr5vZo037rJkdNrMTzf83jl5cIa4/GMfRVQBfdvdjZrYJwMtmdhjAnwI44u5PmNleAHsBPNY2GLNYHmHS+MdxMidEdLiUZmFgdoZkMA6X6OBg5mIcHtk4Xe0UKS3PUNKHPa8kU0dGiaOIqYXKBEl81LdNAHc/7e7Hmp//F8BxALcAeBDA/qbbfgAPtY0lhBieoZZgzOw2AHcBeAHAVnc/3fzqXQBbB5yzB8AeIE+iLIRYGvr7hZnNAPg+gC+6+/sLf+e993v6vdXd97n7TnffWRq/KcT1DPUmNbO16Cnot939B03ze2a2zd1Pm9k2AGfIsZY8ZhbGs+/vTEB1myzZ/KydxPRjFtij3dyV3Via5S6j9B51NX+ECQph5i+Vp2ScTjMzWG/GpwEcd/evLfjVcwB2NT/vAnCQnlUIQcO8Se8B8CcA/tPMXm3a/hLAEwC+a2a7AfwSwB+PREIhrnNaldTdfwJg0Pv7092KI4SIKOJIiMoZe5mJLpwFzM4QZpd96S4UZmcMc53ZOCX1WjOYjAalWTBKMhGw83c1N1NntiRQgXFQltTYVWYGIVYwUlIhKkdKKkTljD0zQ1vAeGl2ukhmF5QscDPnAFxAO2ODlZQ16LLMQlcyMvetpA/7WWCycDBjDWM7LkVJ+Y559CYVonKkpEJUjpRUiMqRkgpROWN1HK1ataqvJELJjgpm53vpro/oTGDmYsbJ2pjyCJkDhElFyWQLKE1NWpL1oDR9aFe7gJjsDVmJDyZIhQkciQ6oqAdLOeP0JhWicqSkQlSOlFSIypGSClE51UUclabCKDmnq+imbCzmOkoioFiYOqeM44ipz8rs+uiqFk3p/WCea5aDq6tnNkwKz75z6Z5CiIkgJRWicqSkQlTOxDMzdBXMwPRh7EbGdmFs2dJal0wwQ+yT2Y2lJTTifF3ZYMwCP7O7JuvTVWpQhnHONY/epEJUjpRUiMqRkgpROVJSISpn7MEMozK8GQdHdIowjqNs3CxQIDpvmNqjmVMotjG7YDLHUVfpS0a5CyVeW+YUats9Aoy29mrJ55VJXzpMgI7epEJUjpRUiMqRkgpROWO3SdtgSh8wgQLMAv/ly5f7+jB246VLl/raop3KBAowNmk2TmlmiEhmyzEBBtHmKtkAkZ138eLFvj5M6svMTi2xJScRqMCgN6kQlSMlFaJypKRCVI6UVIjKmbjjqMRYL80oEJ07meMoOoWyPllbHDuTMTqFGMcV4wBjnG1MTVcAWL9+/aLjbGE+ZjDIMhow9WKjjJk8zD1j6v50nS1hqbkYlJlBiGsIKakQldOqpGY2ZWYvmtlPzex1M/tq0367mb1gZifN7FkzWzd6cYW4/mBs0ksA7nX3OTNbC+AnZvYvAL4E4Cl3P2Bm/whgN4BvLjWQu1MB7G0wQe/nz5/v6xMXy5lA+cwGunDhQl8bUw+TsTeztkhXdVaz64/BA0xGBUaeLOAgkgUzxOvI7k/2rGdmZhYdZ0ERcayu7NbSjRuDaH2Teo+55nBt888B3Avgn5v2/QAeomcVQtBQNqmZrTazVwGcAXAYwC8AnHX3+dfHKQC3jERCIa5zKCV19w/cfQeA7QDuBvBxdgIz22NmR83saPbVUQixNEN5d939LIDnAXwSwBYzmzdOtgN4e8A5+9x9p7vvXLdOviUhhqXVcWRmNwO44u5nzWwawH0AnkRPWR8GcADALgAHSwQoSbOZGd0xCCFzQkTnTuaEiOdlDiFmZwpzHrNTJXPcMDtDmLFLU4FGJ1DmTGGuNV5b9kc8XivjoAO4MhvMfYwwO7CYLBTDvLAY7+42APvNbDV6b97vuvshM3sDwAEz+1sArwB4mp5VCEHTqqTu/jMAdyXtb6FnnwohRogijoSonLEH2LfZoIxNygTGMwHdmd0Sx87srenp6b62uMCf2cRx0Z2xbZmSgZmMsY0t6RjvUWa3RZuUCXBnnkcGc61MmcmsT4lNmsHMFa9jmOAGvUmFqBwpqRCVIyUVonKkpEJUzopwHDG7R5i6msw40TGR7d7YvHlzX1t0DMzNzfX1iU4pxpnDOIUyB0hcLGfqnA6ar23szJEWx2bSoGYw2RsYZyPjXGLuNVPSg8kcMgx6kwpROVJSISpHSipE5VRX+rDUJo3nsTZYJNpXN9xwQ1+fLVu29LUxgRLRbi0tzxevNbObY1smDyNjBlOOkCm7wWRGYJ5ZZqeWZMHo6nlkyCYV4hpGSipE5UhJhagcKakQlTPxMhMRZud7SUrL7Lxsd3xsY7IFZJSWXmAWz9vGBfqdOVkfpswFU5+0tDxDHIe5r2ygQLz/mYzx/mfXysB8HuNnOF7rUvdQb1IhKkdKKkTlSEmFqJyx2qRm1rpgzJQDYEofZMQ+TNYDNigilgzcuHFjX59oJ2blKtpsl2yuzG6OmSGyUgzZdURbLs6V9WH8CBnxeTBlHrJxs+D9trkArlwmY2/HZ1SaBXJgX7qnEGIiSEmFqBwpqRCVIyUVonLGHswQjWzG6GZ2j5QsXjNk8mRBAHH+LFtB3D2T7UJhnCCM4yhea3bPsnsUx96wYUNrHyalJ5M9gdmpko2TXT/j8GGcNyXBJRnRccV8XufRm1SIypGSClE5UlIhKkdKKkTljD3iKDqKSuqaZFE4jKOAMfoZeTIHVHQCZZE6mzZtWnScRRxFGbO5GOdSPC8bJ3OcREfRzMxMX5/o9GDua+bwifeMqenKRIkBZQ4f1rkWYernxHGis2spJ5bepEJUjpRUiMqRkgpRORO3SZkd6iU1KrOdGdEOYEoPZDB2IrNTJwt4OHfu3KJjJhUnY8tl15UFKkQbNJOxTZ6sLQsAYdJ+xmvL7D1m1wlTnzQbm8kWwdit8dnHXVKySYVYwUhJhagcWknNbLWZvWJmh5rj283sBTM7aWbPmll/AKUQYtkM8yZ9FMDxBcdPAnjK3T8G4NcAdncpmBCiB+U4MrPtAP4IwN8B+JL1LOV7AXy+6bIfwN8A+GbbWG3BDMyOigEyLjoudSZER0XWhwlwyAIOovMgC3iIzhwmcIJZqM9SjGaBCllbJF5bdq0xfUvmXGLuNROUwZA5gJhdMPG87LPIpHhpcxp24Tj6OoCvAJif/SYAZ919/o6dAnALOZYQYghaldTMPgPgjLu/XDKBme0xs6NmdpQJZxNCLIb5unsPgM+a2QMApgDcAOAbALaY2ZrmbbodwNvZye6+D8A+ALjpppvK678JcZ3SqqTu/jiAxwHAzD4F4C/c/Qtm9j0ADwM4AGAXgINtY5lZn200SpuDkScSbYPM3mNsZOa8zA7J6qFG5ubmWueK17Z58+a+PrOzs31t8T5mmwCYQIXSgPY2ebJxmaD7LKVn/CwynyEmCD/rE9O5jiuY4TH0nEgn0bNRn17GWEKIAQwVFujuPwbw4+bntwDc3b1IQoiFKOJIiMqRkgpROWPdBbNq1aq+Bfy48Muk9GR2rzDBDJkTIp6XOZcYpxCzM4XZwR+zOQBcwAHjOMnIasa0jZ050tqCVgDu2Ue5mXqpmUzD1F5ZCuZzlT3X6DiKO7KU0lOIFYyUVIjKkZIKUTljLzPRFmTO2KRszdASmIVpxgaKAeZZn+w6mMyIjE0YYTITZGMxWTAYmMCR7L4ytm1plj8mUKJkw0W2mSFunFCZCSGuIaSkQlSOlFSIypGSClE5Y0/pmRnVbZSUomAW2DMYx0nWFs/LFt1Ld/i0kTk8mFSp2T1iyjowjqoIex/b5CnZ7QTk18HUPi3JCpJl3IiZGOLnQ44jIVYwUlIhKkdKKkTlTNwmZRa0S8rPldgS7DiMLZfZ3sxGgRKYe1ZqE04aJjCeeUZMH+Z5MMEUmU0aA+yHsa31JhWicqSkQlSOlFSIypGSClE51dUnZbIVlC46t42bwWRYyGB3a7TBXGsmIxMAUhoYwNCVU6ok4IEdh3EuleymyRxHbbteFMwgxApGSipE5UhJhaicsdukbVnrmGxwpQvTJRkMWDuSsW8YO7GkhAVjN2X3lZm/q8D4UjuemZsJLim1kZlMHdHejIELwHDZASN6kwpROVJSISpHSipE5UhJhagcKwkCKJ7M7L8A/BLAbwD477FN3A0rUWZgZcp9Pcr8m+5+c/aLsSrpR5OaHXX3nWOfeBmsRJmBlSm3ZF6Mvu4KUTlSUiEqZ1JKum9C8y6HlSgzsDLllswLmIhNKoTg0dddISpn7EpqZveb2ZtmdtLM9o57fgYze8bMzpjZawvaZs3ssJmdaP6/cZIyRszsVjN73szeMLPXzezRpr1auc1sysxeNLOfNjJ/tWm/3cxeaD4jz5rZuraxxo2ZrTazV8zsUHM8MpnHqqRmthrAPwD4QwB3AnjEzO4cpwwk3wJwf2jbC+CIu98B4EhzXBNXAXzZ3e8E8AkAf9bc25rlvgTgXnf/XQA7ANxvZp8A8CSAp9z9YwB+DWD35EQcyKMAji84Hp3M7j62fwA+CeBHC44fB/D4OGUYQtbbALy24PhNANuan7cBeHPSMrbIfxDAfStFbgAbABwD8HvoBQWsyT4zNfwDsB29P3j3AjgEwEYp87i/7t4C4FcLjk81bSuBre5+uvn5XQBbJynMUpjZbQDuAvACKpe7+dr4KoAzAA4D+AWAs+4+nxOmxs/I1wF8BcD8fribMEKZ5TgqwHt/Lqt0i5vZDIDvA/iiu7+/8Hc1yu3uH7j7DvTeTncD+PhkJVoaM/sMgDPu/vK45hzrpm8AbwO4dcHx9qZtJfCemW1z99Nmtg29v/xVYWZr0VPQb7v7D5rm6uUGAHc/a2bPo/dVcYuZrWneTLV9Ru4B8FkzewDAFIAbAHwDI5R53G/SlwDc0XjC1gH4HIDnxixDKc8B2NX8vAs9m68arLfV/2kAx939awt+Va3cZnazmW1pfp5Gz4Y+DuB5AA833aqS2d0fd/ft7n4bep/ff3P3L2CUMk/A6H4AwM/Rsz3+atJOgAEyfgfAaQBX0LMvdqNndxwBcALAvwKYnbScQebfR++r7M8AvNr8e6BmuQH8DoBXGplfA/DXTftvAXgRwEkA3wOwftKyDpD/UwAOjVpmRRwJUTlyHAlROVJSISpHSipE5UhJhagcKakQlSMlFaJypKRCVI6UVIjK+T8qCBlyNwV44wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying data\n",
    "SAMPLE_NUMBER = 20\n",
    "print(x2_load[SAMPLE_NUMBER])\n",
    "print(y_load[SAMPLE_NUMBER])\n",
    "plt.imshow(x1_load[SAMPLE_NUMBER].reshape((frame_height, frame_width)),\n",
    "           cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AzfSjqn8oFD"
   },
   "source": [
    "#### Getting those data that looking 'in' screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWA57YKb8oFE",
    "outputId": "bcf52386-ae85-4ff9-af25-1f9415bebd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Education_Study\\University\\MSC\\Thesis\\EyeTracker\\venv\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNormalizing data...\")\n",
    "x2_chs_inp = x2_load[:, tp.CHOSEN_INPUTS]\n",
    "scalers_ibo = jload(ibo_subject_scaler_dir)\n",
    "x1_scaler_ibo, x2_scaler_ibo = scalers_ibo\n",
    "x1 = x1_load / x1_scaler_ibo\n",
    "x2 = x2_scaler_ibo.transform(x2_chs_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJ-ojxa18oFG",
    "outputId": "92885191-edcc-4664-fa23-d57e7c2b770e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading in_blink_out model...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 44, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 44, 16)   416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 22, 16)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 22, 32)   12832       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 11, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 9, 64)    18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 4, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1280)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          327936      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 263)          0           dense[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          33792       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           4128        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            51          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3)            12          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 398,191\n",
      "Trainable params: 398,191\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading in_blink_out model...\")\n",
    "model_ibo = load_model(ibo_subject_model_dir)\n",
    "print(model_ibo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGqOn_458oFH",
    "outputId": "9080e5e9-11ac-4e42-b39f-7c5aa5181ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting those data that looking 'in' screen.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicting those data that looking 'in' screen.\")\n",
    "x = [x1, x2]\n",
    "yhat_ibo = model_ibo.predict(x).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySFqmNyd8oFI",
    "outputId": "75cea127-1407-47f9-a7a9-ab1be5bcdf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New samples: 52\n"
     ]
    }
   ],
   "source": [
    "# Choosing those data\n",
    "x1_new = []\n",
    "x2_new = []\n",
    "y_new = []\n",
    "for (x10, x20, y0, yht0) in zip(x1_load, x2_load, y_load, yhat_ibo):\n",
    "    if True: # yht0 != 1:\n",
    "        x1_new.append(x10)\n",
    "        x2_new.append(x20)\n",
    "        y_new.append(y0)\n",
    "\n",
    "x1_new = np.array(x1_new)\n",
    "x2_new = np.array(x2_new)\n",
    "y_new = np.array(y_new)\n",
    "n_smp_new = x1_new.shape[0]\n",
    "print(f\"New samples: {n_smp_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVhzAjUV8oFJ"
   },
   "source": [
    "### Preparing modified calibration data to feeding in eye_tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2yHN0I9cF6o",
    "outputId": "adfd1167-179f-48b5-c016-91e9249c46eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing modified calibration data to feeding in eye_tracking model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Education_Study\\University\\MSC\\Thesis\\EyeTracker\\venv\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../subjects/6/scalers_eye_tracking.bin']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nNormalizing modified calibration data to feeding in eye_tracking model...\")\n",
    "# x2_chs_inp_new = x2_new[:, tp.CHOSEN_INPUTS]\n",
    "x2_chs_inp_new = x2_new[:, CHOSEN_INPUTS]\n",
    "scalers_et = jload(et_public_scaler_dir)\n",
    "x1_scaler_et, x2_scaler_et, _ = scalers_et\n",
    "\n",
    "x1_nrm = x1_new / x1_scaler_et\n",
    "x2_nrm = x2_scaler_et.transform(x2_chs_inp_new)\n",
    "\n",
    "y_scalers_et = y_new.max(0)\n",
    "y_nrm = y_new / y_scalers_et\n",
    "\n",
    "scalers_et[2] = y_scalers_et\n",
    "jdump(scalers_et, subject_dir + \"scalers_eye_tracking.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNwyQAwL2pGS",
    "outputId": "9812cee4-8a01-4734-b479-81feed0099c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 48, 44, 1) (8, 48, 44, 1) (44,) (8,) (44, 7) (8, 7) (44,) (8,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and splitting data to train and test\n",
    "x1_shf, x2_shf, yx_shf, yy_shf = shuffle(x1_nrm, x2_nrm, y_nrm[:, 0], y_nrm[:, 1])\n",
    "\n",
    "n_train = int(R_TRAIN * n_smp_new)\n",
    "n_test = n_smp_new - n_train\n",
    "x1_train, x2_train = x1_shf[:n_train], x2_shf[:n_train]\n",
    "x1_test, x2_test = x1_shf[n_train:], x2_shf[n_train:]\n",
    "yx_train, yy_train = yx_shf[:n_train], yy_shf[:n_train]\n",
    "yx_test, yy_test = yx_shf[n_train:], yy_shf[n_train:]\n",
    "\n",
    "x_train = [x1_train, x2_train]\n",
    "x_test = [x1_test, x2_test]\n",
    "\n",
    "print(x1_train.shape, x1_test.shape, yx_train.shape, yx_test.shape,\n",
    "      x2_train.shape, x2_test.shape, yy_train.shape, yy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "PqdkxbYFcpuf"
   },
   "outputs": [],
   "source": [
    "# Callback for training\n",
    "cb = EarlyStopping(patience=PATIENCE, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpT4PjQUcprr",
    "outputId": "a3aa1dfd-0002-41de-a4b3-9719987a58ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading public eye_tracking models...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading public eye_tracking models...\")\n",
    "model_x = load_model(et_public_model_dir + \"_x\")\n",
    "model_y = load_model(et_public_model_dir + \"_y\")\n",
    "# print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgxSezv4jY70",
    "outputId": "5c8f1c31-0c46-4388-c243-de3247676f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 48, 44, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 48, 44, 16)   416         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 24, 22, 16)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 22, 32)   12832       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 12, 11, 32)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 10, 9, 64)    18496       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 5, 4, 64)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1280)         0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 256)          327936      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 263)          0           dense_30[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          33792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 64)           8256        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 32)           2080        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 8)            264         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1)            9           dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 404,081\n",
      "Trainable params: 9\n",
      "Non-trainable params: 404,072\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for (layer1, layer2) in zip(model_x.layers[:-TRAINABLE_LAYERS], model_y.layers[:-TRAINABLE_LAYERS]):\n",
    "    layer1.trainable = False\n",
    "    layer2.trainable = False\n",
    "\n",
    "print(model_x.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diMNdUZZjeLQ",
    "outputId": "282ee5b4-fde4-49ee-c57c-3fc9ae03c483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of training for model 1 (x-pixels)\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 183ms/step - loss: 0.1492 - val_loss: 0.1194\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0878 - val_loss: 0.0743\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0621 - val_loss: 0.0798\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0574 - val_loss: 0.0775\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0515 - val_loss: 0.0720\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0406 - val_loss: 0.0724\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0398 - val_loss: 0.0809\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0445 - val_loss: 0.0798\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0433 - val_loss: 0.0689\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0378 - val_loss: 0.0593\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0392 - val_loss: 0.0608\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0393 - val_loss: 0.0614\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0401 - val_loss: 0.0633\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0338 - val_loss: 0.0607\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0351 - val_loss: 0.0600\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0362 - val_loss: 0.0602\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0364 - val_loss: 0.0597\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0343 - val_loss: 0.0594\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0309 - val_loss: 0.0586\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0314 - val_loss: 0.0583\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0312 - val_loss: 0.0579\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0304 - val_loss: 0.0580\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0302 - val_loss: 0.0588\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0298 - val_loss: 0.0593\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0297 - val_loss: 0.0598\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0294 - val_loss: 0.0590\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0302 - val_loss: 0.0566\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0311 - val_loss: 0.0608\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0255 - val_loss: 0.0579\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0301 - val_loss: 0.0541\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0290 - val_loss: 0.0528\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0249 - val_loss: 0.0462\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0326 - val_loss: 0.0517\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0318 - val_loss: 0.0520\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0298 - val_loss: 0.0505\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0297 - val_loss: 0.0471\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0277 - val_loss: 0.0465\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0285 - val_loss: 0.0484\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0273 - val_loss: 0.0504\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0271 - val_loss: 0.0491\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0257 - val_loss: 0.0489\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0257 - val_loss: 0.0506\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStart of training for model 1 (x-pixels)\")\n",
    "results_x = model_x.fit(x_train,\n",
    "                        yx_train,\n",
    "                        validation_data=(x_test, yx_test),\n",
    "                        epochs=N_EPOCHS,\n",
    "                        callbacks=cb)\n",
    "print(\"End of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQz7jjQ5CTS8",
    "outputId": "f9c25499-ae97-4d66-8bfd-d5e13d35585d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of training for model 2 (y-pixels)\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.3512 - val_loss: 0.3248\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3063 - val_loss: 0.2453\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2792 - val_loss: 0.1991\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2294 - val_loss: 0.1794\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.1866 - val_loss: 0.1423\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.1567 - val_loss: 0.0649\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0963 - val_loss: 0.0105\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0612 - val_loss: 0.0234\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0541 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0183 - val_loss: 0.0293\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0237 - val_loss: 0.0381\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0178 - val_loss: 0.0229\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0096 - val_loss: 0.0172\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0071 - val_loss: 0.0097\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0054 - val_loss: 0.0148\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0061 - val_loss: 0.0175\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0068 - val_loss: 0.0088\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0049 - val_loss: 0.0070\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0053 - val_loss: 0.0117\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0044 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.0160\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0039 - val_loss: 0.0118\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.6016e-04 - val_loss: 0.0047\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.8067e-04 - val_loss: 0.0056\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00048: early stopping\n",
      "End of training\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStart of training for model 2 (y-pixels)\")\n",
    "results_y = model_y.fit(x_train,\n",
    "                        yy_train,\n",
    "                        validation_data=(x_test, yy_test),\n",
    "                        epochs=N_EPOCHS,\n",
    "                        callbacks=cb)\n",
    "print(\"End of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCu14ufb8oFN",
    "outputId": "55beefd3-f9e9-4338-8b26-4486771d830e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving models...\n",
      "INFO:tensorflow:Assets written to: ../subjects/6/model_eye_tracking_x\\assets\n",
      "INFO:tensorflow:Assets written to: ../subjects/6/model_eye_tracking_y\\assets\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving models...\")\n",
    "model_x.save(subject_dir + \"model_eye_tracking_x\")\n",
    "model_y.save(subject_dir + \"model_eye_tracking_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "e9L074ihCXD6"
   },
   "outputs": [],
   "source": [
    "# Predicting outputs for train and test data\n",
    "yx_hat_train = model_x.predict(x_train).reshape((n_train,))\n",
    "yx_hat_test = model_x.predict(x_test).reshape((n_test,))\n",
    "yy_hat_train = model_y.predict(x_train).reshape((n_train,))\n",
    "yy_hat_test = model_y.predict(x_test).reshape((n_test,))\n",
    "\n",
    "yx_hat_train[yx_hat_train < 0] = 0\n",
    "yx_hat_test[yx_hat_test < 0] = 0\n",
    "yy_hat_train[yy_hat_train < 0] = 0\n",
    "yy_hat_test[yy_hat_test < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "FDC8rCcVjjDa",
    "outputId": "48c3b4f3-1946-4554-b0e9-6ae7c0ca6120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(776, 1000)\n",
      "(825, 1005)\n",
      "Test\n",
      "(2588, 1000)\n",
      "(2392, 991)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2cb173fd460>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADHCAYAAAAAoQhGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi/klEQVR4nO2dXchlV3nH/89MMt+TjPkgDJnQpBgquWgVQlTSC40NpKmoF1IUKXMRmBsLEQVNWigIvdAbP6BFGRoxBTFaFTIEi6RxpAglGpto80FMFMSExKm0k2Q+Mvlw9eI95/icp+/+n2et95yz9578fzDMOWefvdbaez97vWf99/NhpRQIIYQYH9v6HoAQQog2NIELIcRI0QQuhBAjRRO4EEKMFE3gQggxUjSBCyHESNnSBG5mt5jZk2b2tJndsaxBCdE3sm0xBqzVD9zMtgP4OYCbATwD4McAPlxKeXx5wxNi/ci2xVi4YAv73gDg6VLKLwHAzO4B8H4AnUa+c+fOsmfPnk23mVmq0/gH53e/+92mrxftNwZWMebYpn/Pzl+EXS+/bdu2+UWefx/b8O+z7XvOnDmDc+fO5QyJU2XbO3bsKLt37950bK3X0O9X08YybCZ7Ly6Lddh59nvZ815zjtj9kN32wgsv/LaUcnlseysT+JUAfu3ePwPg7WyHPXv24N3vfvem27Zv3z57zW7sV199dW7byy+/PHt99uzZuW2vvfba7HW8GK+//jobahNscmL9dRkKGzObKJhxxfN37ty52etXXnkl3d8FF/zedKLhXXjhhbPX04ltiv8DvnPnzrlt3gZ8+3Fb7G/K8ePHN/28gSrb3r17N2688cZNx5b9oxjtw1+nuI21ybZlJ53WCbzrugD5MbPvsXPben8zm4/3iu8v2qcfWxyn/260+V27ds1exx+3/j46duzYrzYb/1Ym8BRmdgTAEWD+ZmYXyt+skzZmr9mNzQyP/TWNY8n+EmydYCNdxsb+IkfYNt+ON4q4Xzzv/g+gfw3MH0/c5on9+RsmjnnHjh2d29g1WfcvxkmfM7vetWvXzIbYLzo27nju2eTUOoFnYfcfI9s3s6V4rN52a/44xXmii3iP+bHF8+BtN44lO7/Ee92/Z/dRF1t5iPksgKvc+0OTz+YopRwtpVxfSrk+/vURYqAstG1v1/4PjxDrZCsT+I8BXGtm15jZDgAfAnBsOcMSoldk22IUNEsopZTXzOyvAXwPwHYAXymlPLa0kQnRE7JtMRa2pIGXUr4L4LuV+wCo05A8TEOKbXhNKT6QyD7kaH0o1KrLZh9GsgdGcT92DOxhpN/mH3YC/AEx02/9e/ZwrsZbZnq8y/RmqLHtUkpK/2XPNOL+TBtlzyaYjprVk9k4a54JLUM7z/YdYQ8V2b3D7gdPfPiZ9eZic1S8dqz/2XcWfkMIIcQg0QQuhBAjZeVuhF0w171IdtnN9ovLE98OGwuTWmqWmll3R99fdGNqDTJgy8mu78X3sU2/hIzLSQ+TvKKrF/MHZkvUzFJz1WR9+buI59BLfvF4vS3H/fy2uF/WBhnMxZBJKOwaMRmUkZUwa1yP2ZiZtxG7B7IwGa2L/i1fCCFEE5rAhRBipGgCF0KIkTIYDdwTdSmv6zFdqCbEmunqWX25NWyZhfl63a0mhJrhNb+aNph27vXA2GY2DLzGjdBva803skq67DLrXhbdXL3N12j8vo/43IedwyzM1Y0992H3VKsLXvb5FHtmkg25j/vFFBFZ261xq5UboRBCnMdoAhdCiJGydgllusxiy2AWTVbjZsTa9EtW5mLIlvnMXY9ti65YfjnmpYmaCDIGi/bKupZlo9diHywqlC2JazLuxfO5bkopnXbJ3OyyUXhZF7zYB3M/jDAXztaMeV2SA7P/mPCOZWz075m76pkzZzrH6NO5btZH1zaW/XBZkl5mrtMvcCGEGCmawIUQYqRoAhdCiJGydg28KxthNoyalZ566aWX5ra98MILs9cxmx4LS8+6ujGYfsW0ba8HRn3Ol1yKYb1Z18QIC71mbTCt0H+XVV+JY2Y6InOB66MiT+y/KyMisyX/XfZMKGq4p06dmr1mWfFYaHs8v/4+ivuxsH52Xfx7X/qQuftG9zxv57HkmL8/4n7MPv3x+HHFMbN7qqbCV3YuiP1JAxdCiPMYTeBCCDFSBuNGyFzIWLYy/11WtIEVS+0a42ZjYWSjzbKuX6yCfKz27t/H5WR2WRj7Y9kcWyMFWX9MQmEFo/uOxPQFHWrcXFkkoT83UUI5e/bsXN8e5urG5BzmkreMwiXZivWscAizwSg3+nugJtqSRX1nC7HXyGjs3sycW/0CF0KIkaIJXAghRoomcCGEGCmDyUbI3AhZSLzXzKJLVdYtLrrkZTOL1bgLsZDgqFlPYRp4bCNqgJ7ss4A4jqyLYY0G7c8D0zSZi2HXNVlmUeNWWs9T3OavdXR1Y1WbWMoGb0/MLTT2l3WDi/15tz9//eJ9yjR9du/788BcS1mx7kjWPZA9w2NtsnQKLYXe9QtcCCFGiiZwIYQYKb1JKAzmQsaWXzVZ6rzksG/fvrltbOnCMhX6/Vg2wphxzb/PLrfYGFkx5JpCGl1tAO2FaJk7JTs+5orVdyQmG0NWcovygLdzZtdMComupl4qZDYSpTsGkwZ9f34sccwsM2hWlmSSW00GRVb8JGtnrGgDyxAZ7Trj/qhf4EIIMVI0gQshxEhZOIGb2VfM7ISZPeo+u8TM7jezpyb/v2m1wxRi+ci2xdjJaOBfBfAPAP7ZfXYHgAdKKZ8xszsm7z+V6bArpDarjUYN3L+PbXvdLba5d+/e2euLL754bhvTulhoL6vW42F6HQvJ9Xp/hLkDsuyA8Xx27ceeJ7BnATWFmbNhzK2h+5vwVSzRtmthz3aYS2W2YG/UwLvsDOBui/59jVttl2tddHn1GrjPtBj7i9fdPzuKbfpjjcfDNH5WVYs942JuhMwtuTV0fzbeRV8opfw7gP8JH78fwN2T13cD+MDCnoQYGLJtMXZavVCuKKU8N3n9PIArur5oZkcAHAH+/y8CIQZIyra9XUevIiHWxZbdCEspxcw6fX1KKUcBHAWASy65pLQsf1kmOh/tFdv2y6qaqD+23+nTp2ev49KMRVX5Y4hLOD8BsKyC7Dx44nnw7bAMdSybI0vWz9pkrnM12/xYarLLbQVm296u9+/fv+UQ0Ghn/px6uQ+YP/6YvY/h3fqYPBB/aHmbz0YcAvP25Pc7cODA3PdY8QrfZpR9/DijhMIyimZdaWvcDz3MjZC5CrZEEreKib8xs4MAMPn/RGM7QgwN2bYYDa0T+DEAhyevDwO4dznDEaJ3ZNtiNGTcCL8O4D8A/JGZPWNmtwH4DICbzewpAH82eS/EqJBti7GzUEwspXy4Y9N7ttIxc0uLWpDXiWLmQA8LOWY6mC9+DMzrYPEBlQ+7jxq4d4FiWf+i/uiPyb9mLn6xDX+Oonaezb4Wv9elYQLz549lxIuwEHEWUu3PS0vWts1YhW3HY2culf59tOsum4iwIt/R7dSPLerqsWCwx9s56y/SlREw6txeY2cVhuK9yIp8ZwsxsypULMMhm6OYe3FsM+uW3IUiMYUQYqRoAhdCiJGy9myE0yURy9YXJYCaKMAu2HKISSEsajK6Lnl5IMofzO3PLyn98cQlsF9ixSWwH0tcajKXKhbVx/ZjEbCM7FKzpkjE9Jz1VdDBzDqvr/88fifr3hlhhXBZZJ+/ZvEe8y550X7279+/aRuROGZvv6yYhG8zXkM/ThZtGaUQJsf5bbE/30eN3OGJ8xUrSsFcDCWhCCHEeYwmcCGEGCmawIUQYqSsVQNnWiFzs/PbsgVWI1Er9Npa1KW8Jh3dk/x3Wcg6yzrGQtaZyxYrxMzycfh2WEWQeB78WJh2x/R99owinj+WtY254w0JdkzsWU6EZbbMVqJh1zqG4Ps2oz7udeEYZu9tmdm177smU6fvLz738ccXj8ePJer2zCZrUlR0UaNls6pMmVB+/QIXQoiRoglcCCFGymCKGndFbQF8ac2iozyxTb9Ui8umbARk3I8Vm2UueV1LOlYkNi4nmTugX06ypWbcFt0rPSy6M1scmS0tawpGD6Go8fT8M9kr6xpYQ00xX7ZczxY5iBKKt5lluPRGadBHW7JIYWa7LBKTFbaI21qPz79nkbqL2tn0O6kRCSGEGByawIUQYqRoAhdCiJHSmwbO9B1WLYRpRjVaqNfTorbmNbKoe3ldjLk7xuNjmRG72ojuXF4PZG6DUc9kBWuZe6PfVpM9kl2j1m2ZKipD0MIZ7NnOssbu7YJVyIkaOHPVZTbpNfHYZpdmzJ5HRQ2cuft2uSkC/B72sDaZVs8ycLL5hD2/iW1mbEK/wIUQYqRoAhdCiJHSm4TC3AHZMoNJLzWJ/lmWM7+sim34PuJSyS//WDQWczXzr6NM4perLPMbyxwYXSRZJjhP1oUK4Es/5mrJikJ72NK2L7pknKxUyKQ6ZoOszZpi0wxv5/F4mJtf130Uv8fkRXaOutpYNGZGVqKtyerpty1Lipy1vfAbQgghBokmcCGEGCmawIUQYqSsVQMvpcx0nZpwU68bRR2sNWw7m7mwprCw19KjuxXLCNilW0at0B9PdAfM6tesGHJ0qWI6bE2WwSzsWQdrs7W/ZTIde9Q4s6kDmIshgz1LYsWQWZg9e04SYRWquqg51la3YZYZtDVtB3Nb9NSEy/s24/2uUHohhDiP0QQuhBAjpbeCDmz5s4pscyy5fVyq+KUni2arcf1ikVpd32PngbkcZd3M4pgjvh22LKxxc2PHzpalzD2ub5hdZ68Fi8KrKUDAluvZax1hBayZ3XW1mbX/2EaNrNY1RmA5mU8jfl6ouf9YVtQM+gUuhBAjZeEEbmZXmdlxM3vczB4zs9snn19iZveb2VOT/9+0+uEKsTxk22LsZH6BvwbgE6WU6wC8A8BHzew6AHcAeKCUci2ABybvhRgTsm0xahZq4KWU5wA8N3n9kpk9AeBKAO8H8K7J1+4G8AMAn1rJKB1M96ophJuthMFc+aJ7VbZwa6QrRLfmWJnuxrRPpsPWhFt3jY2lFGB6IAu37nIzrdUQl2nb0zHUuKsy/ZjptMytNttmvNbZ0H12H2WrKDFtucbmsi6GNekNsterpuJW1/eA+fO+cjdCM7sawNsAPAjgiskNAADPA7iipi0hhoRsW4yR9ARuZvsAfBvAx0opL/ptZeNP06Z/Ds3siJk9ZGYPsRqLQvRFi217u2aBLkKskpQboZldiA0D/1op5TuTj39jZgdLKc+Z2UEAJzbbt5RyFMBRALj00kvLdFnAXIKykYqbjJO+D+Pq7M/DIuvikpG5wXnYMju7FKuJUMtKC61uWhG25M66acXlZGuU5iJabdvb9cUXXzw7kBp3S3YM2SIAq4hCjXbnr0U8hmwmwVWMi0Vv17TTsh9ro6b9rdp1xgvFANwF4IlSyufcpmMADk9eHwZw78LehBgQsm0xdjK/wG8E8FcA/svMHpl89jcAPgPgm2Z2G4BfAfjLlYxQiNUh2xajJuOF8kMAXWuh9yx3OEKsD9m2GDtrr8gz1XxqshEyHTHr9sPCkZlrFHNBYjoto1WDY7C+s/0tqxJSts1MxZHN+u9yxRpaiH0knsNslaOa5z7Z+6EmvLwm9N3TYuc1WvYq9P+sWySr/tV6TlaigQshhBgmmsCFEGKk9CahsM9r3OCYWxprgxU5yLp+sUjCSI1c0NVeNtKTue61uuCxzIut1ERi+gyRsVjG9LtDl1Ai/twzSYPZDnNdjdcoa/OtUcSRrJsfk8daCzqwNrJFG1h2xZooV4ZvJ+4nCUUIIc5jNIELIcRIWauE8uqrr+L5558HwJO6dC2RAWDnzp1z25aRcIktQ2tqP7IlFnuC7fvwr9nSjy3vWHEABkvQk10q1+xXU5Ti9OnTm772+KT668TMOmWcrEcCKwTRKilGu87aD2uzRgrs6q/Ga8nTKqfEbX5+qfEYYbJWjZcbG5uHSbJT9AtcCCFGiiZwIYQYKZrAhRBipKy9qPFU14k6dzZZ+mZtbtZGzX7eRS22U1OEt9WNrcsFqSa7GyuO2lrweBVkE+2zZwgtLpmrZjr2ZbnBMW221eWWncNsJs2o9bJnNl12zTJ8tmYiraE1IrXre/G77BlXhLlaZtwR9QtcCCFGiiZwIYQYKb1JKDXuVoxluRZ1tclc3aK8wly/2DKxa/nKokdroj6zkWfZJXDcFo+nNUozG5HXJQP1FYlpZrO+l2Fzi7a1ykks8pPZU1Z2y7rW1dSnzbof1pCtEbuswihZm5CEIoQQbyA0gQshxEjRBC6EECOlt2yENXpltsBCjbaW7a+mEC0jWziZZYzz/TF3rmWFUPv+oh7HwpGZdpfNese2taYKWCWZLJsR5nqWDV+vsfFVu2KyNr19vvLKK537RbvOpqeosQGW9dK/r3mW02rL7LlP5pj0C1wIIUaKJnAhhBgpa3cj7FqWLMMdsNU9qaaeJOtvGdkI/ba4nPTSSMy857dFCcW/r1k6M5eqvXv3zl7HqFo/7ppMhdkMfF3ujn26EU7tuiZ7ZStZKaTGnTR7rzB5jskfXjaJtpstosBgmUEjLPPprl27UvvVRHBmpTIVdBBCiDcQmsCFEGKkaAIXQoiRsnY3wi5a9cuspttaBDiSrZjDsr1FrdDrg0zn9u9jG0xjZ65KHqZJx+M5e/ZsZzue6KbF3D6ZHshczZalLbdSSqHa95SaUPBsOocaO+iq/LSoP7Yfs0kPew7Tmq2v63sA1+3ZPZx1S65xZ85e95b99AtcCCFGysIJ3Mx2mdmPzOynZvaYmX168vk1ZvagmT1tZt8wsx2L2hJiSMi2xdjJSCjnANxUSjllZhcC+KGZ/SuAjwP4fCnlHjP7MoDbAHyJNVRKWVpGMd/mlJpE6sz9iS1Rsy55bDkUl3Qvv/zy7LVfkp47d66zzSivsOWdL1gRJQ1fJLo1OjYrp8SxsDYzkkT8bkN04VJsu5TSmVEyK++wDJVsW7QR5k7qqSkozWzX98/cA5kM44nSmbfP6OLn37NsinEbs7MuOROYt11WXL01KrPFhXKhdZUNTk3eXjj5VwDcBOBbk8/vBvCBhb0JMSBk22LspH4emNl2M3sEwAkA9wP4BYCTpZTpn6hnAFzZse8RM3vIzB6KORCE6JtW25ZdiyGQmsBLKa+XUt4K4BCAGwC8JdtBKeVoKeX6Usr1bPksRB+02rbsWgyBKjfCUspJMzsO4J0ADpjZBZNfKocAPJtpo0vXyYYHsyo1sW3/yygbvs7GGLexcPmorXmdO2rGXa5YzP0pwjRw307UEVlYcbbqD8uMGNv054yF2dfo2ct4rrJV256OnbmPsipD8Vp7G2Hh68wlL54Xr1fXpGlg+7VkTaxxz/Pvo+7MbJBlHMxmMWQpKVgWQ0ZNRsWlaOBmdrmZHZi83g3gZgBPADgO4IOTrx0GcO/C3oQYELJtMXYyfzYOArjbzLZjY8L/ZinlPjN7HMA9Zvb3AB4GcNcKxynEKpBti1GzcAIvpfwMwNs2+fyX2NAMq5guGWoiwVgBXRYJ1rrUZK5YTMbw44z7nT59evY6SihdS092PDVki9LWRLqxrIKe1iyTbJm9xKx+S7XtzcgW04jugOzBqD8XNW6ETFL0bXq5L+63jCIpNduY5OblwJpiCFmXPxbdmb2nIsy9uCaj4myfhd8QQggxSDSBCyHESNEELoQQI2Xt2Qi79K5lZPJjtBb6ZQVYWXFdptWzbIHep5hpmDXaclf7wLyOyLRlpjEyF6p4vVgx5Kz7Zkvx13VRE6LubYLZWcTr3mfOnJnblrXrZRU1Zs9Qss9XottiVxvRzrwtM1uquVeYK2vWjZf1UVOpK1NUWb/AhRBipGgCF0KIkbJWCcVnI2RLzSgd+CUWk0LiMsp/N7pG+W1MCqnJcubbictC32bsz7ezZ8+ezjb8scZtWRdAltGNRZ6x5TEr2sCW8TVukZlE+8uSBbZCa5a/iD+/UV7xbqgsY2WN5JB1na0pFuL789JZTREKf6/E4/FtxnuKHY//LpNF2P3NjqGGrAtlF/oFLoQQI0UTuBBCjBRN4EIIMVJ6K2rMtEKmC0XtLqudRw2caYVe66pxyfPbojbp24zH5/v3bcbv+TbisTKXLaYjMo2fVYVh2d6YBu6J27LugK37rZLpGGrGxp6LePuJGrjXX1kGu3hd/PMV/zr2wdwdI/5aM9vyY2bPduJ58O3Hbf5eYVlKI+z5DatixFxgs6lAavbLoF/gQggxUjSBCyHESFmrhGJmsyVETXQUi0hiS3TWB1ti7d69u3ObZ9++fXPvmauUd/2K+1100UWz1/7Ya1zEmETjxxXdCD1x+chkElaFhl0T306N9FFT5LgPMhHGyyrozWQ8T9x22WWXzV7v379/bpu3TyahRPnDSzHejiO+fZ+ZM/bH3BRjQQdv19F2W936/Dljck5NRszsXNciBeoXuBBCjBRN4EIIMVI0gQshxEhZuxvhVOdh7nmMGm2L6Wde64paIdOa9+7du+nrSHTT8v1HPTdq3V3fY25nnjhmr3vHbSwjHtP8Yha8rv3iufX917iEsuPt243QzGbjYyHWzGUtbvPt1Li5elibEW/LUcv2mnW87v4Y4rYut9qsqx4w/zwq3m/++FgaCJZ+I54/33/NMwsW1s/cPreKfoELIcRI0QQuhBAjpTcJpbWAboS5UbEoLr+0jcs2BpMx/Pu43PNLwZMnT85t8+/9si0bTRbfs6INEZZprrWIq5eL4rXMXpOarH59SyjA74+rpiiG/26NG1xr9J6Xy2JhbW8j0V687Ua5z9sPi3ZmBRb8eYn3one5jXbNsnP68xm3sfvKHx+z3ZrMiH6/OBZm15lrq1/gQggxUjSBCyHESNEELoQQI2UwboQsFDwbbso0sppqKF19A/P6WXS766pAAsxreS+99NLcNu+m5bU7pnOz88dc95gLF3N/YpVS4rEyPTCbna/m2PvGuxHWPNvJFmpm1XNqChf791Gv7uobmH+eE7Vzb7tM32XFgr19xjQW3h2XhfhHbb61gDPTpNnzG/+e2QC7XjXP/mb7LPyGEEKIQZKewM1su5k9bGb3Td5fY2YPmtnTZvYNM+t2BxFioMiuxZipkVBuB/AEgGmY1mcBfL6Uco+ZfRnAbQC+tKiRLgmFLZGzckdcgjAJwG+LbkVsOcQiz1j0nF8axkxwXophifXZstrLJnEZygoCe2qWhV1FKOJ75lLVSlcbjdLKlu06K6GwAh1ZaSlSE2XI9vMSBCucEG3L7xePr2sssX3vdhrdb/13o2TpJZTYN3P5YwUksm7CUTZkkcJd7S/atjQJxcwOAfgLAP80eW8AbgLwrclX7gbwgUxbQgwF2bUYO9mfQ18A8EkA0z9dlwI4WUqZ/hl/BsCVm+1oZkfM7CEzeyj+BRWiZ76AJdg1eyAoxCpZOIGb2XsBnCil/KSlg1LK0VLK9aWU61nUpBDrZJl2zSJdhVglGQ38RgDvM7NbAezChlb4RQAHzOyCya+VQwCeXdSQmc30qJpMX0z79boz0wOZCxcr7MvGyUJ0WWHhAwcOzG3zx/fiiy/OXsfjYbqen0RYseUa1ygWnp91I2S6XqtrZ6RRV1+aXfsxML2VHR8L22bueaz6Uny241fAzGWUZcGMmQr98Z46dWpuW9fKJP7B87p3zBqaLagc7cyPi9l8vF5MA2fuscz9kNkAc69cigZeSrmzlHKolHI1gA8B+H4p5SMAjgP44ORrhwHcu7A3IQaC7FqcD2zFJeBTAD5uZk9jQzu8azlDEqJXZNdiNFRFYpZSfgDgB5PXvwRwQ83+27Ztmy3Fa4oRs+WJhy054lLML4GYiyHrI46TPaRlY/PRZv41k1AirUt1to0VdMgWmm51G6zpb6uRmcuw66kswNxOmZsds0G2jT1Xiv3579a41TKpwsshsYhJlx2ya9lajDiSlQZZsQy2jRUjifNA65yVuXcUiSmEECNFE7gQQowUTeBCCDFS1pqN0MxmrjhRZ8tq4jVh9l7DYro6y+wXt/n9aqprMD3Zk3U5YuehRkdkLppsnOw5gd+PFfll4c8tRa/7ylJoZlSLnsIKNbOxs+vJ7iNWaSqOxeu2sT//3ZpnEy0sy5U0m9mydSzsvLPqSjWh9NLAhRDiPEYTuBBCjJS1SyhTtyNWhLQm6TmLuGIuf1nXHuYuxNyt2PKHuTW1Skld7S3Cn7+WhPIAj9yrgZ13di37xkuDi77nYTKUP0YW9VezHyNrd0xCaS3E3GovWRdV1h+TVuM2dr1a5xMm9UhCEUKI8xhN4EIIMVI0gQshxEhZqwa+bdu2WbaxVhe1Gvc8pnX5Plrd7lgWQ6a7sWNnRYcZrUWhl1EVJtKqB2bdCFtdzVaF18CXUXEIaNf5mSsr07LZsxD27IVdl67rFD9fxnOYVbiQMn08wiohsWcRNc/KNt1/4TeEEEIMEk3gQggxUtbuRjiNWGNLpZjNaxnLyRq5o7WIcnapxKIoWbJ51oaHFc9lZCNEa/aLZKUkdnxdbnV9RmJOr1XNuchGz7YeV7yPsue0xtXNwySUrCtivLbZzJYsYrpGEsq6GNbcD6t0k9QvcCGEGCmawIUQYqRoAhdCiJHSWzbCmhD1rLbM3KZY5rvYPmuTVUphbbbo6rEN5m7F9NRlhLbXZHTLZnpkBWXZWGq2rYvp9WD6J7OlrIvaZn10fZeF4LMskZGsrp/NZskq3bB0AzU2sIyMg+y7cT+m42evV7wG7LndrO2F3xBCCDFINIELIcRIsXVmdjOz/wbwKwCXAfjt2jruZijjAIYzlqGMA6gfyx+UUi5f1WC6GKBdA8MZy1DGAYx7LJva9lon8FmnZg+VUq5fe8cDHQcwnLEMZRzAsMaSYUjjHcpYhjIO4PwciyQUIYQYKZrAhRBipPQ1gR/tqd/IUMYBDGcsQxkHMKyxZBjSeIcylqGMAzgPx9KLBi6EEGLrSEIRQoiRstYJ3MxuMbMnzexpM7tjzX1/xcxOmNmj7rNLzOx+M3tq8v+b1jCOq8zsuJk9bmaPmdntPY5ll5n9yMx+OhnLpyefX2NmD06u0zfMbMeqxzLpd7uZPWxm9/U5jhZk28Ox7aHZ9aTvldj22iZwM9sO4B8B/DmA6wB82MyuW1f/AL4K4Jbw2R0AHiilXAvggcn7VfMagE+UUq4D8A4AH52chz7Gcg7ATaWUPwHwVgC3mNk7AHwWwOdLKW8G8L8AblvDWADgdgBPuPd9jaMK2faModj20OwaWJVtl1LW8g/AOwF8z72/E8Cd6+p/0ufVAB51758EcHDy+iCAJ9c5nkm/9wK4ue+xANgD4D8BvB0bAQYXbHbdVtj/IWzc3DcBuA+A9TGOxrHLtjcfU++23bddT/pamW2vU0K5EsCv3ftnJp/1yRWllOcmr58HcMU6OzezqwG8DcCDfY1lsrR7BMAJAPcD+AWAk6WUaXHOdV2nLwD4JIBpdp9LexpHC7LtQN+2PSC7BlZo23qIOaFs/Clcm0uOme0D8G0AHyulvNjXWEopr5dS3oqNXwk3AHjLOvr1mNl7AZwopfxk3X2/EXgj2vYQ7BpYvW2vM53sswCucu8PTT7rk9+Y2cFSynNmdhAbf61XjpldiA0D/1op5Tt9jmVKKeWkmR3HxnLugJldMPmFsI7rdCOA95nZrQB2AbgIwBd7GEcrsu0JQ7Ptnu0aWLFtr/MX+I8BXDt5+roDwIcAHFtj/5txDMDhyevD2NDsVoqZGYC7ADxRSvlcz2O53MwOTF7vxoZe+QSA4wA+uK6xlFLuLKUcKqVcjQ27+H4p5SPrHscWkG1jOLY9FLsG1mDb63qYMBHrbwXwc2zoUX+75r6/DuA5AK9iQ3O6DRta1AMAngLwbwAuWcM4/hQbS8ifAXhk8u/WnsbyxwAenozlUQB/N/n8DwH8CMDTAP4FwM41Xqd3Abiv73E0jFu2PRDbHqJdT/pfum0rElMIIUaKHmIKIcRI0QQuhBAjRRO4EEKMFE3gQggxUjSBCyHESNEELoQQI0UTuBBCjBRN4EIIMVL+DyfPo4YlSTcuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying data\n",
    "NUM = 2\n",
    "print(\"Train\")\n",
    "sample_train = (int(yx_train[NUM] * y_scalers_et[0]),\n",
    "                int(yy_train[NUM] * y_scalers_et[1]))\n",
    "sample_hat_train = (int(yx_hat_train[NUM] * y_scalers_et[0]),\n",
    "                    int(yy_hat_train[NUM] * y_scalers_et[1]))\n",
    "print(sample_train)\n",
    "print(sample_hat_train)\n",
    "\n",
    "print(\"Test\")\n",
    "sample_test = (int(yx_test[NUM] * y_scalers_et[0]),\n",
    "                int(yy_test[NUM] * y_scalers_et[1]))\n",
    "sample_hat_test = (int(yx_hat_test[NUM] * y_scalers_et[0]),\n",
    "                    int(yy_hat_test[NUM] * y_scalers_et[1]))\n",
    "print(sample_test)\n",
    "print(sample_hat_test)\n",
    "\n",
    "_, ax = plt.subplots(1,2)\n",
    "ax[0].imshow((x1_train[NUM] * x1_scaler_et).astype(np.uint8).\n",
    "           reshape((frame_height, frame_width)), cmap=\"gray\",vmin=0, vmax=255)\n",
    "ax[1].imshow((x1_test[NUM] * x1_scaler_et).astype(np.uint8).\n",
    "           reshape((frame_height, frame_width)), cmap=\"gray\",vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXSSVV778oFP"
   },
   "source": [
    "### Getting sampling data that looking 'in' screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A89vgRT88oFP",
    "outputId": "7be8e6ed-6f3b-4ec0-d134-5c51d5c16a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading subject sampling data in ../subjects/6/sampling data/\n",
      "Number of sampling data : 131\n"
     ]
    }
   ],
   "source": [
    "eye_tracking_smp_dir = subject_dir + \"sampling data/\"\n",
    "print(f\"\\nLoading subject sampling data in {eye_tracking_smp_dir}\")\n",
    "with open(eye_tracking_smp_dir + \"t.pickle\", \"rb\") as f:\n",
    "    t_smp_load = pickle.load(f)\n",
    "with open(eye_tracking_smp_dir + \"x1.pickle\", \"rb\") as f:\n",
    "    x1_smp_load = pickle.load(f)\n",
    "with open(eye_tracking_smp_dir + \"x2.pickle\", \"rb\") as f:\n",
    "    x2_smp_load = pickle.load(f)\n",
    "\n",
    "n_sampling= t_smp_load.shape[0]\n",
    "print(f\"Number of sampling data : {n_sampling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "44uvMv2b8oFQ"
   },
   "outputs": [],
   "source": [
    "# Normalizing Sampling data for 'in_blink_out' model\n",
    "x2_smp_chs_inp = x2_smp_load[:, tp.CHOSEN_INPUTS]\n",
    "x1_smp = x1_smp_load / x1_scaler_ibo\n",
    "x2_smp = x2_scaler_ibo.transform(x2_smp_chs_inp)\n",
    "x_smp = [x1_smp, x2_smp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_UMXhI68oFR",
    "outputId": "0ed86366-9414-4c01-a0f3-f743e866e6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting those data that looking 'in' screen...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicting those data that looking 'in' screen...\")\n",
    "yhat_smp_ibo = model_ibo.predict(x_smp).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AZ_BVnU8oFR",
    "outputId": "88e61602-22d4-43fc-c8c0-89c52e02ef85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New samples: 131\n"
     ]
    }
   ],
   "source": [
    "# Choosing those data\n",
    "t_smp_new = []\n",
    "x1_smp_new = []\n",
    "x2_smp_new = []\n",
    "for (t0, x10, x20, yht0) in zip(t_smp_load, x1_smp_load, x2_smp_load, yhat_smp_ibo):\n",
    "    if True: # yht0 == 0:\n",
    "        t_smp_new.append(t0)\n",
    "        x1_smp_new.append(x10)\n",
    "        x2_smp_new.append(x20)\n",
    "\n",
    "t_smp_new = np.array(t_smp_new)\n",
    "x1_smp_new = np.array(x1_smp_new)\n",
    "x2_smp_new = np.array(x2_smp_new)\n",
    "n_sampling_new = x1_smp_new.shape[0]\n",
    "print(f\"New samples: {n_sampling_new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1c4gEd_8oFS"
   },
   "source": [
    "### Predicting eye track for samling data in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "YMJFqQru8oFS"
   },
   "outputs": [],
   "source": [
    "# Normalizing Sampling data for 'eye_tracking' model\n",
    "x2_smp_new_chs_inp = x2_smp_new[:, tp.CHOSEN_INPUTS]\n",
    "x1_smp_nrm = x1_smp_new / x1_scaler_et\n",
    "x2_smp_nrm = x2_scaler_et.transform(x2_smp_new_chs_inp)\n",
    "x_smp = [x1_smp_nrm, x2_smp_nrm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhGRU1Gp8oFS",
    "outputId": "b56be31f-2332-4b59-c6b4-c46b3ffc186b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting sampling data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicting sampling data...\")\n",
    "yx_hat_smp = np.expand_dims(model_x.predict(x_smp).reshape((n_sampling_new,)), 1)\n",
    "yy_hat_smp = np.expand_dims(model_y.predict(x_smp).reshape((n_sampling_new,)), 1)\n",
    "\n",
    "pixels = (np.concatenate([yx_hat_smp, yy_hat_smp], 1) * y_scalers_et).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nz2knxtl8oFT",
    "outputId": "daa99dbb-be51-4072-9232-e7e313026a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pixel data saved!!\n"
     ]
    }
   ],
   "source": [
    "eye_tracking_pixels_dir = subject_dir + \"sampling data-pixels/\"\n",
    "if not os.path.exists(eye_tracking_pixels_dir):\n",
    "    os.mkdir(eye_tracking_pixels_dir)\n",
    "\n",
    "with open(eye_tracking_pixels_dir + \"t.pickle\", 'wb') as f:\n",
    "    pickle.dump(t_smp_new, f)\n",
    "with open(eye_tracking_pixels_dir + \"pixels.pickle\", 'wb') as f:\n",
    "    pickle.dump(pixels, f)\n",
    "print(\"\\nPixel data saved!!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rtn_2mdl_et_35p_predict_tst.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
